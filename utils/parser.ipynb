{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c89076cf-88c9-43ce-8c35-528137c16a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict, List, Optional, Tuple\n",
    "import json\n",
    "import fitz  # PyMuPDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fdaca6c5-5f90-42ac-92f3-7fb346ea0e01",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mmk2266/envTorch124/lib/python3.10/site-packages/pypdf/_crypt_providers/_cryptography.py:32: CryptographyDeprecationWarning: ARC4 has been moved to cryptography.hazmat.decrepit.ciphers.algorithms.ARC4 and will be removed from cryptography.hazmat.primitives.ciphers.algorithms in 48.0.0.\n",
      "  from cryptography.hazmat.primitives.ciphers.algorithms import AES, ARC4\n"
     ]
    }
   ],
   "source": [
    "# import text, image, and table extractor functions\n",
    "\n",
    "from parser_extractors import (\n",
    "    extract_text_blocks,\n",
    "    extract_image_blocks,\n",
    "    extract_tables_for_page,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2274a672-5ce6-4314-b405-a8cd29f0f120",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_pdf(\n",
    "    pdf_path: str,\n",
    "    out_dir: str,\n",
    "    *,\n",
    "    export_images: bool = True,\n",
    "    raster_fallback: bool = True,\n",
    "    raster_dpi: int = 220,\n",
    "    pages: Optional[List[int]] = None,  # 1-based page numbers; None = all\n",
    ") -> Path:\n",
    "    \"\"\"\n",
    "    Extract TEXT, IMAGES, TABLES for all (or selected) pages into one JSON.\n",
    "    Returns path to the JSON payload.\n",
    "    \"\"\"\n",
    "    pdf_path = str(pdf_path)\n",
    "    stem = Path(pdf_path).stem\n",
    "    workdir = Path(out_dir) / stem\n",
    "    img_dir = workdir / \"images\"\n",
    "    tables_dir = workdir / \"tables\"\n",
    "\n",
    "    # create dirs (images dir optional)\n",
    "    workdir.mkdir(parents=True, exist_ok=True)\n",
    "    tables_dir.mkdir(parents=True, exist_ok=True)\n",
    "    if export_images or raster_fallback:\n",
    "        img_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    doc = fitz.open(pdf_path)\n",
    "    if doc.page_count == 0:\n",
    "        doc.close()\n",
    "        raise ValueError(\"Empty PDF.\")\n",
    "\n",
    "    # page list (1-based)\n",
    "    if pages is None:\n",
    "        page_indices = list(range(1, doc.page_count + 1))\n",
    "    else:\n",
    "        # sanitize and clamp\n",
    "        page_indices = [p for p in pages if 1 <= p <= doc.page_count]\n",
    "        if not page_indices:\n",
    "            doc.close()\n",
    "            raise ValueError(\"No valid pages to process.\")\n",
    "\n",
    "    all_texts: List[Dict[str, Any]] = []\n",
    "    all_pictures: List[Dict[str, Any]] = []\n",
    "    all_tables: List[Dict[str, Any]] = []\n",
    "    per_page_stats: List[Dict[str, Any]] = []\n",
    "\n",
    "    for pno in page_indices:\n",
    "        page = doc.load_page(pno - 1)\n",
    "        pdict = page.get_text(\"dict\")\n",
    "\n",
    "        # --- TEXT ---\n",
    "        texts = extract_text_blocks(page, pno)\n",
    "        all_texts.extend(texts)\n",
    "\n",
    "\n",
    "\n",
    "        # --- TABLES ---\n",
    "        tables, tstats = extract_tables_for_page(\n",
    "            pdf_path=pdf_path,\n",
    "            pno=pno,\n",
    "            workdir=tables_dir,\n",
    "            stem=stem,\n",
    "            page_texts=texts, # we need to pass texts to look for captions \n",
    "            page=page,\n",
    "            flavors=(\"lattice\", \"stream\"),\n",
    "            save_csv=True,\n",
    "        )\n",
    "        all_tables.extend(tables)\n",
    "        \n",
    "\n",
    "        # --- IMAGES ---\n",
    "        pictures, istats = extract_image_blocks(\n",
    "            doc,\n",
    "            page,\n",
    "            pdict,\n",
    "            pno=pno,\n",
    "            img_dir=img_dir,\n",
    "            stem=stem,\n",
    "            raster_fallback=raster_fallback,\n",
    "            raster_dpi=raster_dpi,\n",
    "        )\n",
    "        all_pictures.extend(pictures)       \n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        # quick console summary per page\n",
    "        print(\n",
    "            f\"[p{pno}] text={len(texts)} | figures={istats['figures']} \"\n",
    "            f\"(with_caption={istats['with_caption']}) | \"\n",
    "            f\"xobjs={istats['xobjects_found']}(exp={istats['xobjects_exported']}) \"\n",
    "            f\"| tables={len(tables)}\"\n",
    "        )\n",
    "        \n",
    "        per_page_stats.append({\n",
    "            \"page\": pno,\n",
    "            \"text_blocks\": len(texts),\n",
    "            **istats,\n",
    "            \"tables_found\": len(tables),\n",
    "        })\n",
    "\n",
    "        \n",
    "\n",
    "    # --- Write one JSON payload ---\n",
    "    meta = doc.metadata or {}\n",
    "    payload = {\n",
    "        \"title\": meta.get(\"title\") or None,\n",
    "        \"authors\": [a.strip() for a in (meta.get(\"author\") or \"\").replace(\";\", \",\").split(\",\") if a.strip()],\n",
    "        \"source_path\": pdf_path,\n",
    "        \"page_count\": doc.page_count,\n",
    "        \"processed_pages\": page_indices,\n",
    "        \"counts\": {\n",
    "            \"texts\": len(all_texts),\n",
    "            \"pictures\": len(all_pictures),\n",
    "            \"tables\": len(all_tables),\n",
    "        },\n",
    "        \"stats_per_page\": per_page_stats,\n",
    "        \"texts\": all_texts,\n",
    "        \"pictures\": all_pictures,\n",
    "        \"tables\": all_tables,\n",
    "    }\n",
    "    out_json = workdir / f\"{stem}.raw.json\"\n",
    "    out_json.write_text(json.dumps(payload, ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
    "    doc.close()\n",
    "    print(f\"[done] wrote {out_json}\")\n",
    "    return out_json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b17f59ee-a670-4aad-8f14-ac9eaddba727",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cannot set gray non-stroke color because /'P1' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P2' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P3' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P4' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P5' is an invalid float value\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[p1] text=22 | figures=0 (with_caption=0) | xobjs=3(exp=3) | tables=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cannot set gray non-stroke color because /'P1' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P2' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P3' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P4' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P5' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P1' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P2' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P3' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P4' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P5' is an invalid float value\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[p2] text=34 | figures=0 (with_caption=0) | xobjs=1(exp=1) | tables=1\n",
      "[p3] text=16 | figures=0 (with_caption=0) | xobjs=0(exp=0) | tables=1\n",
      "[p4] text=40 | figures=0 (with_caption=0) | xobjs=0(exp=0) | tables=1\n",
      "[p5] text=34 | figures=0 (with_caption=0) | xobjs=3(exp=3) | tables=1\n",
      "[p6] text=26 | figures=0 (with_caption=0) | xobjs=0(exp=0) | tables=1\n",
      "[p7] text=46 | figures=0 (with_caption=0) | xobjs=0(exp=0) | tables=1\n",
      "[p8] text=26 | figures=0 (with_caption=0) | xobjs=0(exp=0) | tables=1\n",
      "[p9] text=25 | figures=0 (with_caption=0) | xobjs=0(exp=0) | tables=1\n",
      "[p10] text=25 | figures=0 (with_caption=0) | xobjs=0(exp=0) | tables=1\n",
      "[p11] text=20 | figures=0 (with_caption=0) | xobjs=0(exp=0) | tables=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mmk2266/envTorch124/lib/python3.10/site-packages/camelot/parsers/base.py:238: UserWarning: No tables found in table area (6.0, 6.0, 606.0, 82.76528930664062)\n",
      "  cols, rows, v_s, h_s = self._generate_columns_and_rows(bbox, user_cols)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[p12] text=31 | figures=0 (with_caption=0) | xobjs=6(exp=6) | tables=1\n",
      "[done] wrote output/BLIP/BLIP.raw.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PosixPath('output/BLIP/BLIP.raw.json')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf = \"BLIP.pdf\"\n",
    "out = \"output\"\n",
    "extract_pdf(pdf, out, export_images=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997665aa-b5f8-49a9-b992-24acc71269d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parses all PDFs as JSONs and stores them in parsed_documents folder\n",
    "\n",
    "# pdf_folder = Path(\"../data/pdf\")     \n",
    "# out_dir = \"../data/parsed_documents\"\n",
    "\n",
    "# for pdf_path in pdf_folder.glob(\"*.pdf\"):\n",
    "#     print(f\"\\nProcessing {pdf_path.name} ...\")\n",
    "#     try:\n",
    "#         extract_pdf(str(pdf_path), out_dir, export_images=True)\n",
    "#     except Exception as e:\n",
    "#         print(f\"Failed on {pdf_path.name}: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch (CUDA 12.4)",
   "language": "python",
   "name": "envtorch124"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
