"C4
0.50
0.50"
"GitHub
0.53
0.47"
"Kaplan et al. (2020)
0.73
0.27"
"Table A2 | Estimated parameter and data scaling with increased training compute on two al-"
"ternate datasets. The listed values are the exponents, ğ‘ and ğ‘, on the relationship ğ‘ğ‘œğ‘ğ‘¡ âˆ ğ¶ğ‘ and"
"ğ·ğ‘œğ‘ğ‘¡ âˆ ğ¶ğ‘. Using IsoFLOP proï¬les, we estimate the scaling on two diï¬€erent datasets."
"D. Details on the scaling analyses"
"D.1. Approach 1: Fixing model sizes and varying training sequences"
"We use a maximum learning rate of 2 Ã— 10âˆ’4 for the smallest models and 1.25 Ã— 10âˆ’4 for the largest"
"models. In all cases, the learning rate drops by a factor of 10Ã— during training, using a cosine schedule."
"We make the assumption that the cosine cycle length should be approximately matched to the number"
"of training steps. We ï¬nd that when the cosine cycle overshoots the number of training steps by more"
"than 25%, performance is noticeably degradedâ€”see Figure A1.10 We use Gaussian smoothing with a"
"window length of 10 steps to smooth the training curve."
"D.2. Approach 3: Parametric ï¬tting of the loss"
"In this section, we ï¬rst show how Equation (2) can be derived. We repeat the equation below for"
"clarity,"
"ğ´ ğ‘
ğµ ğ·
(5)
,
ğ¿(ğ‘, ğ·) (cid:44) ğ¸ +"
"ğ›¼ +
ğ›½"
"based on a decomposition of
the expected risk between a function approximation term and an"
"optimisation suboptimality term. We then give details on the optimisation procedure for ï¬tting the"
"parameters."
"Formally, we consider the task of predicting the next token ğ‘¦ âˆˆ Y based on
Loss decomposition."
"the previous tokens in a sequence ğ‘¥ âˆˆ Y ğ‘ , with ğ‘  varying from 0 to ğ‘ maxâ€”the maximum sequence"
"length. We consider a distribution ğ‘ƒ âˆˆ D (X Ã— Y) of tokens in Y and their past in X. A predictor"
"ğ‘“
: X â†’ D (Y) computes the probability of each token given the past sequence. The Bayes classiï¬er,"
"ğ‘“ â˜…, minimizes the cross-entropy of
ğ‘“ (ğ‘¥) with the observed tokens ğ‘¦, with expectation taken on the"
"whole data distribution. We let ğ¿ be the expected risk"
