"","grande (Sakaguchi et al., 2020), SIQA (Sap et al., 2019),"
"","BoolQ (Clark et al., 2019), and TruthfulQA (Lin et al.,"
"","2021)."
"Motivation","We chose evaluations from Rae et al. (2021) to allow us to"
"","most directly compare to Gopher."
"Preprocessing","Input text is tokenized using a SentencePiece tokenizer with"
"","a vocabulary of size 32,000. Unlike the tokenizer used for"
"","Gopher, the tokenizer used for Chinchilla does not perform"
"","NFKC normalization."
