"6","Trends for compute-efﬁcient training .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
20"
"References",""
"[ACDE12]","Eduardo G Altmann, Giampaolo Cristadoro, and Mirko Degli Esposti. On the origin of long-"
"","range correlations in texts. Proceedings of
the National Academy of Sciences, 109(29):11582–"
"","11587, 2012. 25"
"[AS17]","Madhu S. Advani and Andrew M. Saxe. High-dimensional dynamics of generalization error in"
"","neural networks. arXiv, 2017, 1710.03667. 11, 18, 22"
"[BB01]","Michele Banko and Eric Brill. Scaling to very very large corpora for natural
language disam-"
"","biguation.
In Proceedings of the 39th annual meeting on association for computational linguis-"
"","tics, pages 26–33. Association for Computational Linguistics, 2001. 18"
"[BHMM18] Mikhail Belkin, Daniel Hsu, Siyuan Ma, and Soumik Mandal. Reconciling modern machine",""
"","learning and the bias-variance trade-off. arXiv, 2018, 1812.11118. 18"
"[Bia12]","GÃŠrard Biau. Analysis of a random forests model.
Journal of Machine Learning Research,"
"","13(Apr):1063–1095, 2012. 18"
"[CGRS19]","Rewon Child, Scott Gray, Alec Radford, and Ilya Sutskever. Generating long sequences with"
"","sparse transformers. CoRR, abs/1904.10509, 2019, 1904.10509. URL http://arxiv.org/"
"","abs/1904.10509. 19"
"[DCLT18]","Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. Bert: Pre-training of deep"
"","bidirectional transformers for language understanding, 2018, arXiv:1810.04805. 2"
"[DGV+18] Mostafa Dehghani, Stephan Gouws, Oriol Vinyals, Jakob Uszkoreit, and Lukasz Kaiser. Uni-",""
"","versal
transformers. CoRR, abs/1807.03819, 2018, 1807.03819. URL http://arxiv.org/"
"","abs/1807.03819. 6, 9, 23, 24"
"[EP94]","Werner Ebeling and Thorsten Pöschel. Entropy and long-range correlations in literary english."
"","EPL (Europhysics Letters), 26(4):241, 1994. 25"
"[Fou]","The Common Crawl Foundation. Common crawl. URL http://commoncrawl.org. 7"
"[GARD18]","Guy Gur-Ari, Daniel A. Roberts, and Ethan Dyer. Gradient descent happens in a tiny subspace."
"","2018, arXiv:1812.04754. 18"
"[GJS+19]","Mario Geiger, Arthur Jacot, Stefano Spigler, Franck Gabriel, Levent Sagun, Stéphane d’Ascoli,"
"","Giulio Biroli, Clément Hongler, and Matthieu Wyart. Scaling description of generalization with"
"","number of parameters in deep learning. arXiv, 2019, 1901.01608. 18"
"[GKX19]","Behrooz Ghorbani, Shankar Krishnan, and Ying Xiao.
An investigation into neural net op-"
"","timization via hessian eigenvalue density.
CoRR, abs/1901.10159, 2019, 1901.10159.
URL"
"","http://arxiv.org/abs/1901.10159. 18"
"[Goo01]","Joshua Goodman. A bit of progress in language modeling. CoRR, cs.CL/0108005, 2001. URL"
"","http://arxiv.org/abs/cs.CL/0108005. 18"
"[GRK17]","Scott Gray, Alec Radford, and Diederik P Kingma. Gpu kernels for block-sparse weights. ope-"
"","nai.com, 2017. 19"
"[HAD19]","Joel Hestness, Newsha Ardalani, and Gregory Diamos. Beyond human-level accuracy: Compu-"
"","the 24th Symposium on Principles and
tational challenges in deep learning.
In Proceedings of"
"","Practice of Parallel Programming, PPoPP ’19, pages 1–14, New York, NY, USA, 2019. ACM."
"","doi:10.1145/3293883.3295710. 18"
