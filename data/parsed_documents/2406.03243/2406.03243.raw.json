{
  "title": null,
  "authors": [],
  "source_path": "../data/pdf/2406.03243.pdf",
  "page_count": 19,
  "processed_pages": [
    1,
    2,
    3,
    4,
    5,
    6,
    7,
    8,
    9,
    10,
    11,
    12,
    13,
    14,
    15,
    16,
    17,
    18,
    19
  ],
  "counts": {
    "texts": 810,
    "pictures": 62,
    "tables": 29
  },
  "stats_per_page": [
    {
      "page": 1,
      "text_blocks": 11,
      "layout_blocks": 6,
      "xobjects_found": 0,
      "xobjects_exported": 0,
      "reused_exported": 0,
      "rasterized": 6,
      "tables_found": 1
    },
    {
      "page": 2,
      "text_blocks": 14,
      "layout_blocks": 5,
      "xobjects_found": 0,
      "xobjects_exported": 0,
      "reused_exported": 0,
      "rasterized": 5,
      "tables_found": 1
    },
    {
      "page": 3,
      "text_blocks": 45,
      "layout_blocks": 0,
      "xobjects_found": 0,
      "xobjects_exported": 0,
      "reused_exported": 0,
      "rasterized": 0,
      "tables_found": 2
    },
    {
      "page": 4,
      "text_blocks": 31,
      "layout_blocks": 0,
      "xobjects_found": 0,
      "xobjects_exported": 0,
      "reused_exported": 0,
      "rasterized": 0,
      "tables_found": 2
    },
    {
      "page": 5,
      "text_blocks": 31,
      "layout_blocks": 39,
      "xobjects_found": 0,
      "xobjects_exported": 0,
      "reused_exported": 0,
      "rasterized": 39,
      "tables_found": 1
    },
    {
      "page": 6,
      "text_blocks": 44,
      "layout_blocks": 4,
      "xobjects_found": 0,
      "xobjects_exported": 0,
      "reused_exported": 0,
      "rasterized": 4,
      "tables_found": 1
    },
    {
      "page": 7,
      "text_blocks": 11,
      "layout_blocks": 8,
      "xobjects_found": 0,
      "xobjects_exported": 0,
      "reused_exported": 0,
      "rasterized": 8,
      "tables_found": 1
    },
    {
      "page": 8,
      "text_blocks": 25,
      "layout_blocks": 0,
      "xobjects_found": 0,
      "xobjects_exported": 0,
      "reused_exported": 0,
      "rasterized": 0,
      "tables_found": 3
    },
    {
      "page": 9,
      "text_blocks": 20,
      "layout_blocks": 0,
      "xobjects_found": 0,
      "xobjects_exported": 0,
      "reused_exported": 0,
      "rasterized": 0,
      "tables_found": 2
    },
    {
      "page": 10,
      "text_blocks": 33,
      "layout_blocks": 0,
      "xobjects_found": 0,
      "xobjects_exported": 0,
      "reused_exported": 0,
      "rasterized": 0,
      "tables_found": 3
    },
    {
      "page": 11,
      "text_blocks": 242,
      "layout_blocks": 0,
      "xobjects_found": 0,
      "xobjects_exported": 0,
      "reused_exported": 0,
      "rasterized": 0,
      "tables_found": 3
    },
    {
      "page": 12,
      "text_blocks": 81,
      "layout_blocks": 0,
      "xobjects_found": 0,
      "xobjects_exported": 0,
      "reused_exported": 0,
      "rasterized": 0,
      "tables_found": 2
    },
    {
      "page": 13,
      "text_blocks": 115,
      "layout_blocks": 0,
      "xobjects_found": 0,
      "xobjects_exported": 0,
      "reused_exported": 0,
      "rasterized": 0,
      "tables_found": 1
    },
    {
      "page": 14,
      "text_blocks": 8,
      "layout_blocks": 0,
      "xobjects_found": 0,
      "xobjects_exported": 0,
      "reused_exported": 0,
      "rasterized": 0,
      "tables_found": 1
    },
    {
      "page": 15,
      "text_blocks": 22,
      "layout_blocks": 0,
      "xobjects_found": 0,
      "xobjects_exported": 0,
      "reused_exported": 0,
      "rasterized": 0,
      "tables_found": 1
    },
    {
      "page": 16,
      "text_blocks": 17,
      "layout_blocks": 0,
      "xobjects_found": 0,
      "xobjects_exported": 0,
      "reused_exported": 0,
      "rasterized": 0,
      "tables_found": 1
    },
    {
      "page": 17,
      "text_blocks": 22,
      "layout_blocks": 0,
      "xobjects_found": 0,
      "xobjects_exported": 0,
      "reused_exported": 0,
      "rasterized": 0,
      "tables_found": 1
    },
    {
      "page": 18,
      "text_blocks": 13,
      "layout_blocks": 0,
      "xobjects_found": 0,
      "xobjects_exported": 0,
      "reused_exported": 0,
      "rasterized": 0,
      "tables_found": 1
    },
    {
      "page": 19,
      "text_blocks": 25,
      "layout_blocks": 0,
      "xobjects_found": 0,
      "xobjects_exported": 0,
      "reused_exported": 0,
      "rasterized": 0,
      "tables_found": 1
    }
  ],
  "texts": [
    {
      "page_no": 1,
      "bbox": [
        102.8740005493164,
        124.39898681640625,
        509.12982177734375,
        138.74517822265625
      ],
      "text": "Llumnix: Dynamic Scheduling for Large Language Model Serving"
    },
    {
      "page_no": 1,
      "bbox": [
        79.76599884033203,
        164.8942108154297,
        532.235107421875,
        179.24647521972656
      ],
      "text": "Biao Sun∗†, Ziming Huang∗†, Hanyu Zhao∗, Wencong Xiao, Xinyi Zhang†, Yong Li, Wei Lin"
    },
    {
      "page_no": 1,
      "bbox": [
        270.23602294921875,
        194.97764587402344,
        341.76397705078125,
        206.93284606933594
      ],
      "text": "Alibaba Group"
    },
    {
      "page_no": 1,
      "bbox": [
        151.81802368164062,
        252.78717041015625,
        196.30331420898438,
        264.74237060546875
      ],
      "text": "Abstract"
    },
    {
      "page_no": 1,
      "bbox": [
        54.0,
        271.3904113769531,
        295.7752380371094,
        580.3980102539062
      ],
      "text": "Inference serving for large language models (LLMs) is the key\nto unleashing their potential in people’s daily lives. However,\nefficient LLM serving remains challenging today because the\nrequests are inherently heterogeneous and unpredictable in\nterms of resource and latency requirements, as a result of\nthe diverse applications and the dynamic execution nature of\nLLMs. Existing systems are fundamentally limited in han-\ndling these characteristics and cause problems such as severe\nqueuing delays, poor tail latencies, and SLO violations.\nWe introduce Llumnix, an LLM serving system that re-\nacts to such heterogeneous and unpredictable requests by\nruntime rescheduling across multiple model instances. Sim-\nilar to context switching across CPU cores in modern op-\nerating systems, Llumnix reschedules requests to improve\nload balancing and isolation, mitigate resource fragmenta-\ntion, and differentiate request priorities and SLOs. Llumnix\nimplements the rescheduling with an efficient and scalable\nlive migration mechanism for requests and their in-memory\nstates, and exploits it in a dynamic scheduling policy that\nunifies the multiple rescheduling scenarios elegantly. Our\nevaluations show that Llumnix improves tail latencies by\nan order of magnitude, accelerates high-priority requests\nby up to 1.5×, and delivers up to 36% cost savings while\nachieving similar tail latencies, compared against state-of-the-\nart LLM serving systems. Llumnix is publicly available at\nhttps://github.com/AlibabaPAI/llumnix."
    },
    {
      "page_no": 1,
      "bbox": [
        54.0,
        599.7831420898438,
        136.8136749267578,
        611.7383422851562
      ],
      "text": "1\nIntroduction"
    },
    {
      "page_no": 1,
      "bbox": [
        53.6510009765625,
        624.0654907226562,
        295.8587341308594,
        693.8680419921875
      ],
      "text": "Large language models (LLMs) such as the GPT series [15,\n49] are bringing generative AI to an unprecedented level.\nTheir human-level generation capabilities are being quickly\nadopted in a wide range of domains, inspiring many imagina-\ntions for future applications, and expected to have profound\ninfluences on how people live and work."
    },
    {
      "page_no": 1,
      "bbox": [
        64.85900115966797,
        702.5338745117188,
        219.33944702148438,
        721.9256591796875
      ],
      "text": "∗Equal contribution.\n†Work done during internship at Alibaba Group."
    },
    {
      "page_no": 1,
      "bbox": [
        317.52099609375,
        254.33230590820312,
        559.7481079101562,
        722.3828735351562
      ],
      "text": "Inference serving of LLMs plays a key role in LLM-\npowered services, becoming a critical workload in datacenters.\nSuch services are typically backed by multiple instances of\nthe LLM deployed on a GPU cluster. The system involves\na scheduler and an inference engine, where a request is first\ndispatched by the scheduler to a model serving instance, then\ngets executed by the inference engine inside. The requests are\ntypically batched for execution on each instance to increase\nthroughput and cost efficiency.\nWe observe unique characteristics of LLMs that call for\nnew design philosophy of the serving infrastructure. The first\nis workload heterogeneity. LLMs are designed to be universal,\nby learning as much knowledge as possible from whatever\ndomains. People can query the same LLM in totally different\nsituations or even build custom applications atop LLMs for\nvarious scenarios; for all of these, a context-specific input (i.e.,\nprompt) is all you need [15]. Such universality and application\ndiversity lead to heterogeneity of the inference requests, in\nterms of input lengths, output lengths, expected latencies, etc.\nFor instance, the task of summarizing long text can introduce\nsignificant input lengths, where the latency of returning the\nfirst token (word) is often important to user experience [38].\nThe second characteristic is execution unpredictability.\nServing an LLM request needs to run the model for multiple\niterations, each producing a single output token; however, it\nis not known a priori how many tokens will be generated\neventually. Moreover, the iterative generation also brings con-\nsiderable GPU memory consumption that dynamically grows\nwith the tokens. As such, the execution time and the resource\ndemand of a request are both unpredictable.\nThese characteristics make an LLM inherently a multi-\ntenant and dynamic environment, serving heterogeneous and\nunpredictable workloads on multiple instances. This behav-\nior is fundamentally different from traditional DNN models,\nwhere the requests are homogeneous and the execution is\none-shot, stateless, and deterministic. Instead, we find LLMs\nmore similar to modern operating systems hosting processes\nwith dynamic working sets and different priorities on multiple\ncores. Managing such systems has complex goals, which goes"
    },
    {
      "page_no": 1,
      "bbox": [
        303.5090026855469,
        742.3324584960938,
        308.49029541015625,
        752.2950439453125
      ],
      "text": "1"
    },
    {
      "page_no": 1,
      "bbox": [
        10.940000534057617,
        218.3599853515625,
        37.619998931884766,
        555.0
      ],
      "text": "arXiv:2406.03243v1  [cs.AR]  5 Jun 2024"
    },
    {
      "page_no": 2,
      "bbox": [
        53.64099884033203,
        74.45295715332031,
        295.8645324707031,
        722.4202880859375
      ],
      "text": "beyond what existing inference serving systems are designed\nfor. Although there has been a series of LLM-tailored infer-\nence engines that shows superior performance, such systems\nconcentrate on the sole goal of maximizing throughput within\na single instance [34,46,67]. The request scheduling across\ninstances, on the other hand, has received relatively little at-\ntention; the common practice today is still to use generic\nscheduling systems or policies inherited from the era of tradi-\ntional DNNs [4,28,35,47,53]. Such a clear gap introduces\nchallenges in the following aspects that are crucial in multi-\ntenant environments and online services.\nIsolation. The system can hardly provide performance isola-\ntion to requests as their memory consumption grows unpre-\ndictably. Memory contention incurs performance interference\nand even preemptions of certain requests in a batch [34], lead-\ning to highly unstable latencies and service-level objective\n(SLO) violations, significantly sacrificing user experiences.\nFragmentation. The varying request lengths and memory\ndemands inevitably result in memory fragmentation across\ninstances, which introduces conflicting scheduling objectives.\nThe running requests prefer load balancing to reduce preemp-\ntions and interference, but such load balancing fragments the\nfree memory space across instances at the same time. The\nfragmentation can cause long queuing delays of new requests\nthat instead require a large space on one instance for the in-\nput sequences. This conflict is difficult for the scheduler to\nreconcile with unpredictable arrivals and lengths of requests.\nPriorities. Requests from different applications and scenarios\nnaturally come with different latency objectives. Online chat-\nbots [6,8] are interactive applications and are therefore with\ntight SLO constraints. On the contrary, offline applications,\nsuch as evaluation [51], scoring [36], or data wrangling [43],\nare less sensitive to latency. Such different latency objectives\nare also a consequence of the commercial purpose of earn-\ning more profits from LLMs via diversified service classes\n(e.g., ChatGPT Plus [2]). However, existing LLM inference\nsystems [34,67] often treat all requests for a model equally\nand cannot differentiate their priorities, which has limitations\nin meeting different latency objectives of requests.\nWe introduce Llumnix, a new scheduling system for LLM\nserving that addresses the challenges above via runtime\nrescheduling of requests across model instances. Analogous\nto context switching across CPU cores in OS process man-\nagement, rescheduling enables Llumnix to react to the unpre-\ndictable workload dynamics at runtime, instead of having to\naddress all the complex scheduling concerns and tradeoffs\nwith the one-shot dispatching of requests. Llumnix resched-\nules requests for multiple purposes (Figure 1): load balancing\nfor reducing preemptions and interference, de-fragmentation\nfor mitigating queuing delays, prioritization of urgent requests\nby creating even higher degree of isolation, saturating or drain-\ning out instances during auto-scaling more quickly.\nLlumnix reschedules requests via an efficient and scalable\nlive migration mechanism of requests along with their GPU"
    },
    {
      "page_no": 2,
      "bbox": [
        323.542724609375,
        171.79701232910156,
        551.8816528320312,
        181.23875427246094
      ],
      "text": "(a) Load balancing\n(b) De-frag\n(d) Auto-scaling\n(c) Prioritization"
    },
    {
      "page_no": 2,
      "bbox": [
        351.39166259765625,
        72.7003173828125,
        463.6401062011719,
        80.04389953613281
      ],
      "text": "Normal instance\nTerminating instance"
    },
    {
      "page_no": 2,
      "bbox": [
        351.39166259765625,
        84.8665771484375,
        391.6060791015625,
        92.21015930175781
      ],
      "text": "Running request"
    },
    {
      "page_no": 2,
      "bbox": [
        412.721435546875,
        84.8665771484375,
        546.5571899414062,
        92.21015930175781
      ],
      "text": "Rescheduling destination\nHigh-priority request"
    },
    {
      "page_no": 2,
      "bbox": [
        495.54083251953125,
        72.7003173828125,
        536.345947265625,
        80.04389953613281
      ],
      "text": "Queuing request"
    },
    {
      "page_no": 2,
      "bbox": [
        329.60699462890625,
        191.4634552001953,
        546.273681640625,
        201.42605590820312
      ],
      "text": "Figure 1: Example rescheduling scenarios in Llumnix."
    },
    {
      "page_no": 2,
      "bbox": [
        317.8800048828125,
        228.8604278564453,
        559.65234375,
        419.99908447265625
      ],
      "text": "memory states across instances. Straightforward rescheduling\napproaches could introduce substantial downtimes to resched-\nuled requests, especially for long sequences. By contrast,\nLlumnix introduces near-zero downtime that is constant to\nsequence lengths, by carefully coordinating the computation\nand the memory transfer to hide the cost.\nTo exploit such great scheduling flexibility of migration,\nLlumnix adopts a distributed scheduling architecture that en-\nables continuous rescheduling with high scalability. Llumnix\nfurther introduces a dynamic scheduling policy under this\narchitecture that unifies all the rescheduling scenarios with\ndifferent goals elegantly. This unification is achieved via a\nconcept called virtual usage: Llumnix just needs to define a\nset of rules for setting the virtual usages of GPU memory for\nrequests in different scenarios, and then use a simple load-\nbalancing policy based on the virtual usages."
    },
    {
      "page_no": 2,
      "bbox": [
        317.8800048828125,
        423.83929443359375,
        559.6998901367188,
        543.3968505859375
      ],
      "text": "We have implemented Llumnix as a scheduling layer on\ntop of inference engines. Llumnix currently supports a repre-\nsentative system, vLLM [34], as the underlying engine. Eval-\nuation on a 16-GPU cluster using realistic workloads shows\nthat Llumnix improves P99 first-token latency by up to 15×\nand P99 per-token generation latency by up to 2×, compared\nagainst a state-of-the-art scheduler INFaaS [53]. Llumnix also\naccelerates high-priority requests by 1.5×, and achieves 36%\ncost saving when delivering similar tail latencies.\nIn summary, this paper makes the following contributions."
    },
    {
      "page_no": 2,
      "bbox": [
        319.3739929199219,
        562.9722900390625,
        559.65380859375,
        596.9200439453125
      ],
      "text": "• We reveal the unique characteristics and scheduling chal-\nlenges of LLM serving that necessitate new scheduling\ngoals such as isolation, de-fragmentation, and priorities."
    },
    {
      "page_no": 2,
      "bbox": [
        319.3739929199219,
        602.822265625,
        558.0042114257812,
        636.7710571289062
      ],
      "text": "• We propose request rescheduling as a key measure to\nachieve these goals and realize it with an efficient migration\nmechanism of requests and their GPU memory states."
    },
    {
      "page_no": 2,
      "bbox": [
        319.3739929199219,
        642.6732788085938,
        559.6552734375,
        676.6210327148438
      ],
      "text": "• We design a distributed scheduling architecture and an\naccompanying scheduling policy that exploit request mi-\ngration to achieve the multiple goals in a unified manner."
    },
    {
      "page_no": 2,
      "bbox": [
        319.3739929199219,
        682.5984497070312,
        558.0036010742188,
        704.5170288085938
      ],
      "text": "• We implement and evaluate Llumnix to show its advantages\nover state-of-the-art inference serving systems."
    },
    {
      "page_no": 2,
      "bbox": [
        303.50897216796875,
        742.3324584960938,
        308.4902648925781,
        752.2950439453125
      ],
      "text": "2"
    },
    {
      "page_no": 3,
      "bbox": [
        113.9819107055664,
        131.46018981933594,
        125.42462158203125,
        139.27513122558594
      ],
      "text": "GPU"
    },
    {
      "page_no": 3,
      "bbox": [
        100.02642059326172,
        93.74028015136719,
        139.0767822265625,
        101.55521392822266
      ],
      "text": "Request queue"
    },
    {
      "page_no": 3,
      "bbox": [
        105.65276336669922,
        70.18666076660156,
        133.5740203857422,
        78.00159454345703
      ],
      "text": "Iteration N"
    },
    {
      "page_no": 3,
      "bbox": [
        91.3990249633789,
        143.7490692138672,
        274.2174072265625,
        151.5640106201172
      ],
      "text": "Running req block\nFree block\nPreempted/queuing req"
    },
    {
      "page_no": 3,
      "bbox": [
        222.72787475585938,
        131.46018981933594,
        234.1705780029297,
        139.27513122558594
      ],
      "text": "GPU"
    },
    {
      "page_no": 3,
      "bbox": [
        208.77239990234375,
        93.74028015136719,
        247.8227996826172,
        101.55521392822266
      ],
      "text": "Request queue"
    },
    {
      "page_no": 3,
      "bbox": [
        211.02633666992188,
        70.18666076660156,
        245.3902587890625,
        78.00159454345703
      ],
      "text": "Iteration N+1"
    },
    {
      "page_no": 3,
      "bbox": [
        146.68185424804688,
        112.84487915039062,
        156.6112060546875,
        118.92315673828125
      ],
      "text": "Alloc"
    },
    {
      "page_no": 3,
      "bbox": [
        146.55386352539062,
        122.14688110351562,
        156.48321533203125,
        128.22515869140625
      ],
      "text": "Alloc"
    },
    {
      "page_no": 3,
      "bbox": [
        96.40328216552734,
        101.83612060546875,
        113.85358428955078,
        107.91439819335938
      ],
      "text": "Preempt"
    },
    {
      "page_no": 3,
      "bbox": [
        248.60226440429688,
        82.89083862304688,
        271.124267578125,
        88.9691162109375
      ],
      "text": "Preempted"
    },
    {
      "page_no": 3,
      "bbox": [
        252.12603759765625,
        88.94992065429688,
        267.58807373046875,
        95.0281982421875
      ],
      "text": "request"
    },
    {
      "page_no": 3,
      "bbox": [
        54.0,
        162.0760498046875,
        294.11578369140625,
        183.98709106445312
      ],
      "text": "Figure 2: Request queuing and preemption using continuous\nbatching and dynamic memory allocation."
    },
    {
      "page_no": 3,
      "bbox": [
        54.0,
        207.77117919921875,
        134.82911682128906,
        219.72637939453125
      ],
      "text": "2\nBackground"
    },
    {
      "page_no": 3,
      "bbox": [
        53.64099884033203,
        233.38746643066406,
        295.774658203125,
        700.5288696289062
      ],
      "text": "Application diversity of LLMs.\nRecent LLMs are becom-\ning task-agnostic. That is, the same model can work for vari-\nous tasks with context-specific inputs (a.k.a. the “prompts”)\nprovided. This is achieved by both increasingly larger model\nand dataset sizes and advanced pre-training approaches such\nas few-shot learning [14]. Task-agnostic models enable di-\nverse applications, from chatbots, search engines, summariza-\ntion, coding, AI assistants, to AI agents, to name a few.\nThe diverse applications lead to requests with different\nrequirements for the serving. An important aspect is the se-\nquence lengths. LLMs are racing to support longer sequence\nlengths — for example, from March to November 2023, the\nmaximum sequence lengths of the GPT family have scaled\nfrom 32k 1 (GPT-4 [49]) to 128k (GPT-4 Turbo [50]). We\nexpect this trend to continue as longer sequences are neces-\nsary for broader applications of LLMs. Consider an intuitive\nexample of the tasks for summarizing and writing an article:\nthey require sufficiently long input and output lengths, respec-\ntively. Another aspect is expected latencies. A real product\nexample is that OpenAI introduces a subscription plan called\nChatGPT Plus [2] to offer faster responses of common Chat-\nGPT services. In general, different applications and situations\nalso naturally have different levels of urgency. For example,\nmore interactive applications like personal assistants expect\nshorter latencies than tasks like summarizing an article.\nAutoregressive generation.\nThe inference for state-of-the-\nart LLMs is autoregressive: the model iteratively accepts the\ninput sequence plus all the previous output tokens to generate\nthe next output token, until an “end-of-sequence” (EOS) token\nis generated. The phase for generating the first token and that\nfor each new token afterwards are usually referred to as prefill\nand decode, respectively. LLM services typically return the\ngenerated tokens in a streaming manner. Therefore, the prefill\nand decode latencies are both user-perceivable and important\nto user experiences. The prefill latency determines how long it\ntakes to start receiving the response, which can be dominated\nby the queuing delay. The decode latency determines the\nspeed of receiving the following tokens subsequently.\nDuring the autoregression, the intermediate results (key and"
    },
    {
      "page_no": 3,
      "bbox": [
        64.85900115966797,
        712.5736694335938,
        279.3699951171875,
        721.9256591796875
      ],
      "text": "11k stands for 1,024 when describing sequence length in this paper."
    },
    {
      "page_no": 3,
      "bbox": [
        347.7005615234375,
        145.81463623046875,
        439.25787353515625,
        157.8812713623047
      ],
      "text": "0\n1000\n2000\n3000\n4000\nTime (s)"
    },
    {
      "page_no": 3,
      "bbox": [
        337.98382568359375,
        137.81948852539062,
        341.0145568847656,
        143.3710479736328
      ],
      "text": "0"
    },
    {
      "page_no": 3,
      "bbox": [
        334.953369140625,
        125.78052520751953,
        341.01483154296875,
        131.33209228515625
      ],
      "text": "20"
    },
    {
      "page_no": 3,
      "bbox": [
        334.953369140625,
        113.74156951904297,
        341.01483154296875,
        119.29314422607422
      ],
      "text": "40"
    },
    {
      "page_no": 3,
      "bbox": [
        334.953369140625,
        101.7026138305664,
        341.01483154296875,
        107.25418853759766
      ],
      "text": "60"
    },
    {
      "page_no": 3,
      "bbox": [
        334.953369140625,
        89.66365814208984,
        341.01483154296875,
        95.2152328491211
      ],
      "text": "80"
    },
    {
      "page_no": 3,
      "bbox": [
        331.9229431152344,
        77.62470245361328,
        341.01513671875,
        83.17627716064453
      ],
      "text": "100"
    },
    {
      "page_no": 3,
      "bbox": [
        326.50567626953125,
        87.52535247802734,
        332.0572509765625,
        133.02920532226562
      ],
      "text": "Memory Usage (%)"
    },
    {
      "page_no": 3,
      "bbox": [
        346.6766052246094,
        103.00846099853516,
        408.0885314941406,
        108.5600357055664
      ],
      "text": "Average Memory: 62.84%"
    },
    {
      "page_no": 3,
      "bbox": [
        361.9815673828125,
        80.72065734863281,
        381.3620300292969,
        86.27223205566406
      ],
      "text": "Memory"
    },
    {
      "page_no": 3,
      "bbox": [
        484.55682373046875,
        140.66961669921875,
        545.647705078125,
        151.3662109375
      ],
      "text": "P50\nP80\nP95\nP99\n0"
    },
    {
      "page_no": 3,
      "bbox": [
        481.5263671875,
        127.96825408935547,
        487.58782958984375,
        133.5198211669922
      ],
      "text": "50"
    },
    {
      "page_no": 3,
      "bbox": [
        478.4959411621094,
        115.26689910888672,
        487.588134765625,
        120.81847381591797
      ],
      "text": "100"
    },
    {
      "page_no": 3,
      "bbox": [
        478.4959411621094,
        102.56554412841797,
        487.588134765625,
        108.11711883544922
      ],
      "text": "150"
    },
    {
      "page_no": 3,
      "bbox": [
        478.4959411621094,
        89.86418914794922,
        487.588134765625,
        95.41576385498047
      ],
      "text": "200"
    },
    {
      "page_no": 3,
      "bbox": [
        478.4959411621094,
        77.16283416748047,
        487.588134765625,
        82.71440887451172
      ],
      "text": "250"
    },
    {
      "page_no": 3,
      "bbox": [
        471.1725769042969,
        82.7475357055664,
        476.7241516113281,
        137.80194091796875
      ],
      "text": "Per-token Latency (ms)"
    },
    {
      "page_no": 3,
      "bbox": [
        506.7914123535156,
        80.3770751953125,
        544.5975952148438,
        91.67262268066406
      ],
      "text": "Decode Inference\nPreemption Loss"
    },
    {
      "page_no": 3,
      "bbox": [
        454.7333679199219,
        139.15313720703125,
        457.76409912109375,
        144.7047119140625
      ],
      "text": "0"
    },
    {
      "page_no": 3,
      "bbox": [
        454.7333679199219,
        117.64295196533203,
        457.76409912109375,
        123.19452667236328
      ],
      "text": "5"
    },
    {
      "page_no": 3,
      "bbox": [
        454.7333679199219,
        96.13275909423828,
        460.7948303222656,
        101.68433380126953
      ],
      "text": "10"
    },
    {
      "page_no": 3,
      "bbox": [
        454.7333679199219,
        74.62255859375,
        460.7948303222656,
        80.17413330078125
      ],
      "text": "15"
    },
    {
      "page_no": 3,
      "bbox": [
        462.3685607910156,
        85.51663208007812,
        467.9201354980469,
        135.0283966064453
      ],
      "text": "Preempted Ratio (%)"
    },
    {
      "page_no": 3,
      "bbox": [
        421.09332275390625,
        133.58123779296875,
        447.0924987792969,
        139.13279724121094
      ],
      "text": "Preempted"
    },
    {
      "page_no": 3,
      "bbox": [
        329.3280029296875,
        171.9534454345703,
        546.5526123046875,
        181.91604614257812
      ],
      "text": "Figure 3: Request preemptions in LLaMA-7B serving."
    },
    {
      "page_no": 3,
      "bbox": [
        317.13299560546875,
        205.49630737304688,
        559.7423706054688,
        562.3050537109375
      ],
      "text": "value tensors used in the attention operation [59]) for each\ntoken are involved in the generation of all following tokens.\nTherefore, the inference engine typically stores these states\nin GPU memory for reuse, known as the KV cache [52].\nBatching and memory management.\nState-of-the-art infer-\nence engines apply the continuous batching technique [34,67]\nto handle the varying sequence lengths and dynamic arrivals\nof requests. That is, a new/completed request can join/leave\nthe running batch immediately, instead of waiting for all the\nrunning requests to complete. Batching also raises concern\nabout memory management of KV cache. Since the memory\ndemand of KV cache is not known a priori, it would clearly\nlimit the batch size and batching benefits if the memory is\nreserved to the maximum length. For example, a LLaMA-2-\n13B [58] model supports sequence lengths up to 4k, which\ntranslates to 3.2 GB KV cache for a single request; while the\nmemory of current GPUs remain tens of GBs, let alone the\nspace for model weights (26 GB for LLaMA-2-13B). There-\nfore, recent work (vLLM [34]) proposed dynamic memory\nallocation for KV cache to increase batch size and throughput,\nenabled by a technique named PagedAttention: the KV cache\ntensors are stored in dynamically allocated blocks as the KV\ncache grows. Figure 2 presents an example of using continu-\nous batching with dynamic memory allocation. The running\nrequests are chosen based on the free memory blocks, hence\nthere is a queuing request (the gray one) at iteration N as the\nmemory is insufficient. At the next iteration, the system runs\nout of memory for the new blocks of the running requests.\nTherefore, the system preempts certain running requests (the\nblue one), which then goes back to the queue."
    },
    {
      "page_no": 3,
      "bbox": [
        317.8800048828125,
        580.754150390625,
        392.02618408203125,
        592.7093505859375
      ],
      "text": "3\nMotivation"
    },
    {
      "page_no": 3,
      "bbox": [
        317.4119873046875,
        604.7916259765625,
        559.6557006835938,
        722.4310302734375
      ],
      "text": "We motivate the design of Llumnix with a series of key char-\nacteristics of LLM serving as follows.\nUnpredictable memory demands and preemptions.\nWith\ndynamic memory allocation, request preemptions are in-\nevitable as a result of the unpredictable memory demands,\nwhich can significantly increase the latencies of the preempted\nrequests. Figure 3 shows an experiment of LLaMA-7B model\nserving using vLLM on an A10 GPU running a trace of 2,000\nrequests generated from a Poisson distribution. The input and\noutput lengths follow a power-law distribution with a mean"
    },
    {
      "page_no": 3,
      "bbox": [
        303.5090026855469,
        742.3324584960938,
        308.49029541015625,
        752.2950439453125
      ],
      "text": "3"
    },
    {
      "page_no": 4,
      "bbox": [
        115.96876525878906,
        171.76126098632812,
        254.28701782226562,
        186.5296630859375
      ],
      "text": "64\n128\n256\n512\n1k\n2k\n4k\n8k\nTotal Batched Tokens"
    },
    {
      "page_no": 4,
      "bbox": [
        105.60549926757812,
        165.92587280273438,
        109.04289245605469,
        172.22235107421875
      ],
      "text": "0"
    },
    {
      "page_no": 4,
      "bbox": [
        102.16844177246094,
        151.4995574951172,
        109.04322814941406,
        157.79603576660156
      ],
      "text": "20"
    },
    {
      "page_no": 4,
      "bbox": [
        102.16844177246094,
        137.0732421875,
        109.04322814941406,
        143.36972045898438
      ],
      "text": "40"
    },
    {
      "page_no": 4,
      "bbox": [
        102.16844177246094,
        122.64694213867188,
        109.04322814941406,
        128.94342041015625
      ],
      "text": "60"
    },
    {
      "page_no": 4,
      "bbox": [
        102.16844177246094,
        108.22062683105469,
        109.04322814941406,
        114.51710510253906
      ],
      "text": "80"
    },
    {
      "page_no": 4,
      "bbox": [
        98.73139190673828,
        93.79431915283203,
        109.04356384277344,
        100.0907974243164
      ],
      "text": "100"
    },
    {
      "page_no": 4,
      "bbox": [
        98.73139190673828,
        79.36800384521484,
        109.04356384277344,
        85.66448211669922
      ],
      "text": "120"
    },
    {
      "page_no": 4,
      "bbox": [
        89.19317626953125,
        86.04088592529297,
        96.74894714355469,
        155.18429565429688
      ],
      "text": "Decode Latency (ms)"
    },
    {
      "page_no": 4,
      "bbox": [
        133.60826110839844,
        76.65616607666016,
        176.740478515625,
        101.02934265136719
      ],
      "text": "7B(seq=64)\n7B(seq=256)\n7B(seq=1024)"
    },
    {
      "page_no": 4,
      "bbox": [
        205.2982177734375,
        76.65616607666016,
        252.21156311035156,
        101.02934265136719
      ],
      "text": "30B(seq=64)\n30B(seq=256)\n30B(seq=1024)"
    },
    {
      "page_no": 4,
      "bbox": [
        54.0,
        196.19827270507812,
        294.1197814941406,
        218.1668701171875
      ],
      "text": "Figure 4: Latencies of one decode step of LLaMA-7B and\nLLaMA-30B with different sequence lengths and batch sizes."
    },
    {
      "page_no": 4,
      "bbox": [
        53.750999450683594,
        243.87332153320312,
        295.86669921875,
        722.4190673828125
      ],
      "text": "value of 256 tokens (details in §6). We control the request\nrate (0.42 req/s) to get a moderate memory load (62% on av-\nerage) with some spikes due to the varying sequence lengths.\nUnder such load, we still observe 8% of the requests being\npreempted. We quantify the preemption loss by measuring\nthe latency penalty caused by preemption, including the extra\nqueuing time and the recomputing for previous KV cache. We\nshow different percentiles of per-token decode latency (aver-\naged across all decode iterations of a request). We do not use\nthe end-to-end latency because it depends on the number of\niterations. We observe that the P99 per-token decode latency\nis much worse than the P50 (3.8×), and the preemption loss\naccounts for 70% for the P99 request. In particular, the P99\nrequest experiences a total preemption loss of 50 seconds (pre-\nempted twice), showing severe service stalls and degradation\nof user experiences due to preemptions.\nPerformance interference among requests.\nWe also ob-\nserve performance interference of requests in a batch to each\nother, due to resource competition on GPU compute and mem-\nory bandwidth resources. Figure 4 shows the times for a de-\ncode step of LLaMA-7B (1-GPU) and LLaMA-30B (4-GPU)\nusing different sequence lengths and batch sizes (the X-axis\nshows the total number of tokens in a batch for each data\npoint). The decode speed decreases with more requests and\nhigher interference, and the gap between the same sequence\nlength is up to 2.6×.\nMemory fragmentation.\nConsidering the aforementioned\nproblems, it would be better to spread requests across in-\nstances to reduce preemptions and interference. However,\nsuch spreading will make the available memory of the cluster\nfragmented across instances simultaneously. Here fragmenta-\ntion refers to external fragmentation, i.e., unallocated memory\non an instance. Dynamic allocation techniques like PagedAt-\ntention [34] can eliminate external fragmentation during the\ndecode phase, where the blocks are allocated one at a time.\nHowever, external fragmentation remains a significant prob-\nlem for the prefill phase, which requires many blocks on an\ninstance in one allocation to accommodate the KV cache of\nall tokens in the inputs. Therefore, external fragmentation can\ncause long queuing delays of new requests, especially those"
    },
    {
      "page_no": 4,
      "bbox": [
        377.44219970703125,
        168.49073791503906,
        522.3900756835938,
        182.1019287109375
      ],
      "text": "400\n450\n500\n550\n600\n650\n700\nTime (s)"
    },
    {
      "page_no": 4,
      "bbox": [
        368.76776123046875,
        163.1125946044922,
        371.935791015625,
        168.9156951904297
      ],
      "text": "0"
    },
    {
      "page_no": 4,
      "bbox": [
        362.43231201171875,
        152.0662841796875,
        371.9364318847656,
        157.869384765625
      ],
      "text": "250"
    },
    {
      "page_no": 4,
      "bbox": [
        362.43231201171875,
        141.0199737548828,
        371.9364318847656,
        146.8230743408203
      ],
      "text": "500"
    },
    {
      "page_no": 4,
      "bbox": [
        362.43231201171875,
        129.97366333007812,
        371.9364318847656,
        135.77676391601562
      ],
      "text": "750"
    },
    {
      "page_no": 4,
      "bbox": [
        359.26458740234375,
        118.92735290527344,
        371.9367370605469,
        124.7304458618164
      ],
      "text": "1000"
    },
    {
      "page_no": 4,
      "bbox": [
        359.26458740234375,
        107.88104248046875,
        371.9367370605469,
        113.68413543701172
      ],
      "text": "1250"
    },
    {
      "page_no": 4,
      "bbox": [
        359.26458740234375,
        96.8347396850586,
        371.9367370605469,
        102.63783264160156
      ],
      "text": "1500"
    },
    {
      "page_no": 4,
      "bbox": [
        359.26458740234375,
        85.78842163085938,
        371.9367370605469,
        91.59151458740234
      ],
      "text": "1750"
    },
    {
      "page_no": 4,
      "bbox": [
        359.26458740234375,
        74.74211883544922,
        371.9367370605469,
        80.54521179199219
      ],
      "text": "2000"
    },
    {
      "page_no": 4,
      "bbox": [
        350.4737548828125,
        100.19557189941406,
        357.4374694824219,
        143.12554931640625
      ],
      "text": "Num of Blocks"
    },
    {
      "page_no": 4,
      "bbox": [
        395.1472473144531,
        81.11649322509766,
        421.0893249511719,
        94.22794342041016
      ],
      "text": "Instance 0\nInstance 1"
    },
    {
      "page_no": 4,
      "bbox": [
        445.01373291015625,
        81.11649322509766,
        470.955810546875,
        94.22794342041016
      ],
      "text": "Instance 2\nInstance 3"
    },
    {
      "page_no": 4,
      "bbox": [
        494.88018798828125,
        81.11649322509766,
        518.6778564453125,
        86.91958618164062
      ],
      "text": "Total Free"
    },
    {
      "page_no": 4,
      "bbox": [
        317.8800048828125,
        196.3135986328125,
        558.0003662109375,
        218.21609497070312
      ],
      "text": "Figure 5: Total free memory vs. demands of the head-of-line\nqueuing requests across four LLaMA-7B instances."
    },
    {
      "page_no": 4,
      "bbox": [
        317.52099609375,
        243.5144805908203,
        384.7784423828125,
        253.47708129882812
      ],
      "text": "with long inputs."
    },
    {
      "page_no": 4,
      "bbox": [
        317.52099609375,
        256.2873229980469,
        559.6553955078125,
        722.4070434570312
      ],
      "text": "Figure 5 shows an experiment of four LLaMA-7B in-\nstances, where the trace also uses the input/output length\ndistribution with mean value 256 and a Poisson distribution\nwith a request rate of 1.9 req/s. We implement a spreading dis-\npatching policy that dispatches new requests to the instance\nwith the lowest memory load for load balancing. We demon-\nstrate the fragmentation by showing the total free memory\nblocks across the cluster, against the demand of the head-of-\nline queuing request on each instance. For most of the time\nspan, the total free memory can accommodate the queuing re-\nquests on at least three instances (sometimes all of them). The\nrequest are queuing despite enough total memory because\nthey exceed the free space on their own instances, which\ndemonstrates the fragmentation and also the potential of de-\nfragmentation to reduce queuing delays.\nDifferent emergency and priorities of requests.\nWith\nrequirements of products like ChatGPT Plus and the diverse\napplication scenarios of LLMs, we foresee more applications\nwith different latency sensitivities. However, existing systems\nusually treat all requests equally, where the latency-sensitive\ncould easily be interfered by other normal ones, e.g., excessive\nqueuing delays or performance interference. This calls for a\nsystematic approach to differentiating the request priorities\nfor an LLM to meet their respective latency objectives.\nOpportunity: request rescheduling across instances.\nThis\npaper explores a new dimension that is missing in current\nLLM serving systems: the multiple model instances of a de-\nployment and their interaction. A simple intuition is that when\nthe aforementioned problems occur on a certain instance, it\nis possible that the whole cluster still has enough space for\navoiding preempting requests, accommodating new requests,\nor mitigating interference. This is also a natural consequence\nof the varying request lengths and memory loads across in-\nstances. However, existing systems cannot exploit such free\nspace on other instances because requests are tied on the same\ninstance once scheduled throughout the autoregressive exe-\ncution. Llumnix unifies the request scheduling component\nand the model inference engine to explore the potentials of\nfine-grained coordination among inference instances."
    },
    {
      "page_no": 4,
      "bbox": [
        303.5090026855469,
        742.3324584960938,
        308.49029541015625,
        752.2950439453125
      ],
      "text": "4"
    },
    {
      "page_no": 5,
      "bbox": [
        54.0,
        72.78716278076172,
        153.31185913085938,
        84.74236297607422
      ],
      "text": "4\nLlumnix Design"
    },
    {
      "page_no": 5,
      "bbox": [
        54.0,
        99.64318084716797,
        129.79595947265625,
        111.59838104248047
      ],
      "text": "4.1\nOverview"
    },
    {
      "page_no": 5,
      "bbox": [
        53.64099884033203,
        122.46530151367188,
        295.8623046875,
        722.4070434570312
      ],
      "text": "Llumnix builds upon the key idea of rescheduling LLM in-\nference requests at runtime across model instances. Llumnix\ninherits continuous batching [67] and dynamic memory allo-\ncation [34] from state-of-the-art systems for high throughput.\nBeyond that, Llumnix exploits request rescheduling to react\nto the unpredictable workload dynamics in various situations\nwith different scheduling goals, as illustrated in Figure 1.\nA first goal is load balancing (Figure 1-a) to reduce re-\nquest preemptions and interference on high-load instances.\nAlthough the dispatching can also consider load balancing of\nmemory usage, it could be sub-optimal as the final memory\nusages of requests are unknown at the arrivals, due to the un-\npredictability of output lengths. Rescheduling complements it\nby reacting to the real usage growths of requests. Meanwhile,\nas shown before, load balancing can also lead to higher mem-\nory fragmentation and longer queuing delays of long inputs\nprobably. Therefore, Llumnix also reschedules requests for\nde-fragmentation (1-b), i.e., creating contiguous space on an\ninstance by moving requests onto others. Although these two\ngoals remain a tradeoff, Llumnix has a much larger space\nto balance them with rescheduling. Another goal is prioriti-\nzation (1-c) of certain requests by rescheduling co-located\nrequests away for lower load and avoiding interference. Such\nrescheduling provides “decicated” resources to high-priority\nrequests dynamically, without the need for reserving machines\nstatically. Finally, Llumnix also reschedules requests during\nauto-scaling, e.g., to drain out an instance to be terminated\n(1-d) or saturate a new instance more quickly.\nRealizing such highly dynamic rescheduling efficiently is\nchallenging, considering the large request context states (i.e.,\nthe KV cache). Naïve solutions include recomputing or copy-\ning the KV cache of the rescheduled requests, however with\nhigh computation stalls and downtime, reaching over 50× of\nthe decoding cost (§6.2). What’s more, the KV cache states\nincrease with sequence lengths, limiting the scheduling flexi-\nbility under the trend of growing context lengths [50]. Such\na high inference delay in generating next tokens greatly de-\ngrades the user experiences of LLM serving and thus prohibits\nrequest rescheduling. Llumnix addresses this challenge with\na live migration mechanism that pipelines and coordinates\nthe KV cache copying and the token generation computation,\nthereby bringing negligible downtime (§4.2).\nTo exploit the benefits of migration, Llumnix adopts a scal-\nable architecture that combines global and local scheduling to\ndecentralize the scheduling decisions and the coordinated mi-\ngration actions, facilitating continuous rescheduling at scale\n(§4.3). Under this architecture, we further design an efficient\nheuristic scheduling policy that centers around the virtual\nusage concept to abstract the requirements of the different\nscheduling goals in a unified manner (§4.4)."
    },
    {
      "page_no": 5,
      "bbox": [
        327.114990234375,
        151.90179443359375,
        346.90570068359375,
        158.3677215576172
      ],
      "text": "Compute"
    },
    {
      "page_no": 5,
      "bbox": [
        395.56549072265625,
        85.80802154541016,
        409.84356689453125,
        91.55551147460938
      ],
      "text": "Stage-0"
    },
    {
      "page_no": 5,
      "bbox": [
        326.1249694824219,
        96.61575317382812,
        345.9156799316406,
        103.08168029785156
      ],
      "text": "Compute"
    },
    {
      "page_no": 5,
      "bbox": [
        329.6162414550781,
        113.06741333007812,
        341.019775390625,
        119.53334045410156
      ],
      "text": "Mem"
    },
    {
      "page_no": 5,
      "bbox": [
        539.6980590820312,
        123.65863037109375,
        550.3543701171875,
        130.1245574951172
      ],
      "text": "Time"
    },
    {
      "page_no": 5,
      "bbox": [
        412.6298828125,
        95.4154052734375,
        416.2838439941406,
        101.88133239746094
      ],
      "text": "…"
    },
    {
      "page_no": 5,
      "bbox": [
        412.6970520019531,
        111.79647827148438,
        416.35101318359375,
        118.26240539550781
      ],
      "text": "…"
    },
    {
      "page_no": 5,
      "bbox": [
        449.1380615234375,
        85.80802154541016,
        463.41619873046875,
        91.55551147460938
      ],
      "text": "Stage-1"
    },
    {
      "page_no": 5,
      "bbox": [
        495.96563720703125,
        70.7685317993164,
        515.9025268554688,
        76.51602172851562
      ],
      "text": "Downtime"
    },
    {
      "page_no": 5,
      "bbox": [
        491.0204772949219,
        185.93016052246094,
        531.1508178710938,
        191.67764282226562
      ],
      "text": "Migration completed"
    },
    {
      "page_no": 5,
      "bbox": [
        329.57379150390625,
        168.5653076171875,
        340.9773254394531,
        175.03123474121094
      ],
      "text": "Mem"
    },
    {
      "page_no": 5,
      "bbox": [
        539.5135498046875,
        178.87408447265625,
        550.1698608398438,
        185.3400115966797
      ],
      "text": "Time"
    },
    {
      "page_no": 5,
      "bbox": [
        426.8083801269531,
        167.29437255859375,
        430.46234130859375,
        173.7602996826172
      ],
      "text": "…"
    },
    {
      "page_no": 5,
      "bbox": [
        403.6104736328125,
        142.79339599609375,
        407.2644348144531,
        149.2593231201172
      ],
      "text": "…"
    },
    {
      "page_no": 5,
      "bbox": [
        322.59912109375,
        79.59921264648438,
        356.40924072265625,
        86.06513977050781
      ],
      "text": "Source instance"
    },
    {
      "page_no": 5,
      "bbox": [
        477.63421630859375,
        95.27420043945312,
        481.2881774902344,
        101.74012756347656
      ],
      "text": "…"
    },
    {
      "page_no": 5,
      "bbox": [
        486.53118896484375,
        85.66678619384766,
        501.463623046875,
        91.41427612304688
      ],
      "text": "Stage-N"
    },
    {
      "page_no": 5,
      "bbox": [
        322.65191650390625,
        186.0054931640625,
        366.546630859375,
        192.47142028808594
      ],
      "text": "Destination instance"
    },
    {
      "page_no": 5,
      "bbox": [
        456.633544921875,
        142.7227783203125,
        460.2875061035156,
        149.18870544433594
      ],
      "text": "…"
    },
    {
      "page_no": 5,
      "bbox": [
        525.202880859375,
        87.5732192993164,
        549.6755981445312,
        98.89874267578125
      ],
      "text": "Decoding \ncomputation"
    },
    {
      "page_no": 5,
      "bbox": [
        525.172119140625,
        100.21204376220703,
        546.4873046875,
        111.60818481445312
      ],
      "text": "Generated \nKV cache"
    },
    {
      "page_no": 5,
      "bbox": [
        515.6480712890625,
        80.23468017578125,
        531.2118530273438,
        86.70060729980469
      ],
      "text": "Legend"
    },
    {
      "page_no": 5,
      "bbox": [
        525.0128784179688,
        114.05121612548828,
        552.8436889648438,
        119.7987060546875
      ],
      "text": "Copy KV cache"
    },
    {
      "page_no": 5,
      "bbox": [
        350.1988830566406,
        130.50291442871094,
        385.71728515625,
        136.25039672851562
      ],
      "text": "Migration initiated"
    },
    {
      "page_no": 5,
      "bbox": [
        317.8800048828125,
        206.7113800048828,
        557.9998168945312,
        228.55307006835938
      ],
      "text": "Figure 6: Llumnix adopts multi-stage migration to overlap the\ncomputation and KV cache copying for minimal downtime."
    },
    {
      "page_no": 5,
      "bbox": [
        317.8800048828125,
        255.0621337890625,
        513.8974609375,
        267.017333984375
      ],
      "text": "4.2\nLive Migration of LLM Requests"
    },
    {
      "page_no": 5,
      "bbox": [
        317.52099609375,
        279.6742858886719,
        559.7434692382812,
        722.4310302734375
      ],
      "text": "The significant KV cache states of requests can potentially\nintroduce great cost and serving stalls during rescheduling.\nLlumnix addresses this challenge by exploiting a key char-\nacteristic of LLM inference: the KV cache is append-only.\nLLM inference iteratively concatenates the output token of\nthe current iteration with the input tokens, which is set as\nthe input for the next iteration. In this way, inference engines\nalso keep appending the calculated KV state of the current\niteration to the KV cache parameters, leaving the parameters\ngenerated by previous iterations remain constant.\nThe live migration mechanism of Llumnix utilizes the in-\nherent append-only characteristic of KV cache to pipeline the\nKV cache copying with the decoding computation. Because\nthe KV cache already generated won’t be modified in the\nfollowing iterations, Llumnix can safely copy the KV cache\nof previous tokens in parallel with the computation for new\ntokens. In this way, Llumnix achieves near-zero and constant\ndowntime to the rescheduled request. As shown in Figure 6,\nwhen migration is initiated, the source instance starts to copy\nthe KV cache blocks of completed iterations, and continues\nthe computation at the same time (stage 0). When the copying\nfor the previous KV cache blocks is done, there will be a few\nmore iterations (i.e., blocks in Figure 6) computed in stage 0.\nThen, it switches to stage 1 to copy the KV cache generated\nby stage 0, while continuing the computation afterwards. The\ncopying is generally much faster than the computation, thus\nthe number of new blocks is typically small such that we can\ncopy them in a very short period. To the end, only one itera-\ntion of computation is conducted for the KV cache migration\n(i.e., stage-N). Therefore, Llumnix suspends the computation\nfor the request by draining it out of the current batch and\ncopies the remaining block, which introduces the downtime\nof this request. Once it is finished, the migration completes\nand the request resumes on the destination instance. Although\nthe total copying duration of the whole sequence depends on\nthe sequence length, the downtime for the request is only the\nperiod of copying the KV cache generated by one iteration,"
    },
    {
      "page_no": 5,
      "bbox": [
        303.5090026855469,
        742.3324584960938,
        308.49029541015625,
        752.2950439453125
      ],
      "text": "5"
    },
    {
      "page_no": 6,
      "bbox": [
        146.5548858642578,
        129.46780395507812,
        200.62094116210938,
        137.43218994140625
      ],
      "text": "Destination instance"
    },
    {
      "page_no": 6,
      "bbox": [
        152.82582092285156,
        70.06643676757812,
        194.4713134765625,
        78.03083038330078
      ],
      "text": "Source instance"
    },
    {
      "page_no": 6,
      "bbox": [
        56.50825119018555,
        92.439697265625,
        67.85440826416016,
        115.8077392578125
      ],
      "text": "PRE-ALLOC"
    },
    {
      "page_no": 6,
      "bbox": [
        89.38738250732422,
        97.72648620605469,
        97.53278350830078,
        108.99464416503906
      ],
      "text": "ACK/"
    },
    {
      "page_no": 6,
      "bbox": [
        95.00389862060547,
        97.005126953125,
        103.97176361083984,
        112.21258544921875
      ],
      "text": "ABORT"
    },
    {
      "page_no": 6,
      "bbox": [
        123.69293212890625,
        90.8126220703125,
        139.59703063964844,
        115.97755432128906
      ],
      "text": "PRE-ALLOC/\nABORT"
    },
    {
      "page_no": 6,
      "bbox": [
        106.23306274414062,
        82.056884765625,
        121.24940490722656,
        88.25141143798828
      ],
      "text": "Stage 0"
    },
    {
      "page_no": 6,
      "bbox": [
        158.00938415527344,
        97.9482421875,
        166.23370361328125,
        109.26765441894531
      ],
      "text": "ACK/"
    },
    {
      "page_no": 6,
      "bbox": [
        163.5966033935547,
        97.33704376220703,
        172.6791229248047,
        112.57255554199219
      ],
      "text": "ABORT"
    },
    {
      "page_no": 6,
      "bbox": [
        174.6001434326172,
        82.056884765625,
        190.0241241455078,
        88.25141143798828
      ],
      "text": "Stage-1"
    },
    {
      "page_no": 6,
      "bbox": [
        257.9309387207031,
        94.40567016601562,
        268.44049072265625,
        113.81591796875
      ],
      "text": "COMMIT"
    },
    {
      "page_no": 6,
      "bbox": [
        73.59646606445312,
        117.19326782226562,
        84.64818572998047,
        128.43209838867188
      ],
      "text": "Block\nAlloc"
    },
    {
      "page_no": 6,
      "bbox": [
        142.69290161132812,
        117.19326782226562,
        153.74462890625,
        128.43209838867188
      ],
      "text": "Block\nAlloc"
    },
    {
      "page_no": 6,
      "bbox": [
        235.6726531982422,
        79.70864868164062,
        254.23948669433594,
        90.94751739501953
      ],
      "text": "Block\nReleased"
    },
    {
      "page_no": 6,
      "bbox": [
        271.20965576171875,
        117.19326782226562,
        290.3238830566406,
        128.43209838867188
      ],
      "text": "Compute\nResumed"
    },
    {
      "page_no": 6,
      "bbox": [
        198.77699279785156,
        79.285400390625,
        228.47540283203125,
        88.25141143798828
      ],
      "text": "Stage-N\n…"
    },
    {
      "page_no": 6,
      "bbox": [
        96.49199676513672,
        146.55445861816406,
        251.6295623779297,
        156.51705932617188
      ],
      "text": "Figure 7: Handshake during migration."
    },
    {
      "page_no": 6,
      "bbox": [
        53.640995025634766,
        170.9464874267578,
        295.7767639160156,
        540.0050659179688
      ],
      "text": "which is negligible regardless of the sequence length.\nThe request migration approach of Llumnix borrows the\nkey concept introduced in virtual machine (VM) live migra-\ntion [17], which gradually reduces the working set to mini-\nmize the downtime. Llumnix does not require the dirty page\ntracing in VM migration as the working set (i.e., KV cache) is\nappend-only and does not change during migration. However,\nLLM serving further introduces additional challenges. Firstly,\nas both the source and destination instances are continually\nprocessing requests, the request might run out of memory\nduring migration. Secondly, the request can complete in the\nmiddle of migration, due to the unpredictable execution (i.e.,\ngenerating EOS token) and the continuous batching [67]. To\nhandle such exceptions and guarantee correctness during the\nasynchronous computation and memory copying, Llumnix in-\ntroduces fine-grained coordination between the participating\ninstances with a handshake process (Figure 7). Before each\nstage, the source instance issues a pre-allocate request with\nthe number of blocks to migrate to make sure that the destina-\ntion has enough space. The destination will try to allocate and\nreserve the blocks; if it succeeds or fails, the destination will\nnotify the source to proceed or abort the migration and clean\nthe states, respectively. Similarly, after each stage, the source\ninstance also checks whether the request being migrated has\ncompleted or been preempted — if it has, the source will no-\ntify the destination to abort and release the reserved blocks;\notherwise the source will go ahead to the next stage. The\nsource or destination will also abort the migration if the other\nside fails. After the final stage finishes, the source releases\nits local blocks and notifies the destination to commit the\nmigration and resume the execution of the request."
    },
    {
      "page_no": 6,
      "bbox": [
        54.0,
        559.3611450195312,
        266.19287109375,
        571.3163452148438
      ],
      "text": "4.3\nDistributed Scheduling Architecture"
    },
    {
      "page_no": 6,
      "bbox": [
        53.691001892089844,
        580.4222412109375,
        295.8620300292969,
        698.0560302734375
      ],
      "text": "The live migration mechanism provides the foundation for\nruntime rescheduling of LLM inference requests. However,\nachieving fully dynamic scheduling is still non-trivial due to\nthe higher scheduling pressure than in traditional schedulers.\nIn particular, Llumnix would need to continuously track and\nreschedule every single running request throughout the cluster,\nrather than only dispatch incoming requests for one time or\nonly manage running requests on one instance. This implies a\nhigher scheduling frequency and a larger number of requests\nfor the scheduler to track and schedule in each round."
    },
    {
      "page_no": 6,
      "bbox": [
        54.0,
        700.4142456054688,
        294.121826171875,
        722.4226684570312
      ],
      "text": "Llumnix devises a scalable architecture that combines a\ncluster-level global scheduler and distributed instance-level"
    },
    {
      "page_no": 6,
      "bbox": [
        396.3155212402344,
        153.27931213378906,
        420.67724609375,
        163.7916259765625
      ],
      "text": "llumlet"
    },
    {
      "page_no": 6,
      "bbox": [
        381.71905517578125,
        208.29469299316406,
        435.5753173828125,
        218.8070068359375
      ],
      "text": "Model Instance"
    },
    {
      "page_no": 6,
      "bbox": [
        345.9656066894531,
        105.60799407958984,
        443.4949951171875,
        113.49223327636719
      ],
      "text": "Report load\nDispatch"
    },
    {
      "page_no": 6,
      "bbox": [
        354.8668212890625,
        133.6408233642578,
        458.00030517578125,
        152.00836181640625
      ],
      "text": "Local Scheduler\nMigration \nCoordinator"
    },
    {
      "page_no": 6,
      "bbox": [
        402.7447509765625,
        193.68423461914062,
        414.3534851074219,
        201.56846618652344
      ],
      "text": "GPU"
    },
    {
      "page_no": 6,
      "bbox": [
        393.1885681152344,
        171.61781311035156,
        423.73028564453125,
        182.130126953125
      ],
      "text": "Executor"
    },
    {
      "page_no": 6,
      "bbox": [
        491.53594970703125,
        138.16090393066406,
        512.9805297851562,
        147.35919189453125
      ],
      "text": "llumlet"
    },
    {
      "page_no": 6,
      "bbox": [
        488.725341796875,
        157.01588439941406,
        515.4967651367188,
        166.21417236328125
      ],
      "text": "Executor"
    },
    {
      "page_no": 6,
      "bbox": [
        489.4761047363281,
        124.21333312988281,
        515.1876220703125,
        133.41162109375
      ],
      "text": "Instance"
    },
    {
      "page_no": 6,
      "bbox": [
        489.0819091796875,
        189.56019592285156,
        514.7933959960938,
        198.75848388671875
      ],
      "text": "Instance"
    },
    {
      "page_no": 6,
      "bbox": [
        488.37103271484375,
        74.2259750366211,
        534.0426635742188,
        82.11021423339844
      ],
      "text": "Migration control"
    },
    {
      "page_no": 6,
      "bbox": [
        489.3201599121094,
        208.0277862548828,
        515.0316772460938,
        217.22607421875
      ],
      "text": "Instance"
    },
    {
      "page_no": 6,
      "bbox": [
        379.0621643066406,
        73.46833801269531,
        438.2182922363281,
        83.98065185546875
      ],
      "text": "Global Scheduler"
    },
    {
      "page_no": 6,
      "bbox": [
        352.1747131347656,
        92.5644760131836,
        452.28033447265625,
        100.44871520996094
      ],
      "text": "New requests\nInstance loads"
    },
    {
      "page_no": 6,
      "bbox": [
        471.9886474609375,
        109.3531723022461,
        516.6948852539062,
        117.23741149902344
      ],
      "text": "Trigger migration"
    },
    {
      "page_no": 6,
      "bbox": [
        512.681396484375,
        99.5382308959961,
        526.133056640625,
        107.42247009277344
      ],
      "text": "Scale"
    },
    {
      "page_no": 6,
      "bbox": [
        488.4698486328125,
        85.71981048583984,
        523.8394775390625,
        93.60404968261719
      ],
      "text": "Other control"
    },
    {
      "page_no": 6,
      "bbox": [
        375.4049987792969,
        231.2914581298828,
        500.4754333496094,
        241.25405883789062
      ],
      "text": "Figure 8: Llumnix architecture."
    },
    {
      "page_no": 6,
      "bbox": [
        317.5710144042969,
        264.0452880859375,
        559.7439575195312,
        632.759033203125
      ],
      "text": "schedulers, named llumlets, to enable continuous rescheduling\nefficiently (Figure 8). Llumnix defines a clean separation of\nconcerns with a narrow interface between the two levels. The\nglobal scheduler does not directly track or schedule the run-\nning requests; instead, it makes all scheduling decisions ori-\nented to the instances, according to the memory loads of them.\nThis way, the complexity of the global scheduler remains\nindependent from the running requests, thereby preserving\nsimilar scalability to schedulers without dynamic scheduling.\nThe loads are reported by the llumlets periodically, based on\nthe request status and Llumnix’s scheduling policy.\nThe global scheduler utilizes the load information to dis-\npatch new requests, trigger migration across instances, and\ncontrol the instance auto-scaling. In particular, for migration,\nthe decisions are not made for specific requests; the global\nscheduler just pairs the source and destination instances, only\nbased on the loads, and marks them as in the corresponding\nstates to trigger the migration. The llumlets will decide the\nrequests to migrate and execute the migration automatically.\nThe llumlet of each instance consists of a local scheduler\nand a migration coordinator. In addition to the functionalities\nof similar roles in existing systems like queuing, batching,\nand block management, an important new task of the local\nscheduler is to calculate the memory load of the instance. The\nload is not simply the physical memory being used; instead,\nit is a sum of the “virtual usages” (§4.4) of the requests. The\nlocal scheduler is also responsible for deciding the requests\nto migrate when triggered. Given the chosen requests, the\nmigration coordinator will coordinate with the local scheduler\nand the other instance, and instruct the model executor to do\nthe memory copying, as described before."
    },
    {
      "page_no": 6,
      "bbox": [
        317.8800048828125,
        649.5541381835938,
        484.03338623046875,
        661.5093383789062
      ],
      "text": "4.4\nDynamic Scheduling Policy"
    },
    {
      "page_no": 6,
      "bbox": [
        317.8800048828125,
        669.7635498046875,
        439.1148986816406,
        679.7261352539062
      ],
      "text": "4.4.1\nGoals and Definitions"
    },
    {
      "page_no": 6,
      "bbox": [
        317.8800048828125,
        688.4779663085938,
        559.7423706054688,
        722.4310302734375
      ],
      "text": "Llumnix’s scheduling policy is designed with the following\ngoals. The first is to improve prefill and decode latencies,\nby reducing queuing delays, preemptions, and interference."
    },
    {
      "page_no": 6,
      "bbox": [
        303.5090026855469,
        742.3324584960938,
        308.49029541015625,
        752.2950439453125
      ],
      "text": "6"
    },
    {
      "page_no": 7,
      "bbox": [
        53.691001892089844,
        74.35101318359375,
        295.862060546875,
        336.10406494140625
      ],
      "text": "The second goal is load-adaptivity to handle varying cluster\nload and improve cost efficiency. We notice that the benefits\nof rescheduling is also relevant to cluster load, which could\nbe limited under too high/low load. Llumnix incorporates\ninstance auto-scaling to keep appropriate cluster load for both\nsaving costs and maximizing the benefits of rescheduling.\nBesides these two goals similar to those of existing sys-\ntems, Llumnix introduces a new goal of request priorities\nthat comes from the new requirements of LLMs. Priorities\npresent a systematic approach for the same LLM to serve\ncertain requests with higher emergency, e.g., from ChatGPT\nPlus or more interactive applications. Llumnix provides ap-\nplications with an interface for specifying request priorities\nto meet different SLOs, in terms of scheduling priority and\nexecution priority. Requests with higher scheduling priori-\nties will get scheduled earlier to reduce their queuing delays.\nThose with higher execution priorities will be given lower\ninstance load and hence less interference to accelerate their\nexecution. Currently, Llumnix supports two priority classes,\nhigh and normal, to demonstrate the ability of Llumnix to\nprefer high-priority requests, but our design also generalizes\nto more priorities."
    },
    {
      "page_no": 7,
      "bbox": [
        54.0,
        356.29351806640625,
        142.45791625976562,
        366.256103515625
      ],
      "text": "4.4.2\nVirtual Usage"
    },
    {
      "page_no": 7,
      "bbox": [
        53.691001892089844,
        376.2732849121094,
        295.7768249511719,
        722.3828735351562
      ],
      "text": "To achieve the multiple goals above under the distributed\nscheduling architecture, Llumnix needs a scheduling policy\nthat can express these goals using simple instance-level met-\nrics, to improve the efficiency and scalability of the global\nscheduler. To this end, Llumnix introduces the virtual usage\nabstraction to unify these different, sometimes conflicting\ngoals into a simple load metric of instances. The key observa-\ntion here is that the aforementioned rescheduling scenarios\nfall into two categories: load balancing, and creating free\nspace on one instance (de-fragmentation, prioritization, and\ndraining out instances). We find that they can be unified into\nload balancing by assuming a virtual load on the instance: to\ncreate free space on an instance, we just need to set the vir-\ntual usages of certain requests to make the instance virtually\noverloaded, then a load balancing policy will be triggered to\nmigrate the requests to other instances.\nThis observation leads us to a simple heuristic with load-\nbalancing as the basis, combined with a set of rules for setting\nrequest virtual usages in different situations. We summarize\nthe rules in the function CalcVirtualUsage in Algorithm 1\nand illustrate example scenarios in Figure 9. In normal cases,\nthe virtual usage of a request is just its physical memory usage\nto enable routine load balancing, as shown in Figure 9(a). We\ndiscuss the rules for other cases as follows.\nQueuing requests.\nFor the head-of-line queuing request\non an instance, we assign a positive virtual usage to it to\nreflect its resource demand in terms of the required memory,\nalthough the physical usage is 0. Thus, queuing requests will\nincrease the total virtual usage of the instance, then the policy"
    },
    {
      "page_no": 7,
      "bbox": [
        355.9075927734375,
        74.82649993896484,
        398.3472595214844,
        83.77110290527344
      ],
      "text": "Physical usage"
    },
    {
      "page_no": 7,
      "bbox": [
        418.403076171875,
        74.82649993896484,
        457.2409973144531,
        83.77110290527344
      ],
      "text": "Virtual usage"
    },
    {
      "page_no": 7,
      "bbox": [
        329.56463623046875,
        173.86912536621094,
        545.8806762695312,
        182.81373596191406
      ],
      "text": "(a) Load balancing\n(b) De-frag\n(d) Auto-scaling\n(c) Prioritization"
    },
    {
      "page_no": 7,
      "bbox": [
        317.8800048828125,
        192.99227905273438,
        559.6510009765625,
        214.98507690429688
      ],
      "text": "Figure 9: Llumnix combines virtual usages with a load-\nbalancing policy to unify multiple scheduling goals."
    },
    {
      "page_no": 7,
      "bbox": [
        317.13299560546875,
        229.91928100585938,
        559.743896484375,
        659.8470458984375
      ],
      "text": "will trigger migration for load balancing (which in effect\nis de-fragmentation for the queuing request), as shown in\nFigure 9(b). There could be a lot of heuristics to explore for\nsetting the virtual usage, which controls the tradeoff between\nreducing queuing delays and load balancing — for example,\ngradually increasing the virtual usage of a queuing request\nuntil it reaches the real memory demand. Llumnix currently\nuses a simple rule that directly uses its real demand (line\n4 in Algorithm 1), which favours reducing queuing delays.\nThis rule is based on our observation that queuing delay can\ndominate the end-to-end latency and worth such preference.\nOur evaluation also shows that this rule preserves the benefits\nof load balancing, due to the high flexibility of migration.\nExecution priorities.\nFor a request with high execution\npriorities, Llumnix tries to prevent the instance the request\nis running on from exceeding a given level of real load, by\nreserving a memory space as headroom, as shown in Fig-\nure 9(c). This is achieved by adding such a headroom on the\nphysical usage of a high-priority request to get the virtual\nusage (line 8). When there are multiple high-priority requests\non an instance, this headroom is divided among them (line\n10). The headroom for high-priority requests is currently de-\nfined as that required to preserve the ideal decode speed (i.e.,\nno visible interference), which is obtained through profiling.\nThe headroom for normal requests is 0. Llumnix can also\nsupport more execution priorities by specifying the sizes for\nthe headroom. When the headroom for a high-priority request\nis running up, the other normal requests will be migrated\naway by the load balancing policy because the instance is\noverloaded in terms of the total virtual usage.\nAuto-scaling.\nWhen a new instance is launched, Llumnix’s\nload balancing policy will automatically saturate it by migrat-\ning requests from other instances to it. When an instance is\nterminating, we artificially add a fake request with a virtual\nusage of infinity on it (line 7), then the remaining requests\nwill be migrated to other instances, as shown in Figure 9(d)."
    },
    {
      "page_no": 7,
      "bbox": [
        317.8800048828125,
        680.33251953125,
        379.66802978515625,
        690.2951049804688
      ],
      "text": "4.4.3\nPolicies"
    },
    {
      "page_no": 7,
      "bbox": [
        317.4119873046875,
        700.4142456054688,
        558.004150390625,
        722.4070434570312
      ],
      "text": "We then describe how the specific scheduling decisions are\nmade based on the virtual usages."
    },
    {
      "page_no": 7,
      "bbox": [
        303.5090026855469,
        742.3324584960938,
        308.49029541015625,
        752.2950439453125
      ],
      "text": "7"
    },
    {
      "page_no": 8,
      "bbox": [
        58.62300109863281,
        77.0733642578125,
        267.2245788574219,
        87.02588653564453
      ],
      "text": "Algorithm 1: Virtual Usage and Freeness Calculation"
    },
    {
      "page_no": 8,
      "bbox": [
        58.483001708984375,
        91.53697967529297,
        197.00628662109375,
        98.78227996826172
      ],
      "text": "1 Function CalcVirtualUsage(req, instance):"
    },
    {
      "page_no": 8,
      "bbox": [
        58.88199996948242,
        99.68074035644531,
        142.0185089111328,
        106.75225067138672
      ],
      "text": "2\nif req.isQueuing then"
    },
    {
      "page_no": 8,
      "bbox": [
        59.279998779296875,
        107.65077209472656,
        170.75650024414062,
        114.72228240966797
      ],
      "text": "3\nif req.isHeadOfLine then"
    },
    {
      "page_no": 8,
      "bbox": [
        59.67900085449219,
        115.62074279785156,
        166.4336700439453,
        122.69225311279297
      ],
      "text": "4\nreturn req.demand"
    },
    {
      "page_no": 8,
      "bbox": [
        59.279998779296875,
        127.67347717285156,
        121.00689697265625,
        134.71095275878906
      ],
      "text": "5\nreturn 0"
    },
    {
      "page_no": 8,
      "bbox": [
        58.88199996948242,
        139.53077697753906,
        132.05250549316406,
        146.602294921875
      ],
      "text": "6\nif req.isFake then"
    },
    {
      "page_no": 8,
      "bbox": [
        59.279998779296875,
        147.5984649658203,
        122.49231719970703,
        155.12315368652344
      ],
      "text": "7\nreturn ∞"
    },
    {
      "page_no": 8,
      "bbox": [
        58.88199996948242,
        159.28196716308594,
        266.5146484375,
        166.52728271484375
      ],
      "text": "8\nreturn req.physicalUsage+GetHeadroom(req.priority,instance)"
    },
    {
      "page_no": 8,
      "bbox": [
        58.483001708984375,
        171.2379608154297,
        174.03529357910156,
        178.4832763671875
      ],
      "text": "9 Function GetHeadroom(p, instance):"
    },
    {
      "page_no": 8,
      "bbox": [
        56.39099884033203,
        179.38172912597656,
        245.55772399902344,
        186.4532470703125
      ],
      "text": "10\nreturn headroomForPriority[p]/instance.numRequests[p]"
    },
    {
      "page_no": 8,
      "bbox": [
        55.99300003051758,
        191.16294860839844,
        170.0942840576172,
        198.40826416015625
      ],
      "text": "11 Function CalcFreeness(instance):"
    },
    {
      "page_no": 8,
      "bbox": [
        56.39099884033203,
        199.30677795410156,
        167.4304962158203,
        206.3782958984375
      ],
      "text": "12\nif instance.isTerminating then"
    },
    {
      "page_no": 8,
      "bbox": [
        56.790000915527344,
        207.1029510498047,
        187.41029357910156,
        214.4119415283203
      ],
      "text": "13\nAddFakeReq (instance.requests)"
    },
    {
      "page_no": 8,
      "bbox": [
        56.39099884033203,
        219.2317657470703,
        148.33889770507812,
        226.36695861816406
      ],
      "text": "14\ntotalVirtualUsages = 0"
    },
    {
      "page_no": 8,
      "bbox": [
        56.39100646972656,
        227.2017364501953,
        167.8073272705078,
        234.27325439453125
      ],
      "text": "15\nfor req in instance.requests do"
    },
    {
      "page_no": 8,
      "bbox": [
        56.790000915527344,
        234.9979705810547,
        263.5316162109375,
        242.18524169921875
      ],
      "text": "16\ntotalVirtualUsages+ =CalcVirtualUsage(req,instance)"
    },
    {
      "page_no": 8,
      "bbox": [
        56.39099884033203,
        247.03738403320312,
        244.302978515625,
        254.1412353515625
      ],
      "text": "17\nfreeness = (instance.M −totalVirtualUsage)/instance.B"
    },
    {
      "page_no": 8,
      "bbox": [
        56.3909912109375,
        255.1374053955078,
        126.99666595458984,
        262.16925048828125
      ],
      "text": "18\nreturn freeness"
    },
    {
      "page_no": 8,
      "bbox": [
        54.0,
        302.29107666015625,
        295.7747497558594,
        551.3900756835938
      ],
      "text": "Dispatching.\nLlumnix dispatches new requests with higher\nscheduling priorities first. Within the same priority, it adopts\na simple first-come-first-serve order. On each instance, re-\nquests are scheduled in the same order. Llumnix uses a load-\nbalancing policy that dispatches each request to the freest\ninstance. We introduce a metric for measuring the freeness\nof an instance defined as F = (M −∑V)/B, where M is the\ntotal memory, V is the virtual usage of each request, and B\nis the batch size. While (M −∑V) already measures the free\nspace, we divide it by the batch size because it determines\nthe consumption speed, i.e., the number of new tokens per\niteration. Thus the metric suggests how many iterations the\nbatch can still run for. Then Llumnix dispatches each incom-\ning request to the instance with the highest freeness. Because\nthe virtual usage of a request can be larger than the physi-\ncal, it is possible that F is a negative value, e.g., when there\nare queuing requests or high-priority requests. Such nega-\ntive freeness values help Llumnix automatically treat such\ninstances as overloaded and prefer dispatching requests to\nother instances. The freeness metric also guides the migration\nand auto-scaling, as shown later."
    },
    {
      "page_no": 8,
      "bbox": [
        54.0,
        556.8604125976562,
        295.7755432128906,
        722.4070434570312
      ],
      "text": "Migration.\nLlumnix triggers the migration policy period-\nically. In each round, Llumnix selects the candidate sets of\nsource and destination instances by choosing those with free-\nness values smaller or greater than given thresholds, respec-\ntively. Llumnix pairs the instances from both sets by picking\nthe two with the lowest and the highest freeness values repeat-\nedly, and then sets them in corresponding states. The llumlet\nof each source instance then starts to migrate requests to the\ndestination continuously, until it is no longer set in the source\nstate. The llumlet prefers the requests with lower priorities\nand shorter sequence lengths when choosing the requests to\nmigrate. In the next round, if an instance during migration\nis no longer beyond the thresholds, Llumnix will unset the\nmigration state and the migration will stop."
    },
    {
      "page_no": 8,
      "bbox": [
        317.52099609375,
        74.39337158203125,
        559.6504516601562,
        156.10104370117188
      ],
      "text": "Auto-scaling.\nLlumnix scales the instances according to the\ncluster load in terms of the averages freeness for the normal\npriority across instances. The policy maintains the average\nfreeness within a range [x,y], and adds or terminates an in-\nstance when the freeness is smaller than x or greater than y\nfor a period, respectively. Llumnix chooses the instance with\nfewest running requests for termination."
    },
    {
      "page_no": 8,
      "bbox": [
        317.8800048828125,
        180.65313720703125,
        417.502685546875,
        192.60833740234375
      ],
      "text": "5\nImplementation"
    },
    {
      "page_no": 8,
      "bbox": [
        317.4119873046875,
        206.70828247070312,
        559.7416381835938,
        722.4070434570312
      ],
      "text": "We implement Llumnix with 3,300 lines of Python code.\nLlumnix is a standalone library comprising both its own com-\nponents and an interface to integrate and communicate with\nbackend inference engines. This architecture makes Llumnix\nnon-intrusive and extensible to different backends. Llumnix\ncurrently supports vLLM [11] as the backend, which is an\nopen-source state-of-the-art inference engine that features\ncontinuous batching, PagedAttention, and tensor-parallel dis-\ntributed inference [34,56].\nMulti-instance serving.\nLlumnix instantiates the multiple\ninstances of the backend and the other components as Ray [42]\nactors. Ray’s Python-native distributed runtime enables fine-\ngrained coordination among these actors in a simple and\nefficient manner. Llumnix also launches a set of request fron-\ntend actors that exposes an OpenAI-style API endpoint [48].\nAlthough a request can be migrated across backend instances,\nthe generated tokens are forwarded to the frontend and then\nreturned to end users, ensuring a steady API service.\nKV cache transfer.\nWe use the Gloo collective communica-\ntion library [5] (the Send/Recv primitives) for the KV cache\ntransfer during migration. A potential alternative is NCCL [1],\nwhich is generally faster than Gloo on GPUs but has been\nadopted in communication for distributed inference. However,\nLlumnix needs to migrate requests in parallel with the infer-\nence to minimize the downtimes, but concurrent invocations\nof NCCL are known to be unsafe [45]. The pipelined migra-\ntion design allows us to use Gloo while maintaining negligible\ndowntimes. Using Gloo needs to copy the KV cache between\nCPU and GPU memory, which is done in another CUDA\nstream to avoid blocking the inference computation. Note\nthat in typical deployments, the communication-heavy ten-\nsor parallelism is limited in a single machine for high-speed\ntransfer [44]. In such cases, migration between instances (ma-\nchines) will not interfere with the tensor-parallel inference.\nBlock fusion.\nvLLM stores the KV cache in non-contiguous\nsmall blocks that are dynamically allocated. For example, the\nblock size of a 16-bit LLaMA-7B model is 128 KB (for key or\nvalue tensors of 16 tokens in each layer), and a sequence of 1k\ntokens translates to 4k such blocks (32 layers). To avoid the\noverhead of sending these blocks using many small messages,\nwe fuse the blocks by copying them from GPU memory to\na contiguous CPU memory buffer and use Gloo to send the\nbuffer as a whole, thereby improving the transfer efficiency."
    },
    {
      "page_no": 8,
      "bbox": [
        303.5090026855469,
        742.3324584960938,
        308.49029541015625,
        752.2950439453125
      ],
      "text": "8"
    },
    {
      "page_no": 9,
      "bbox": [
        54.0,
        74.35101318359375,
        295.7698059082031,
        227.83206176757812
      ],
      "text": "Fault tolerance.\nLlumnix provides fault tolerance for each\ncomponent to ensure high service availability. When the\nglobal scheduler fails, Llumnix temporarily falls back to a\nscheduler-bypassing mode, thus not affecting the service avail-\nability: that is, the request frontends directly dispatch requests\nto certain instances using simple rules, and migration is dis-\nabled. When an instance (or the co-located llumlet) fails, the\nrequests running on it will be aborted. In particular, ongoing\nmigration on failed instances will also be aborted (the request\nbeing migrated is not necessarily aborted, depending on if its\nsource instance is healthy), which is handled by the handshake\nprocess. These failed actors will be automatically restarted by\nRay, after which the service could go back to normal state."
    },
    {
      "page_no": 9,
      "bbox": [
        54.0,
        246.6661376953125,
        127.62013244628906,
        258.621337890625
      ],
      "text": "6\nEvaluation"
    },
    {
      "page_no": 9,
      "bbox": [
        53.53200149536133,
        270.8974304199219,
        295.7703857421875,
        292.7364807128906
      ],
      "text": "We evaluate Llumnix on a 16-GPU cluster using realistic mod-\nels and various workloads. Overall, our key findings include:"
    },
    {
      "page_no": 9,
      "bbox": [
        55.49399948120117,
        305.2614440917969,
        295.86761474609375,
        327.16094970703125
      ],
      "text": "• Llumnix introduces near-zero downtime to requests being\nmigrated and near-zero overhead to other running requests."
    },
    {
      "page_no": 9,
      "bbox": [
        55.49399948120117,
        332.79681396484375,
        295.7752685546875,
        378.98406982421875
      ],
      "text": "• Llumnix improves prefill latencies by up to 15×/7.7×\n(P99/mean) over INFaaS on 16 LLaMA-7B instances via\nde-fragmentation. Llumnix also improves P99 decode la-\ntency by up to 2× by reducing preemptions."
    },
    {
      "page_no": 9,
      "bbox": [
        55.49400329589844,
        384.96246337890625,
        294.12384033203125,
        430.7900695800781
      ],
      "text": "• Llumnix improves high-priority request latencies by up to\n1.5× by reducing their queuing delays and accelerating\ntheir execution, while preserving similar performance of\nthe normal requests."
    },
    {
      "page_no": 9,
      "bbox": [
        55.49400329589844,
        436.7674560546875,
        294.11810302734375,
        458.6860656738281
      ],
      "text": "• Llumnix achieves up to 36% cost saving while preserving\nsimilar P99 latencies with efficient auto-scaling."
    },
    {
      "page_no": 9,
      "bbox": [
        54.000003814697266,
        476.3991394042969,
        182.8531494140625,
        488.3543395996094
      ],
      "text": "6.1\nExperimental Setup"
    },
    {
      "page_no": 9,
      "bbox": [
        53.64099884033203,
        496.954345703125,
        295.867431640625,
        722.3865356445312
      ],
      "text": "Testbed.\nWe use a 16-GPU cluster with 4 GPU VMs on Al-\nibaba Cloud (type ecs.gn7i-c32g1.32xlarge), each with\n4 NVIDIA A10 (24 GB) GPUs connected via PCI-e 4.0, 128\nvCPUs, 752 GB memory, and 64 Gb/s network bandwidth.\nModels.\nWe conduct experiments using a popular model\nfamily, LLaMA [57]. We test two different specifications:\nLLaMA-7B, which runs on a single GPU, and LLaMA-30B,\nwhich runs on 4 GPUs of a machine using tensor parallelism.\nThe models adopt the commonly used 16-bit precision. The\nversion of vLLM that we based on only supports the orig-\ninal LLaMA with a maximum sequence length of 2k, but\nthere have been a series of recent LLaMA variants supporting\nlonger sequence lengths ranging from 4k to 256k [3,7,58,65].\nSince the model architectures and inference performance of\nthese variants are mostly similar to those of LLaMA, we be-\nlieve that our results are representative of more model types\nand larger sequence length ranges from a systems perspective.\nTraces.\nSimilar to prior work [34, 35, 67], we synthesize\nrequest traces to asses Llumnix’s online serving performance."
    },
    {
      "page_no": 9,
      "bbox": [
        347.24798583984375,
        76.21878814697266,
        548.189697265625,
        84.18888854980469
      ],
      "text": "Distribution\nMean\nP50\nP80\nP95\nP99"
    },
    {
      "page_no": 9,
      "bbox": [
        326.1440124511719,
        105.15856170654297,
        340.75323486328125,
        113.128662109375
      ],
      "text": "Real"
    },
    {
      "page_no": 9,
      "bbox": [
        352.7080078125,
        90.96154022216797,
        549.7360229492188,
        108.39666748046875
      ],
      "text": "ShareGPT\nIn\n306\n74\n348\n1484\n3388\nOut\n500\n487\n781\n988\n1234"
    },
    {
      "page_no": 9,
      "bbox": [
        353.14599609375,
        114.89653778076172,
        549.7359619140625,
        132.3316650390625
      ],
      "text": "BurstGPT\nIn\n830\n582\n1427\n2345\n3549\nOut\n271\n243\n434\n669\n964"
    },
    {
      "page_no": 9,
      "bbox": [
        326.8089904785156,
        148.49554443359375,
        340.0871887207031,
        156.46563720703125
      ],
      "text": "Gen"
    },
    {
      "page_no": 9,
      "bbox": [
        360.5660095214844,
        139.03155517578125,
        549.7360229492188,
        165.9306640625
      ],
      "text": "Short (S)\n128\n38\n113\n413\n1464\nMedium (M)\n256\n32\n173\n1288\n4208\nLong (L)\n512\n55\n582\n3113\n5166"
    },
    {
      "page_no": 9,
      "bbox": [
        317.5509948730469,
        180.27398681640625,
        559.6571044921875,
        214.06739807128906
      ],
      "text": "Table 1: Real and generated distributions of sequence lengths\n(numbers of tokens) used in our evaluation. The real distribu-\ntions include those of both inputs (“In”) and outputs (“Out”)."
    },
    {
      "page_no": 9,
      "bbox": [
        317.13299560546875,
        239.17129516601562,
        559.7445068359375,
        621.4700317382812
      ],
      "text": "We use Poisson and Gamma distributions with different re-\nquest rates (requests per second) to generate request arrivals.\nFor Gamma, we also use varying coefficients of variance\n(CVs) to adjust the burstiness of the requests. Each trace has\n10,000 requests. We choose an appropriate range of request\nrates or CVs for the traces to maintain the loads within a rea-\nsonable range: nearly no queuing delays and preemptions for\nP50 requests, and queuing delays within a few tens of seconds\nfor P99 requests when using Llumnix.\nFor the input/output lengths of requests, we use two public\nChatGPT-4 conversation datasets, ShareGPT (GPT4) [10] and\nBurstGPT (GPT4-Conversation) [62], for an evaluation on\nreal workloads. Considering that Llumnix targets more diver-\nsified applications, we also use generated power-law length\ndistributions to emulate long-tail workloads that mix both fre-\nquent, short sequences (e.g., for interactive applications like\nchatbots and personal assistants) and seldom, long sequences\n(e.g., summarizing or writing articles). We generate multiple\ndistributions with different long-tail degrees and mean lengths\n(128, 256, 512), as shown by the Short (S), Medium (M), and\nLong (L) distributions in Table 1. These distributions have\na maximum length of 6k, thus the total sequence length of a\nrequest (input plus output) will not exceed the capacity of an\nA10 GPU when running LLaMA-7B (13,616 tokens). To ob-\nserve the performance with different workload characteristics,\nwe construct the traces by picking different combinations of\nthe length distributions for inputs and outputs as follows: S-S,\nM-M, L-L, S-L, and L-S.\nBaselines.\nWe compare Llumnix with the following sched-\nulers. All the baselines and Llumnix use vLLM as the under-\nlying inference engine to focus the comparison on the request\nscheduling across instances."
    },
    {
      "page_no": 9,
      "bbox": [
        319.3739929199219,
        636.4776611328125,
        559.7467651367188,
        670.5805053710938
      ],
      "text": "• Round-robin dispatching: a simple dispatching policy to\ndistribute requests across instances evenly, which is a typi-\ncal behavior of production-grade serving systems [4,9,47]."
    },
    {
      "page_no": 9,
      "bbox": [
        319.3739929199219,
        676.3392333984375,
        559.6576538085938,
        722.4310302734375
      ],
      "text": "• INFaaS++: an optimized version of INFaaS [53], a state-\nof-the-art scheduler for multi-instance serving. We evaluate\nits load-balancing dispatching and load-aware auto-scaling\npolicies. We improve it by making it focus on the GPU"
    },
    {
      "page_no": 9,
      "bbox": [
        303.5090026855469,
        742.3324584960938,
        308.49029541015625,
        752.2950439453125
      ],
      "text": "9"
    },
    {
      "page_no": 10,
      "bbox": [
        77.57015991210938,
        156.7101287841797,
        173.6206817626953,
        169.25018310546875
      ],
      "text": "256\n512\n1k\n2k\n4k\n8k\nSequence Length"
    },
    {
      "page_no": 10,
      "bbox": [
        71.37262725830078,
        151.75521850585938,
        74.2913589477539,
        157.1016387939453
      ],
      "text": "0"
    },
    {
      "page_no": 10,
      "bbox": [
        65.53573608398438,
        140.74024963378906,
        74.29193115234375,
        146.086669921875
      ],
      "text": "500"
    },
    {
      "page_no": 10,
      "bbox": [
        62.61729431152344,
        129.72528076171875,
        74.29222106933594,
        135.0717010498047
      ],
      "text": "1000"
    },
    {
      "page_no": 10,
      "bbox": [
        62.61729431152344,
        118.71031951904297,
        74.29222106933594,
        124.0567398071289
      ],
      "text": "1500"
    },
    {
      "page_no": 10,
      "bbox": [
        62.61729431152344,
        107.69535064697266,
        74.29222106933594,
        113.0417709350586
      ],
      "text": "2000"
    },
    {
      "page_no": 10,
      "bbox": [
        62.61729431152344,
        96.68038177490234,
        74.29222106933594,
        102.02680206298828
      ],
      "text": "2500"
    },
    {
      "page_no": 10,
      "bbox": [
        62.61729431152344,
        85.66542053222656,
        74.29222106933594,
        91.0118408203125
      ],
      "text": "3000"
    },
    {
      "page_no": 10,
      "bbox": [
        62.61729431152344,
        74.65045166015625,
        74.29222106933594,
        79.99687194824219
      ],
      "text": "3500"
    },
    {
      "page_no": 10,
      "bbox": [
        54.518272399902344,
        92.10770416259766,
        60.9339714050293,
        134.434814453125
      ],
      "text": "Downtime (ms)"
    },
    {
      "page_no": 10,
      "bbox": [
        94.48355102539062,
        75.61712646484375,
        138.9850311279297,
        114.62962341308594
      ],
      "text": "Migration(7B)\nMigration(30B)\nBlocking copy(7B)\nBlocking copy(30B)\nRecompute(7B)\nRecompute(30B)"
    },
    {
      "page_no": 10,
      "bbox": [
        194.900146484375,
        156.7101287841797,
        290.9506530761719,
        169.25018310546875
      ],
      "text": "256\n512\n1k\n2k\n4k\n8k\nSequence Length"
    },
    {
      "page_no": 10,
      "bbox": [
        188.70260620117188,
        151.75521850585938,
        191.621337890625,
        157.1016387939453
      ],
      "text": "0"
    },
    {
      "page_no": 10,
      "bbox": [
        185.78416442871094,
        139.66822814941406,
        191.6216278076172,
        145.0146484375
      ],
      "text": "10"
    },
    {
      "page_no": 10,
      "bbox": [
        185.78416442871094,
        127.58123779296875,
        191.6216278076172,
        132.9276580810547
      ],
      "text": "20"
    },
    {
      "page_no": 10,
      "bbox": [
        185.78416442871094,
        115.49424743652344,
        191.6216278076172,
        120.84066772460938
      ],
      "text": "30"
    },
    {
      "page_no": 10,
      "bbox": [
        185.78416442871094,
        103.40725708007812,
        191.6216278076172,
        108.75367736816406
      ],
      "text": "40"
    },
    {
      "page_no": 10,
      "bbox": [
        185.78416442871094,
        91.32026672363281,
        191.6216278076172,
        96.66668701171875
      ],
      "text": "50"
    },
    {
      "page_no": 10,
      "bbox": [
        185.78416442871094,
        79.2332763671875,
        191.6216278076172,
        84.57969665527344
      ],
      "text": "60"
    },
    {
      "page_no": 10,
      "bbox": [
        177.68515014648438,
        83.92385864257812,
        184.10086059570312,
        142.63441467285156
      ],
      "text": "Decode Latency (ms)"
    },
    {
      "page_no": 10,
      "bbox": [
        211.81353759765625,
        124.72914123535156,
        246.0214385986328,
        150.27520751953125
      ],
      "text": "Migration(7B)\nMigration(30B)\nNormal(7B)\nNormal(30B)"
    },
    {
      "page_no": 10,
      "bbox": [
        76.24299621582031,
        180.0674591064453,
        271.8785095214844,
        190.03005981445312
      ],
      "text": "Figure 10: Downtime and overhead of migration."
    },
    {
      "page_no": 10,
      "bbox": [
        63.65399932861328,
        211.76539611816406,
        295.8620910644531,
        245.56210327148438
      ],
      "text": "memory load as it is the dominant resource in LLM serving.\nThis load also counts in the memory required by queuing\nrequests on each instance to reflect the queue pressure."
    },
    {
      "page_no": 10,
      "bbox": [
        55.49400329589844,
        251.28968811035156,
        295.77410888671875,
        285.4130859375
      ],
      "text": "• Llumnix-base: a base version of Llumnix that is priority-\nagnostic (i.e., treats all requests as the same priority) but\nenables all the other features including migration."
    },
    {
      "page_no": 10,
      "bbox": [
        53.67100143432617,
        294.9855041503906,
        295.77362060546875,
        340.8810729980469
      ],
      "text": "Key metrics.\nWe focus on request latency, in terms of end-\nto-end, prefill (that of the first generated token), and decode\n(that since first generated token to the last, averaged over all\ngenerated tokens). We report both mean and P99 values."
    },
    {
      "page_no": 10,
      "bbox": [
        54.0,
        357.399169921875,
        186.16473388671875,
        369.3543701171875
      ],
      "text": "6.2\nMigration Efficiency"
    },
    {
      "page_no": 10,
      "bbox": [
        53.53200149536133,
        377.6242980957031,
        295.7707824707031,
        507.2140808105469
      ],
      "text": "We first examine the performance of Llumnix’s migration\nmechanism, in terms of the downtimes introduced to the mi-\ngrated requests and the performance overheads for the running\nrequests. We test both the 1-GPU LLaMA-7B and the 4-GPU\nLLaMA-30B models. For each model, we deploy two in-\nstances on two different machines. We use different sequence\nlengths, for each of which we run a batch of requests with the\nsame total length of 8k on both instances. We migrate one\nof the requests from one instance to another and measure its\ndowntime and the decode speeds of the running batches on\nboth instances during migration."
    },
    {
      "page_no": 10,
      "bbox": [
        54.0,
        509.24810791015625,
        295.77752685546875,
        722.4226684570312
      ],
      "text": "We compare the downtime during migration with two sim-\nple approaches: recomputing, and blocking copying of the\nKV cache using Gloo (non-blocking for other requests). As\nshown in Figure 10 (left), the downtime of migration is nearly\nconstant with increasing sequence lengths (roughly 20-30 ms),\neven shorter than a single decode step. In comparison, the\ndowntimes of baselines increase with the sequence lengths,\nreaching up to 111× that of migration. For example, recom-\nputing an 8k sequence for LLaMA-30B takes 3.5s, which\ntranslates to a service stall similar to 54 decode steps. We\nalso notice that for all sequence lengths, the migration only\ntakes two stages, which is the minimum. This is because the\ndata copying is sufficiently fast and the number of new tokens\ngenerated during the first stage is small.\nFigure 10 (right) also compares the per-step decode times\nduring migration on the source instance with that during nor-\nmal execution (results on the destination are mostly simi-\nlar). We observe up to 1% performance differences for both"
    },
    {
      "page_no": 10,
      "bbox": [
        317.4119873046875,
        74.44155883789062,
        559.742431640625,
        168.05606079101562
      ],
      "text": "LLaMA-7B and LLaMA-30B, showing the negligible migra-\ntion overhead. Also note that such overhead exists only when\nthere are requests being migrated (in or out) on an instance.\nWe find that in all the serving experiments in the following\nsections, the average fraction of time span with ongoing mi-\ngration for each instance is only roughly 10%. This implies\nan effective overhead that is even much smaller, which is\nworthwhile for the great scheduling benefits of migration."
    },
    {
      "page_no": 10,
      "bbox": [
        317.8800048828125,
        187.65411376953125,
        452.68682861328125,
        199.60931396484375
      ],
      "text": "6.3\nServing Performance"
    },
    {
      "page_no": 10,
      "bbox": [
        317.4119873046875,
        208.79928588867188,
        559.6533813476562,
        577.9760131835938
      ],
      "text": "We evaluate the scheduling performance of Llumnix in on-\nline serving using 16 LLaMA-7B instances (auto-scaling is\ndisabled except in experiments in §6.5).\nReal datasets.\nWe first compare Llumnix with round-robin\nand INFaaS++ using the ShareGPT and BurstGPT traces (the\ntop two rows in Figure 11). Llumnix outperforms the base-\nlines in end-to-end request latency by up to 2× and 2.9×\nfor mean and P99, respectively. In particular, we observe\nthat round-robin always performs much worse than both IN-\nFaaS++ and Llumnix: since the sequence lengths have high\nvariance, simply distributing requests evenly can still lead\nto unbalanced load, impacting both prefill and decode laten-\ncies. Llumnix achieves significant gains in prefill latency over\nround-robin, by up to 26.6× for mean and 34.4× for P99. This\nis because round-robin can possibly dispatch new requests to\noverloaded instances, leading to long queuing delays. Llum-\nnix also improves P99 decode latency by up to 2×, by load\nbalancing to reduce preemptions. This margin seems smaller\nas the latency penalty caused by preemptions is averaged\nover all generated tokens. However, whenever preemption\noccurs, it results in a sudden service stall, which impacts user\nexperience. Figure 11 (the rightmost column) reports the pre-\nemption loss in terms of the extra queuing and recomputing\ntimes (mean value of all requests). Llumnix reduces preemp-\ntion loss by 84% on average compared to round-robin. These\nresults highlight the importance of load balancing in LLM\nserving. In the following experiments using generated distri-\nbutions with higher variance, round-robin showed up to two\norders of magnitude worse latencies. Therefore, we omit it\nfor the other traces for clarity of the figures and focus on the\ncomparison between INFaaS++ and Llumnix."
    },
    {
      "page_no": 10,
      "bbox": [
        317.8800048828125,
        580.3782958984375,
        559.6549682617188,
        722.3828735351562
      ],
      "text": "Llumnix outperforms INFaaS++ in mean and P99 prefill\nlatencies by up to 2.2× and 5.5×, and P99 decode latencies\nby up to 1.3×, respectively, showing the extra benefits of\nmigration, beyond dispatch-time load balancing. Next we use\nmore traces with different characteristics to further evaluate\nthem for a deeper understanding of the improvements.\nGenerated distributions.\nWe compare Llumnix and IN-\nFaaS++ using multiple generated distributions (bottom five\nrows in Figure 11). Llumnix outperforms INFaaS++ across all\ntraces in end-to-end request latency by up to 1.5× and 1.6×\nfor mean and P99, respectively. For prefill, the improvements\nare up to 7.7× for mean and 14.8× for P99. Despite dispatch-"
    },
    {
      "page_no": 10,
      "bbox": [
        301.0190124511719,
        742.3324584960938,
        310.9815979003906,
        752.2950439453125
      ],
      "text": "10"
    },
    {
      "page_no": 11,
      "bbox": [
        96.29658508300781,
        135.97315979003906,
        147.27943420410156,
        140.79388427734375
      ],
      "text": "7.0\n7.5\n8.0"
    },
    {
      "page_no": 11,
      "bbox": [
        92.31993103027344,
        128.8722686767578,
        94.95167541503906,
        133.6929931640625
      ],
      "text": "0"
    },
    {
      "page_no": 11,
      "bbox": [
        89.68521118164062,
        118.68083190917969,
        94.94869995117188,
        123.50154876708984
      ],
      "text": "50"
    },
    {
      "page_no": 11,
      "bbox": [
        87.05049133300781,
        108.48942565917969,
        94.94572448730469,
        113.31014251708984
      ],
      "text": "100"
    },
    {
      "page_no": 11,
      "bbox": [
        87.05049133300781,
        98.29798889160156,
        94.94572448730469,
        103.11870574951172
      ],
      "text": "150"
    },
    {
      "page_no": 11,
      "bbox": [
        68.2063980102539,
        102.95748138427734,
        74.2322998046875,
        128.173828125
      ],
      "text": "ShareGPT"
    },
    {
      "page_no": 11,
      "bbox": [
        79.78837585449219,
        101.16598510742188,
        85.81427764892578,
        129.98687744140625
      ],
      "text": "Latency (s)"
    },
    {
      "page_no": 11,
      "bbox": [
        105.60221862792969,
        90.0169677734375,
        137.95697021484375,
        96.0428695678711
      ],
      "text": "Request P99"
    },
    {
      "page_no": 11,
      "bbox": [
        162.23577880859375,
        135.97315979003906,
        213.2186279296875,
        140.79388427734375
      ],
      "text": "7.0\n7.5\n8.0"
    },
    {
      "page_no": 11,
      "bbox": [
        158.25912475585938,
        128.8722686767578,
        160.890869140625,
        133.6929931640625
      ],
      "text": "0"
    },
    {
      "page_no": 11,
      "bbox": [
        155.6243896484375,
        115.01338195800781,
        160.88787841796875,
        119.83409881591797
      ],
      "text": "20"
    },
    {
      "page_no": 11,
      "bbox": [
        155.6243896484375,
        101.15455627441406,
        160.88787841796875,
        105.97527313232422
      ],
      "text": "40"
    },
    {
      "page_no": 11,
      "bbox": [
        169.3458251953125,
        90.0169677734375,
        206.09715270996094,
        96.0428695678711
      ],
      "text": "Request Mean"
    },
    {
      "page_no": 11,
      "bbox": [
        228.17495727539062,
        135.97315979003906,
        279.1578063964844,
        140.79388427734375
      ],
      "text": "7.0\n7.5\n8.0"
    },
    {
      "page_no": 11,
      "bbox": [
        224.19830322265625,
        128.8722686767578,
        226.83004760742188,
        133.6929931640625
      ],
      "text": "0"
    },
    {
      "page_no": 11,
      "bbox": [
        221.5635986328125,
        114.07041931152344,
        226.82708740234375,
        118.8911361694336
      ],
      "text": "50"
    },
    {
      "page_no": 11,
      "bbox": [
        218.9288787841797,
        99.26860046386719,
        226.82411193847656,
        104.08931732177734
      ],
      "text": "100"
    },
    {
      "page_no": 11,
      "bbox": [
        240.81845092773438,
        90.0169677734375,
        266.5227355957031,
        96.0428695678711
      ],
      "text": "Prefill P99"
    },
    {
      "page_no": 11,
      "bbox": [
        294.1141357421875,
        135.97315979003906,
        345.09698486328125,
        140.79388427734375
      ],
      "text": "7.0\n7.5\n8.0"
    },
    {
      "page_no": 11,
      "bbox": [
        290.13751220703125,
        128.8722686767578,
        292.7692565917969,
        133.6929931640625
      ],
      "text": "0"
    },
    {
      "page_no": 11,
      "bbox": [
        290.13751220703125,
        117.13359069824219,
        292.7692565917969,
        121.95430755615234
      ],
      "text": "5"
    },
    {
      "page_no": 11,
      "bbox": [
        287.5027770996094,
        105.39488220214844,
        292.7662658691406,
        110.2155990600586
      ],
      "text": "10"
    },
    {
      "page_no": 11,
      "bbox": [
        304.56207275390625,
        90.0169677734375,
        334.6629333496094,
        96.0428695678711
      ],
      "text": "Prefill Mean"
    },
    {
      "page_no": 11,
      "bbox": [
        360.0533447265625,
        135.97315979003906,
        411.03619384765625,
        140.79388427734375
      ],
      "text": "7.0\n7.5\n8.0"
    },
    {
      "page_no": 11,
      "bbox": [
        352.1273193359375,
        128.8722686767578,
        358.7066650390625,
        133.6929931640625
      ],
      "text": "0.0"
    },
    {
      "page_no": 11,
      "bbox": [
        352.1273193359375,
        111.44841003417969,
        358.7066650390625,
        116.26912689208984
      ],
      "text": "0.1"
    },
    {
      "page_no": 11,
      "bbox": [
        370.05401611328125,
        90.0169677734375,
        401.0369873046875,
        96.0428695678711
      ],
      "text": "Decode P99"
    },
    {
      "page_no": 11,
      "bbox": [
        425.9925537109375,
        135.97315979003906,
        476.975341796875,
        140.79388427734375
      ],
      "text": "7.0\n7.5\n8.0"
    },
    {
      "page_no": 11,
      "bbox": [
        415.4317626953125,
        128.8722686767578,
        424.6428527832031,
        133.6929931640625
      ],
      "text": "0.00"
    },
    {
      "page_no": 11,
      "bbox": [
        415.4317626953125,
        119.37455749511719,
        424.6428527832031,
        124.19527435302734
      ],
      "text": "0.02"
    },
    {
      "page_no": 11,
      "bbox": [
        415.4317626953125,
        109.87687683105469,
        424.6428527832031,
        114.69759368896484
      ],
      "text": "0.04"
    },
    {
      "page_no": 11,
      "bbox": [
        415.4317626953125,
        100.37919616699219,
        424.6428527832031,
        105.19991302490234
      ],
      "text": "0.06"
    },
    {
      "page_no": 11,
      "bbox": [
        433.79766845703125,
        90.0169677734375,
        469.1772155761719,
        96.0428695678711
      ],
      "text": "Decode Mean"
    },
    {
      "page_no": 11,
      "bbox": [
        491.93170166015625,
        135.97315979003906,
        542.91455078125,
        140.79388427734375
      ],
      "text": "7.0\n7.5\n8.0"
    },
    {
      "page_no": 11,
      "bbox": [
        487.955078125,
        128.8722686767578,
        490.5868225097656,
        133.6929931640625
      ],
      "text": "0"
    },
    {
      "page_no": 11,
      "bbox": [
        487.955078125,
        111.18360900878906,
        490.5868225097656,
        116.00432586669922
      ],
      "text": "1"
    },
    {
      "page_no": 11,
      "bbox": [
        496.1160888671875,
        90.0169677734375,
        538.7515258789062,
        96.0428695678711
      ],
      "text": "Preemption Loss"
    },
    {
      "page_no": 11,
      "bbox": [
        96.29658508300781,
        184.54869079589844,
        147.27943420410156,
        189.36941528320312
      ],
      "text": "7.5\n8.0\n8.5"
    },
    {
      "page_no": 11,
      "bbox": [
        92.31993103027344,
        177.44776916503906,
        94.95167541503906,
        182.26849365234375
      ],
      "text": "0"
    },
    {
      "page_no": 11,
      "bbox": [
        87.05049133300781,
        160.56019592285156,
        94.94572448730469,
        165.38092041015625
      ],
      "text": "100"
    },
    {
      "page_no": 11,
      "bbox": [
        87.05049133300781,
        143.67262268066406,
        94.94572448730469,
        148.49334716796875
      ],
      "text": "200"
    },
    {
      "page_no": 11,
      "bbox": [
        68.2063980102539,
        152.16845703125,
        74.2322998046875,
        176.13241577148438
      ],
      "text": "BurstGPT"
    },
    {
      "page_no": 11,
      "bbox": [
        79.78837585449219,
        149.74148559570312,
        85.81427764892578,
        178.5623779296875
      ],
      "text": "Latency (s)"
    },
    {
      "page_no": 11,
      "bbox": [
        162.23577880859375,
        184.54869079589844,
        213.2186279296875,
        189.36941528320312
      ],
      "text": "7.5\n8.0\n8.5"
    },
    {
      "page_no": 11,
      "bbox": [
        158.25912475585938,
        177.44776916503906,
        160.890869140625,
        182.26849365234375
      ],
      "text": "0"
    },
    {
      "page_no": 11,
      "bbox": [
        155.6243896484375,
        161.4302215576172,
        160.88787841796875,
        166.25094604492188
      ],
      "text": "20"
    },
    {
      "page_no": 11,
      "bbox": [
        155.6243896484375,
        145.4126739501953,
        160.88787841796875,
        150.2333984375
      ],
      "text": "40"
    },
    {
      "page_no": 11,
      "bbox": [
        228.17495727539062,
        184.54869079589844,
        279.1578063964844,
        189.36941528320312
      ],
      "text": "7.5\n8.0\n8.5"
    },
    {
      "page_no": 11,
      "bbox": [
        224.19830322265625,
        177.44776916503906,
        226.83004760742188,
        182.26849365234375
      ],
      "text": "0"
    },
    {
      "page_no": 11,
      "bbox": [
        218.9288787841797,
        159.6058807373047,
        226.82411193847656,
        164.42660522460938
      ],
      "text": "100"
    },
    {
      "page_no": 11,
      "bbox": [
        294.1141357421875,
        184.54869079589844,
        345.09698486328125,
        189.36941528320312
      ],
      "text": "7.5\n8.0\n8.5"
    },
    {
      "page_no": 11,
      "bbox": [
        290.13751220703125,
        177.44776916503906,
        292.7692565917969,
        182.26849365234375
      ],
      "text": "0"
    },
    {
      "page_no": 11,
      "bbox": [
        287.5027770996094,
        163.94334411621094,
        292.7662658691406,
        168.76406860351562
      ],
      "text": "10"
    },
    {
      "page_no": 11,
      "bbox": [
        287.5027770996094,
        150.4389190673828,
        292.7662658691406,
        155.2596435546875
      ],
      "text": "20"
    },
    {
      "page_no": 11,
      "bbox": [
        360.0533447265625,
        184.54869079589844,
        411.03619384765625,
        189.36941528320312
      ],
      "text": "7.5\n8.0\n8.5"
    },
    {
      "page_no": 11,
      "bbox": [
        349.49261474609375,
        177.44776916503906,
        358.7037048339844,
        182.26849365234375
      ],
      "text": "0.00"
    },
    {
      "page_no": 11,
      "bbox": [
        349.49261474609375,
        164.1499481201172,
        358.7037048339844,
        168.97067260742188
      ],
      "text": "0.05"
    },
    {
      "page_no": 11,
      "bbox": [
        349.49261474609375,
        150.8521270751953,
        358.7037048339844,
        155.6728515625
      ],
      "text": "0.10"
    },
    {
      "page_no": 11,
      "bbox": [
        425.9925537109375,
        184.54869079589844,
        476.975341796875,
        189.36941528320312
      ],
      "text": "7.5\n8.0\n8.5"
    },
    {
      "page_no": 11,
      "bbox": [
        415.4317626953125,
        177.44776916503906,
        424.6428527832031,
        182.26849365234375
      ],
      "text": "0.00"
    },
    {
      "page_no": 11,
      "bbox": [
        415.4317626953125,
        166.7289581298828,
        424.6428527832031,
        171.5496826171875
      ],
      "text": "0.02"
    },
    {
      "page_no": 11,
      "bbox": [
        415.4317626953125,
        156.01014709472656,
        424.6428527832031,
        160.83087158203125
      ],
      "text": "0.04"
    },
    {
      "page_no": 11,
      "bbox": [
        415.4317626953125,
        145.2913360595703,
        424.6428527832031,
        150.112060546875
      ],
      "text": "0.06"
    },
    {
      "page_no": 11,
      "bbox": [
        491.93170166015625,
        184.54869079589844,
        542.91455078125,
        189.36941528320312
      ],
      "text": "7.5\n8.0\n8.5"
    },
    {
      "page_no": 11,
      "bbox": [
        484.00567626953125,
        177.44776916503906,
        490.58502197265625,
        182.26849365234375
      ],
      "text": "0.0"
    },
    {
      "page_no": 11,
      "bbox": [
        484.00567626953125,
        161.1322479248047,
        490.58502197265625,
        165.95297241210938
      ],
      "text": "0.2"
    },
    {
      "page_no": 11,
      "bbox": [
        484.00567626953125,
        144.81675720214844,
        490.58502197265625,
        149.63748168945312
      ],
      "text": "0.4"
    },
    {
      "page_no": 11,
      "bbox": [
        96.95391082763672,
        233.1241912841797,
        146.6208953857422,
        237.94491577148438
      ],
      "text": "32\n34\n36"
    },
    {
      "page_no": 11,
      "bbox": [
        92.31993103027344,
        226.0232696533203,
        94.95167541503906,
        230.843994140625
      ],
      "text": "0"
    },
    {
      "page_no": 11,
      "bbox": [
        87.05049133300781,
        207.7380828857422,
        94.94572448730469,
        212.55880737304688
      ],
      "text": "100"
    },
    {
      "page_no": 11,
      "bbox": [
        68.2063980102539,
        208.50221252441406,
        74.2322998046875,
        216.9384765625
      ],
      "text": "S-S"
    },
    {
      "page_no": 11,
      "bbox": [
        79.78837585449219,
        198.31700134277344,
        85.81427764892578,
        227.1378936767578
      ],
      "text": "Latency (s)"
    },
    {
      "page_no": 11,
      "bbox": [
        162.89309692382812,
        233.1241912841797,
        212.56008911132812,
        237.94491577148438
      ],
      "text": "32\n34\n36"
    },
    {
      "page_no": 11,
      "bbox": [
        158.25912475585938,
        226.0232696533203,
        160.890869140625,
        230.843994140625
      ],
      "text": "0"
    },
    {
      "page_no": 11,
      "bbox": [
        158.25912475585938,
        214.4807891845703,
        160.890869140625,
        219.301513671875
      ],
      "text": "5"
    },
    {
      "page_no": 11,
      "bbox": [
        155.6243896484375,
        202.93832397460938,
        160.88787841796875,
        207.75904846191406
      ],
      "text": "10"
    },
    {
      "page_no": 11,
      "bbox": [
        228.83229064941406,
        233.1241912841797,
        278.499267578125,
        237.94491577148438
      ],
      "text": "32\n34\n36"
    },
    {
      "page_no": 11,
      "bbox": [
        224.19830322265625,
        226.0232696533203,
        226.83004760742188,
        230.843994140625
      ],
      "text": "0"
    },
    {
      "page_no": 11,
      "bbox": [
        221.5635986328125,
        216.10406494140625,
        226.82708740234375,
        220.92478942871094
      ],
      "text": "25"
    },
    {
      "page_no": 11,
      "bbox": [
        221.5635986328125,
        206.18484497070312,
        226.82708740234375,
        211.0055694580078
      ],
      "text": "50"
    },
    {
      "page_no": 11,
      "bbox": [
        221.5635986328125,
        196.26564025878906,
        226.82708740234375,
        201.08636474609375
      ],
      "text": "75"
    },
    {
      "page_no": 11,
      "bbox": [
        294.771484375,
        233.1241912841797,
        344.4384765625,
        237.94491577148438
      ],
      "text": "32\n34\n36"
    },
    {
      "page_no": 11,
      "bbox": [
        290.13751220703125,
        226.0232696533203,
        292.7692565917969,
        230.843994140625
      ],
      "text": "0"
    },
    {
      "page_no": 11,
      "bbox": [
        290.13751220703125,
        213.1078643798828,
        292.7692565917969,
        217.9285888671875
      ],
      "text": "2"
    },
    {
      "page_no": 11,
      "bbox": [
        290.13751220703125,
        200.19244384765625,
        292.7692565917969,
        205.01316833496094
      ],
      "text": "4"
    },
    {
      "page_no": 11,
      "bbox": [
        360.710693359375,
        233.1241912841797,
        410.37762451171875,
        237.94491577148438
      ],
      "text": "32\n34\n36"
    },
    {
      "page_no": 11,
      "bbox": [
        352.1273193359375,
        226.0232696533203,
        358.7066650390625,
        230.843994140625
      ],
      "text": "0.0"
    },
    {
      "page_no": 11,
      "bbox": [
        352.1273193359375,
        208.75778198242188,
        358.7066650390625,
        213.57850646972656
      ],
      "text": "0.1"
    },
    {
      "page_no": 11,
      "bbox": [
        426.64984130859375,
        233.1241912841797,
        476.31683349609375,
        237.94491577148438
      ],
      "text": "32\n34\n36"
    },
    {
      "page_no": 11,
      "bbox": [
        412.79705810546875,
        226.0232696533203,
        424.639892578125,
        230.843994140625
      ],
      "text": "0.000"
    },
    {
      "page_no": 11,
      "bbox": [
        412.79705810546875,
        215.0043487548828,
        424.639892578125,
        219.8250732421875
      ],
      "text": "0.025"
    },
    {
      "page_no": 11,
      "bbox": [
        412.79705810546875,
        203.98544311523438,
        424.639892578125,
        208.80616760253906
      ],
      "text": "0.050"
    },
    {
      "page_no": 11,
      "bbox": [
        412.79705810546875,
        192.96652221679688,
        424.639892578125,
        197.78724670410156
      ],
      "text": "0.075"
    },
    {
      "page_no": 11,
      "bbox": [
        492.58905029296875,
        233.1241912841797,
        542.2559814453125,
        237.94491577148438
      ],
      "text": "32\n34\n36"
    },
    {
      "page_no": 11,
      "bbox": [
        484.00567626953125,
        226.0232696533203,
        490.58502197265625,
        230.843994140625
      ],
      "text": "0.0"
    },
    {
      "page_no": 11,
      "bbox": [
        484.00567626953125,
        214.1869354248047,
        490.58502197265625,
        219.00765991210938
      ],
      "text": "0.2"
    },
    {
      "page_no": 11,
      "bbox": [
        484.00567626953125,
        202.35057067871094,
        490.58502197265625,
        207.17129516601562
      ],
      "text": "0.4"
    },
    {
      "page_no": 11,
      "bbox": [
        96.29658508300781,
        281.69970703125,
        147.27943420410156,
        286.52044677734375
      ],
      "text": "7.4\n7.6\n7.8"
    },
    {
      "page_no": 11,
      "bbox": [
        92.31993103027344,
        274.5987548828125,
        94.95167541503906,
        279.41949462890625
      ],
      "text": "0"
    },
    {
      "page_no": 11,
      "bbox": [
        87.05049133300781,
        256.45843505859375,
        94.94572448730469,
        261.2791748046875
      ],
      "text": "200"
    },
    {
      "page_no": 11,
      "bbox": [
        68.2063980102539,
        255.89903259277344,
        74.2322998046875,
        266.6939392089844
      ],
      "text": "M-M"
    },
    {
      "page_no": 11,
      "bbox": [
        79.78837585449219,
        246.89251708984375,
        85.81427764892578,
        275.7134094238281
      ],
      "text": "Latency (s)"
    },
    {
      "page_no": 11,
      "bbox": [
        162.23577880859375,
        281.69970703125,
        213.2186279296875,
        286.52044677734375
      ],
      "text": "7.4\n7.6\n7.8"
    },
    {
      "page_no": 11,
      "bbox": [
        158.25912475585938,
        274.5987548828125,
        160.890869140625,
        279.41949462890625
      ],
      "text": "0"
    },
    {
      "page_no": 11,
      "bbox": [
        155.6243896484375,
        260.28369140625,
        160.88787841796875,
        265.10443115234375
      ],
      "text": "10"
    },
    {
      "page_no": 11,
      "bbox": [
        155.6243896484375,
        245.96864318847656,
        160.88787841796875,
        250.78936767578125
      ],
      "text": "20"
    },
    {
      "page_no": 11,
      "bbox": [
        228.17495727539062,
        281.69970703125,
        279.1578063964844,
        286.52044677734375
      ],
      "text": "7.4\n7.6\n7.8"
    },
    {
      "page_no": 11,
      "bbox": [
        224.19830322265625,
        274.5987548828125,
        226.83004760742188,
        279.41949462890625
      ],
      "text": "0"
    },
    {
      "page_no": 11,
      "bbox": [
        218.9288787841797,
        262.24322509765625,
        226.82411193847656,
        267.06396484375
      ],
      "text": "100"
    },
    {
      "page_no": 11,
      "bbox": [
        218.9288787841797,
        249.8876495361328,
        226.82411193847656,
        254.7083740234375
      ],
      "text": "200"
    },
    {
      "page_no": 11,
      "bbox": [
        294.1141357421875,
        281.69970703125,
        345.09698486328125,
        286.52044677734375
      ],
      "text": "7.4\n7.6\n7.8"
    },
    {
      "page_no": 11,
      "bbox": [
        290.13751220703125,
        274.5987548828125,
        292.7692565917969,
        279.41949462890625
      ],
      "text": "0"
    },
    {
      "page_no": 11,
      "bbox": [
        290.13751220703125,
        264.5341796875,
        292.7692565917969,
        269.35491943359375
      ],
      "text": "2"
    },
    {
      "page_no": 11,
      "bbox": [
        290.13751220703125,
        254.46961975097656,
        292.7692565917969,
        259.29034423828125
      ],
      "text": "4"
    },
    {
      "page_no": 11,
      "bbox": [
        290.13751220703125,
        244.40501403808594,
        292.7692565917969,
        249.22573852539062
      ],
      "text": "6"
    },
    {
      "page_no": 11,
      "bbox": [
        360.0533447265625,
        281.69970703125,
        411.03619384765625,
        286.52044677734375
      ],
      "text": "7.4\n7.6\n7.8"
    },
    {
      "page_no": 11,
      "bbox": [
        349.49261474609375,
        274.5987548828125,
        358.7037048339844,
        279.41949462890625
      ],
      "text": "0.00"
    },
    {
      "page_no": 11,
      "bbox": [
        349.49261474609375,
        264.53314208984375,
        358.7037048339844,
        269.3538818359375
      ],
      "text": "0.05"
    },
    {
      "page_no": 11,
      "bbox": [
        349.49261474609375,
        254.46751403808594,
        358.7037048339844,
        259.2882385253906
      ],
      "text": "0.10"
    },
    {
      "page_no": 11,
      "bbox": [
        349.49261474609375,
        244.40188598632812,
        358.7037048339844,
        249.2226104736328
      ],
      "text": "0.15"
    },
    {
      "page_no": 11,
      "bbox": [
        425.9925537109375,
        281.69970703125,
        476.975341796875,
        286.52044677734375
      ],
      "text": "7.4\n7.6\n7.8"
    },
    {
      "page_no": 11,
      "bbox": [
        415.4317626953125,
        274.5987548828125,
        424.6428527832031,
        279.41949462890625
      ],
      "text": "0.00"
    },
    {
      "page_no": 11,
      "bbox": [
        415.4317626953125,
        264.5531005859375,
        424.6428527832031,
        269.37384033203125
      ],
      "text": "0.02"
    },
    {
      "page_no": 11,
      "bbox": [
        415.4317626953125,
        254.5074005126953,
        424.6428527832031,
        259.328125
      ],
      "text": "0.04"
    },
    {
      "page_no": 11,
      "bbox": [
        415.4317626953125,
        244.46170043945312,
        424.6428527832031,
        249.2824249267578
      ],
      "text": "0.06"
    },
    {
      "page_no": 11,
      "bbox": [
        491.93170166015625,
        281.69970703125,
        542.91455078125,
        286.52044677734375
      ],
      "text": "7.4\n7.6\n7.8"
    },
    {
      "page_no": 11,
      "bbox": [
        484.00567626953125,
        274.5987548828125,
        490.58502197265625,
        279.41949462890625
      ],
      "text": "0.0"
    },
    {
      "page_no": 11,
      "bbox": [
        484.00567626953125,
        264.1064453125,
        490.58502197265625,
        268.92718505859375
      ],
      "text": "0.5"
    },
    {
      "page_no": 11,
      "bbox": [
        484.00567626953125,
        253.61415100097656,
        490.58502197265625,
        258.43487548828125
      ],
      "text": "1.0"
    },
    {
      "page_no": 11,
      "bbox": [
        484.00567626953125,
        243.12184143066406,
        490.58502197265625,
        247.94256591796875
      ],
      "text": "1.5"
    },
    {
      "page_no": 11,
      "bbox": [
        96.29658508300781,
        330.27520751953125,
        147.27943420410156,
        335.095947265625
      ],
      "text": "2.6\n2.8\n3.0"
    },
    {
      "page_no": 11,
      "bbox": [
        92.31993103027344,
        323.1742858886719,
        94.95167541503906,
        327.9950256347656
      ],
      "text": "0"
    },
    {
      "page_no": 11,
      "bbox": [
        87.05049133300781,
        312.08990478515625,
        94.94572448730469,
        316.91064453125
      ],
      "text": "100"
    },
    {
      "page_no": 11,
      "bbox": [
        87.05049133300781,
        301.0054931640625,
        94.94572448730469,
        305.82623291015625
      ],
      "text": "200"
    },
    {
      "page_no": 11,
      "bbox": [
        87.05049133300781,
        289.921142578125,
        94.94572448730469,
        294.74188232421875
      ],
      "text": "300"
    },
    {
      "page_no": 11,
      "bbox": [
        68.2063980102539,
        306.1045227050781,
        74.2322998046875,
        313.6476745605469
      ],
      "text": "L-L"
    },
    {
      "page_no": 11,
      "bbox": [
        79.78837585449219,
        295.4680480957031,
        85.81427764892578,
        324.2889404296875
      ],
      "text": "Latency (s)"
    },
    {
      "page_no": 11,
      "bbox": [
        162.23577880859375,
        330.27520751953125,
        213.2186279296875,
        335.095947265625
      ],
      "text": "2.6\n2.8\n3.0"
    },
    {
      "page_no": 11,
      "bbox": [
        158.25912475585938,
        323.1742858886719,
        160.890869140625,
        327.9950256347656
      ],
      "text": "0"
    },
    {
      "page_no": 11,
      "bbox": [
        155.6243896484375,
        312.62078857421875,
        160.88787841796875,
        317.4415283203125
      ],
      "text": "10"
    },
    {
      "page_no": 11,
      "bbox": [
        155.6243896484375,
        302.0672607421875,
        160.88787841796875,
        306.88800048828125
      ],
      "text": "20"
    },
    {
      "page_no": 11,
      "bbox": [
        155.6243896484375,
        291.51373291015625,
        160.88787841796875,
        296.33447265625
      ],
      "text": "30"
    },
    {
      "page_no": 11,
      "bbox": [
        228.17495727539062,
        330.27520751953125,
        279.1578063964844,
        335.095947265625
      ],
      "text": "2.6\n2.8\n3.0"
    },
    {
      "page_no": 11,
      "bbox": [
        224.19830322265625,
        323.1742858886719,
        226.83004760742188,
        327.9950256347656
      ],
      "text": "0"
    },
    {
      "page_no": 11,
      "bbox": [
        221.5635986328125,
        308.7412109375,
        226.82708740234375,
        313.56195068359375
      ],
      "text": "20"
    },
    {
      "page_no": 11,
      "bbox": [
        221.5635986328125,
        294.30816650390625,
        226.82708740234375,
        299.12890625
      ],
      "text": "40"
    },
    {
      "page_no": 11,
      "bbox": [
        294.1141357421875,
        330.27520751953125,
        345.09698486328125,
        335.095947265625
      ],
      "text": "2.6\n2.8\n3.0"
    },
    {
      "page_no": 11,
      "bbox": [
        286.1881103515625,
        323.1742858886719,
        292.7674560546875,
        327.9950256347656
      ],
      "text": "0.0"
    },
    {
      "page_no": 11,
      "bbox": [
        286.1881103515625,
        312.77886962890625,
        292.7674560546875,
        317.599609375
      ],
      "text": "0.5"
    },
    {
      "page_no": 11,
      "bbox": [
        286.1881103515625,
        302.3834228515625,
        292.7674560546875,
        307.20416259765625
      ],
      "text": "1.0"
    },
    {
      "page_no": 11,
      "bbox": [
        286.1881103515625,
        291.98797607421875,
        292.7674560546875,
        296.8087158203125
      ],
      "text": "1.5"
    },
    {
      "page_no": 11,
      "bbox": [
        360.0533447265625,
        330.27520751953125,
        411.03619384765625,
        335.095947265625
      ],
      "text": "2.6\n2.8\n3.0"
    },
    {
      "page_no": 11,
      "bbox": [
        349.49261474609375,
        323.1742858886719,
        358.7037048339844,
        327.9950256347656
      ],
      "text": "0.00"
    },
    {
      "page_no": 11,
      "bbox": [
        349.49261474609375,
        313.25146484375,
        358.7037048339844,
        318.07220458984375
      ],
      "text": "0.05"
    },
    {
      "page_no": 11,
      "bbox": [
        349.49261474609375,
        303.32861328125,
        358.7037048339844,
        308.14935302734375
      ],
      "text": "0.10"
    },
    {
      "page_no": 11,
      "bbox": [
        349.49261474609375,
        293.4057922363281,
        358.7037048339844,
        298.2265319824219
      ],
      "text": "0.15"
    },
    {
      "page_no": 11,
      "bbox": [
        425.9925537109375,
        330.27520751953125,
        476.975341796875,
        335.095947265625
      ],
      "text": "2.6\n2.8\n3.0"
    },
    {
      "page_no": 11,
      "bbox": [
        415.4317626953125,
        323.1742858886719,
        424.6428527832031,
        327.9950256347656
      ],
      "text": "0.00"
    },
    {
      "page_no": 11,
      "bbox": [
        415.4317626953125,
        311.8033447265625,
        424.6428527832031,
        316.62408447265625
      ],
      "text": "0.02"
    },
    {
      "page_no": 11,
      "bbox": [
        415.4317626953125,
        300.43243408203125,
        424.6428527832031,
        305.253173828125
      ],
      "text": "0.04"
    },
    {
      "page_no": 11,
      "bbox": [
        415.4317626953125,
        289.0615234375,
        424.6428527832031,
        293.88226318359375
      ],
      "text": "0.06"
    },
    {
      "page_no": 11,
      "bbox": [
        491.93170166015625,
        330.27520751953125,
        542.91455078125,
        335.095947265625
      ],
      "text": "2.6\n2.8\n3.0"
    },
    {
      "page_no": 11,
      "bbox": [
        487.955078125,
        323.1742858886719,
        490.5868225097656,
        327.9950256347656
      ],
      "text": "0"
    },
    {
      "page_no": 11,
      "bbox": [
        487.955078125,
        307.56146240234375,
        490.5868225097656,
        312.3822021484375
      ],
      "text": "1"
    },
    {
      "page_no": 11,
      "bbox": [
        487.955078125,
        291.9486389160156,
        490.5868225097656,
        296.7693786621094
      ],
      "text": "2"
    },
    {
      "page_no": 11,
      "bbox": [
        96.29658508300781,
        378.8507080078125,
        147.27943420410156,
        383.67144775390625
      ],
      "text": "4.1\n4.2\n4.3"
    },
    {
      "page_no": 11,
      "bbox": [
        92.31993103027344,
        371.74981689453125,
        94.95167541503906,
        376.570556640625
      ],
      "text": "0"
    },
    {
      "page_no": 11,
      "bbox": [
        87.05049133300781,
        354.8051452636719,
        94.94572448730469,
        359.6258850097656
      ],
      "text": "200"
    },
    {
      "page_no": 11,
      "bbox": [
        87.05049133300781,
        337.8604736328125,
        94.94572448730469,
        342.68121337890625
      ],
      "text": "400"
    },
    {
      "page_no": 11,
      "bbox": [
        68.2063980102539,
        354.4328308105469,
        74.2322998046875,
        362.46563720703125
      ],
      "text": "S-L"
    },
    {
      "page_no": 11,
      "bbox": [
        79.78837585449219,
        344.0435485839844,
        85.81427764892578,
        372.86444091796875
      ],
      "text": "Latency (s)"
    },
    {
      "page_no": 11,
      "bbox": [
        162.23577880859375,
        378.8507080078125,
        213.2186279296875,
        383.67144775390625
      ],
      "text": "4.1\n4.2\n4.3"
    },
    {
      "page_no": 11,
      "bbox": [
        158.25912475585938,
        371.74981689453125,
        160.890869140625,
        376.570556640625
      ],
      "text": "0"
    },
    {
      "page_no": 11,
      "bbox": [
        155.6243896484375,
        356.7066650390625,
        160.88787841796875,
        361.52740478515625
      ],
      "text": "20"
    },
    {
      "page_no": 11,
      "bbox": [
        155.6243896484375,
        341.6635437011719,
        160.88787841796875,
        346.4842834472656
      ],
      "text": "40"
    },
    {
      "page_no": 11,
      "bbox": [
        228.17495727539062,
        378.8507080078125,
        279.1578063964844,
        383.67144775390625
      ],
      "text": "4.1\n4.2\n4.3"
    },
    {
      "page_no": 11,
      "bbox": [
        224.19830322265625,
        371.74981689453125,
        226.83004760742188,
        376.570556640625
      ],
      "text": "0"
    },
    {
      "page_no": 11,
      "bbox": [
        221.5635986328125,
        360.6728820800781,
        226.82708740234375,
        365.4936218261719
      ],
      "text": "50"
    },
    {
      "page_no": 11,
      "bbox": [
        218.9288787841797,
        349.5959777832031,
        226.82411193847656,
        354.4167175292969
      ],
      "text": "100"
    },
    {
      "page_no": 11,
      "bbox": [
        218.9288787841797,
        338.51904296875,
        226.82411193847656,
        343.33978271484375
      ],
      "text": "150"
    },
    {
      "page_no": 11,
      "bbox": [
        294.1141357421875,
        378.8507080078125,
        345.09698486328125,
        383.67144775390625
      ],
      "text": "4.1\n4.2\n4.3"
    },
    {
      "page_no": 11,
      "bbox": [
        290.13751220703125,
        371.74981689453125,
        292.7692565917969,
        376.570556640625
      ],
      "text": "0"
    },
    {
      "page_no": 11,
      "bbox": [
        290.13751220703125,
        355.5104064941406,
        292.7692565917969,
        360.3311462402344
      ],
      "text": "2"
    },
    {
      "page_no": 11,
      "bbox": [
        290.13751220703125,
        339.27099609375,
        292.7692565917969,
        344.09173583984375
      ],
      "text": "4"
    },
    {
      "page_no": 11,
      "bbox": [
        360.0533447265625,
        378.8507080078125,
        411.03619384765625,
        383.67144775390625
      ],
      "text": "4.1\n4.2\n4.3"
    },
    {
      "page_no": 11,
      "bbox": [
        352.1273193359375,
        371.74981689453125,
        358.7066650390625,
        376.570556640625
      ],
      "text": "0.0"
    },
    {
      "page_no": 11,
      "bbox": [
        352.1273193359375,
        358.5428771972656,
        358.7066650390625,
        363.3636169433594
      ],
      "text": "0.2"
    },
    {
      "page_no": 11,
      "bbox": [
        352.1273193359375,
        345.3359680175781,
        358.7066650390625,
        350.1567077636719
      ],
      "text": "0.4"
    },
    {
      "page_no": 11,
      "bbox": [
        425.9925537109375,
        378.8507080078125,
        476.975341796875,
        383.67144775390625
      ],
      "text": "4.1\n4.2\n4.3"
    },
    {
      "page_no": 11,
      "bbox": [
        412.79705810546875,
        371.74981689453125,
        424.639892578125,
        376.570556640625
      ],
      "text": "0.000"
    },
    {
      "page_no": 11,
      "bbox": [
        412.79705810546875,
        361.6848449707031,
        424.639892578125,
        366.5055847167969
      ],
      "text": "0.025"
    },
    {
      "page_no": 11,
      "bbox": [
        412.79705810546875,
        351.6199035644531,
        424.639892578125,
        356.4406433105469
      ],
      "text": "0.050"
    },
    {
      "page_no": 11,
      "bbox": [
        412.79705810546875,
        341.554931640625,
        424.639892578125,
        346.37567138671875
      ],
      "text": "0.075"
    },
    {
      "page_no": 11,
      "bbox": [
        491.93170166015625,
        378.8507080078125,
        542.91455078125,
        383.67144775390625
      ],
      "text": "4.1\n4.2\n4.3"
    },
    {
      "page_no": 11,
      "bbox": [
        487.955078125,
        371.74981689453125,
        490.5868225097656,
        376.570556640625
      ],
      "text": "0"
    },
    {
      "page_no": 11,
      "bbox": [
        487.955078125,
        354.0090026855469,
        490.5868225097656,
        358.8297424316406
      ],
      "text": "5"
    },
    {
      "page_no": 11,
      "bbox": [
        96.95391082763672,
        427.4262390136719,
        139.05020141601562,
        438.66033935546875
      ],
      "text": "10\n15\nRequest Rate"
    },
    {
      "page_no": 11,
      "bbox": [
        92.31993103027344,
        420.3253173828125,
        94.95167541503906,
        425.14605712890625
      ],
      "text": "0"
    },
    {
      "page_no": 11,
      "bbox": [
        87.05049133300781,
        406.3122253417969,
        94.94572448730469,
        411.1329650878906
      ],
      "text": "100"
    },
    {
      "page_no": 11,
      "bbox": [
        87.05049133300781,
        392.29913330078125,
        94.94572448730469,
        397.119873046875
      ],
      "text": "200"
    },
    {
      "page_no": 11,
      "bbox": [
        68.2063980102539,
        403.05145263671875,
        74.2322998046875,
        410.9980773925781
      ],
      "text": "L-S"
    },
    {
      "page_no": 11,
      "bbox": [
        79.78837585449219,
        392.6190490722656,
        85.81427764892578,
        421.43994140625
      ],
      "text": "Latency (s)"
    },
    {
      "page_no": 11,
      "bbox": [
        162.89309692382812,
        427.4262390136719,
        204.9893798828125,
        438.66033935546875
      ],
      "text": "10\n15\nRequest Rate"
    },
    {
      "page_no": 11,
      "bbox": [
        158.25912475585938,
        420.3253173828125,
        160.890869140625,
        425.14605712890625
      ],
      "text": "0"
    },
    {
      "page_no": 11,
      "bbox": [
        155.6243896484375,
        407.25030517578125,
        160.88787841796875,
        412.071044921875
      ],
      "text": "10"
    },
    {
      "page_no": 11,
      "bbox": [
        155.6243896484375,
        394.17529296875,
        160.88787841796875,
        398.99603271484375
      ],
      "text": "20"
    },
    {
      "page_no": 11,
      "bbox": [
        228.83229064941406,
        427.4262390136719,
        270.9285888671875,
        438.66033935546875
      ],
      "text": "10\n15\nRequest Rate"
    },
    {
      "page_no": 11,
      "bbox": [
        224.19830322265625,
        420.3253173828125,
        226.83004760742188,
        425.14605712890625
      ],
      "text": "0"
    },
    {
      "page_no": 11,
      "bbox": [
        218.9288787841797,
        405.899658203125,
        226.82411193847656,
        410.72039794921875
      ],
      "text": "100"
    },
    {
      "page_no": 11,
      "bbox": [
        218.9288787841797,
        391.4739685058594,
        226.82411193847656,
        396.2947082519531
      ],
      "text": "200"
    },
    {
      "page_no": 11,
      "bbox": [
        294.771484375,
        427.4262390136719,
        336.8677673339844,
        438.66033935546875
      ],
      "text": "10\n15\nRequest Rate"
    },
    {
      "page_no": 11,
      "bbox": [
        290.13751220703125,
        420.3253173828125,
        292.7692565917969,
        425.14605712890625
      ],
      "text": "0"
    },
    {
      "page_no": 11,
      "bbox": [
        290.13751220703125,
        410.34527587890625,
        292.7692565917969,
        415.166015625
      ],
      "text": "5"
    },
    {
      "page_no": 11,
      "bbox": [
        287.5027770996094,
        400.3652648925781,
        292.7662658691406,
        405.1860046386719
      ],
      "text": "10"
    },
    {
      "page_no": 11,
      "bbox": [
        287.5027770996094,
        390.3852233886719,
        292.7662658691406,
        395.2059631347656
      ],
      "text": "15"
    },
    {
      "page_no": 11,
      "bbox": [
        360.710693359375,
        427.4262390136719,
        402.8069763183594,
        438.66033935546875
      ],
      "text": "10\n15\nRequest Rate"
    },
    {
      "page_no": 11,
      "bbox": [
        349.49261474609375,
        420.3253173828125,
        358.7037048339844,
        425.14605712890625
      ],
      "text": "0.00"
    },
    {
      "page_no": 11,
      "bbox": [
        349.49261474609375,
        409.3601379394531,
        358.7037048339844,
        414.1808776855469
      ],
      "text": "0.05"
    },
    {
      "page_no": 11,
      "bbox": [
        349.49261474609375,
        398.39495849609375,
        358.7037048339844,
        403.2156982421875
      ],
      "text": "0.10"
    },
    {
      "page_no": 11,
      "bbox": [
        349.49261474609375,
        387.4297790527344,
        358.7037048339844,
        392.2505187988281
      ],
      "text": "0.15"
    },
    {
      "page_no": 11,
      "bbox": [
        426.64984130859375,
        427.4262390136719,
        468.7461853027344,
        438.66033935546875
      ],
      "text": "10\n15\nRequest Rate"
    },
    {
      "page_no": 11,
      "bbox": [
        412.79705810546875,
        420.3253173828125,
        424.639892578125,
        425.14605712890625
      ],
      "text": "0.000"
    },
    {
      "page_no": 11,
      "bbox": [
        412.79705810546875,
        408.8028259277344,
        424.639892578125,
        413.6235656738281
      ],
      "text": "0.025"
    },
    {
      "page_no": 11,
      "bbox": [
        412.79705810546875,
        397.28033447265625,
        424.639892578125,
        402.10107421875
      ],
      "text": "0.050"
    },
    {
      "page_no": 11,
      "bbox": [
        492.58905029296875,
        427.4262390136719,
        534.685302734375,
        438.66033935546875
      ],
      "text": "10\n15\nRequest Rate"
    },
    {
      "page_no": 11,
      "bbox": [
        484.00567626953125,
        420.3253173828125,
        490.58502197265625,
        425.14605712890625
      ],
      "text": "0.0"
    },
    {
      "page_no": 11,
      "bbox": [
        484.00567626953125,
        403.89117431640625,
        490.58502197265625,
        408.7119140625
      ],
      "text": "0.1"
    },
    {
      "page_no": 11,
      "bbox": [
        484.00567626953125,
        387.4570617675781,
        490.58502197265625,
        392.2778015136719
      ],
      "text": "0.2"
    },
    {
      "page_no": 11,
      "bbox": [
        255.159423828125,
        75.67721557617188,
        384.1797180175781,
        81.70311737060547
      ],
      "text": "Llumnix\nINFaaS++\nRound-Robin"
    },
    {
      "page_no": 11,
      "bbox": [
        54.0,
        451.79815673828125,
        558.3607788085938,
        473.6930847167969
      ],
      "text": "Figure 11: Request end-to-end, prefill, and decode latencies and preemption loss of serving 16 LLaMA-7B instances. Each row\nshows a set of experiments using a trace with a specific sequence length distribution, as annotated on the Y-axis labels."
    },
    {
      "page_no": 11,
      "bbox": [
        98.64666748046875,
        568.3270874023438,
        264.39093017578125,
        578.9067993164062
      ],
      "text": "600\n650\n700\n750\n800\n850\n900\n950\n1000\nTime (s)"
    },
    {
      "page_no": 11,
      "bbox": [
        89.31160736083984,
        561.0245361328125,
        91.7740707397461,
        565.5352172851562
      ],
      "text": "0"
    },
    {
      "page_no": 11,
      "bbox": [
        89.31160736083984,
        546.0321655273438,
        91.7740707397461,
        550.5428466796875
      ],
      "text": "5"
    },
    {
      "page_no": 11,
      "bbox": [
        86.8493881225586,
        531.0398559570312,
        91.7743148803711,
        535.550537109375
      ],
      "text": "10"
    },
    {
      "page_no": 11,
      "bbox": [
        86.8493881225586,
        516.0474853515625,
        91.7743148803711,
        520.5581665039062
      ],
      "text": "15"
    },
    {
      "page_no": 11,
      "bbox": [
        86.8493881225586,
        501.0552062988281,
        91.7743148803711,
        505.56585693359375
      ],
      "text": "20"
    },
    {
      "page_no": 11,
      "bbox": [
        80.01643371582031,
        497.464111328125,
        85.42921447753906,
        566.38818359375
      ],
      "text": "Fragmentation Proportion (%)"
    },
    {
      "page_no": 11,
      "bbox": [
        187.5791015625,
        501.5473937988281,
        262.4458923339844,
        507.8623046875
      ],
      "text": "INFaaS++\nLlumnix"
    },
    {
      "page_no": 11,
      "bbox": [
        84.55599975585938,
        592.3414306640625,
        263.5639953613281,
        602.3040161132812
      ],
      "text": "Figure 12: Memory fragmentation over time."
    },
    {
      "page_no": 11,
      "bbox": [
        54.0,
        627.8229370117188,
        295.7699890136719,
        722.4298095703125
      ],
      "text": "ing requests to instances with the lowest load, INFaaS++ can\nstill exhibit long queuing delays due to fragmentation, espe-\ncially for the long-tail requests with long inputs. Llumnix\nuses migration for de-fragmentation to reduce such queuing\ndelays, showing more gains in traces with more long inputs.\nTo take a closer look at the memory fragmentation, we\nfurther present a case study on the experiment of the M-M\ntrace with the request rate of 7.5. We define the fragmented"
    },
    {
      "page_no": 11,
      "bbox": [
        317.4119873046875,
        497.2814025878906,
        559.7472534179688,
        722.4310302734375
      ],
      "text": "memory at each moment as the portion of cluster free memory\nthat could satisfy the demands of the head-of-line blocking\nrequests across all instances, if no fragmentation. For exam-\nple, if the total free memory is 8 GB, with three head-of-line\nblocking requests each requiring 3 GB, then the fragmented\nmemory is counted as 6 GB, i.e., this 6 GB memory could\nsatisfy two queuing requests if no fragmentation. This metric\nsuggests the memory space wasted due to fragmentation. We\nreport the proportion of fragmented memory in the cluster\ntotal memory. In the example, if the total memory is 16 GB,\nthen the proportion is 37.5% (6/16). Figure 12 shows the frag-\nmentation proportion of the experiment during a busy period.\nWe observe that INFaaS++ often shows higher than 10% frag-\nmentation, wasting a significant amount of cluster memory.\nIn comparison, the fragmentation is often 0 in Llumnix. The\naverage values during this period are 0.7% and 7.9% for Llum-\nnix and INFaaS++ respectively (92% reduction), highlighting\nthe effect of de-fragmentation using migration.\nLlumnix also improves the P99 decode latency by up to"
    },
    {
      "page_no": 11,
      "bbox": [
        301.0190124511719,
        742.3324584960938,
        310.9815979003906,
        752.2950439453125
      ],
      "text": "11"
    },
    {
      "page_no": 12,
      "bbox": [
        95.84727478027344,
        131.1448974609375,
        142.86614990234375,
        135.9639434814453
      ],
      "text": "2\n4\n6\n8"
    },
    {
      "page_no": 12,
      "bbox": [
        89.89800262451172,
        123.90906524658203,
        92.5288314819336,
        128.7281036376953
      ],
      "text": "0"
    },
    {
      "page_no": 12,
      "bbox": [
        87.26420593261719,
        113.94134521484375,
        92.52586364746094,
        118.76039123535156
      ],
      "text": "25"
    },
    {
      "page_no": 12,
      "bbox": [
        87.26420593261719,
        103.9736328125,
        92.52586364746094,
        108.79267883300781
      ],
      "text": "50"
    },
    {
      "page_no": 12,
      "bbox": [
        87.26420593261719,
        94.00590515136719,
        92.52586364746094,
        98.824951171875
      ],
      "text": "75"
    },
    {
      "page_no": 12,
      "bbox": [
        68.42666625976562,
        93.95748138427734,
        74.45047760009766,
        125.89830780029297
      ],
      "text": "High Priority"
    },
    {
      "page_no": 12,
      "bbox": [
        80.0046157836914,
        95.52547454833984,
        86.02842712402344,
        124.33634185791016
      ],
      "text": "Latency (s)"
    },
    {
      "page_no": 12,
      "bbox": [
        103.17567443847656,
        83.5560073852539,
        135.5191650390625,
        89.57981872558594
      ],
      "text": "Request P99"
    },
    {
      "page_no": 12,
      "bbox": [
        161.76351928710938,
        131.1448974609375,
        208.78237915039062,
        135.9639434814453
      ],
      "text": "2\n4\n6\n8"
    },
    {
      "page_no": 12,
      "bbox": [
        155.81423950195312,
        123.90906524658203,
        158.445068359375,
        128.7281036376953
      ],
      "text": "0"
    },
    {
      "page_no": 12,
      "bbox": [
        155.81423950195312,
        105.1834487915039,
        158.445068359375,
        110.00249481201172
      ],
      "text": "5"
    },
    {
      "page_no": 12,
      "bbox": [
        166.8970947265625,
        83.5560073852539,
        203.63565063476562,
        89.57981872558594
      ],
      "text": "Request Mean"
    },
    {
      "page_no": 12,
      "bbox": [
        227.67974853515625,
        131.1448974609375,
        274.6986389160156,
        135.9639434814453
      ],
      "text": "2\n4\n6\n8"
    },
    {
      "page_no": 12,
      "bbox": [
        221.73049926757812,
        123.90906524658203,
        224.361328125,
        128.7281036376953
      ],
      "text": "0"
    },
    {
      "page_no": 12,
      "bbox": [
        221.73049926757812,
        106.4671630859375,
        224.361328125,
        111.28620910644531
      ],
      "text": "5"
    },
    {
      "page_no": 12,
      "bbox": [
        219.0966796875,
        89.02525329589844,
        224.35833740234375,
        93.84429931640625
      ],
      "text": "10"
    },
    {
      "page_no": 12,
      "bbox": [
        238.3448486328125,
        83.5560073852539,
        264.0401916503906,
        89.57981872558594
      ],
      "text": "Prefill P99"
    },
    {
      "page_no": 12,
      "bbox": [
        293.59600830078125,
        131.1448974609375,
        340.6148681640625,
        135.9639434814453
      ],
      "text": "2\n4\n6\n8"
    },
    {
      "page_no": 12,
      "bbox": [
        283.6986999511719,
        123.90906524658203,
        290.2757568359375,
        128.7281036376953
      ],
      "text": "0.0"
    },
    {
      "page_no": 12,
      "bbox": [
        283.6986999511719,
        112.9648666381836,
        290.2757568359375,
        117.7839126586914
      ],
      "text": "0.5"
    },
    {
      "page_no": 12,
      "bbox": [
        283.6986999511719,
        102.02066802978516,
        290.2757568359375,
        106.83971405029297
      ],
      "text": "1.0"
    },
    {
      "page_no": 12,
      "bbox": [
        283.6986999511719,
        91.07647705078125,
        290.2757568359375,
        95.89552307128906
      ],
      "text": "1.5"
    },
    {
      "page_no": 12,
      "bbox": [
        302.0662536621094,
        83.5560073852539,
        332.1566467285156,
        89.57981872558594
      ],
      "text": "Prefill Mean"
    },
    {
      "page_no": 12,
      "bbox": [
        359.5122375488281,
        131.1448974609375,
        406.5310974121094,
        135.9639434814453
      ],
      "text": "2\n4\n6\n8"
    },
    {
      "page_no": 12,
      "bbox": [
        346.9811706542969,
        123.90906524658203,
        356.1890563964844,
        128.7281036376953
      ],
      "text": "0.00"
    },
    {
      "page_no": 12,
      "bbox": [
        346.9811706542969,
        112.99373626708984,
        356.1890563964844,
        117.81278228759766
      ],
      "text": "0.05"
    },
    {
      "page_no": 12,
      "bbox": [
        346.9811706542969,
        102.07839965820312,
        356.1890563964844,
        106.89744567871094
      ],
      "text": "0.10"
    },
    {
      "page_no": 12,
      "bbox": [
        346.9811706542969,
        91.16307067871094,
        356.1890563964844,
        95.98211669921875
      ],
      "text": "0.15"
    },
    {
      "page_no": 12,
      "bbox": [
        367.5354309082031,
        83.5560073852539,
        398.50762939453125,
        89.57981872558594
      ],
      "text": "Decode P99"
    },
    {
      "page_no": 12,
      "bbox": [
        425.428466796875,
        131.1448974609375,
        472.44732666015625,
        135.9639434814453
      ],
      "text": "2\n4\n6\n8"
    },
    {
      "page_no": 12,
      "bbox": [
        410.26361083984375,
        123.90906524658203,
        422.1023254394531,
        128.7281036376953
      ],
      "text": "0.000"
    },
    {
      "page_no": 12,
      "bbox": [
        410.26361083984375,
        112.47528076171875,
        422.1023254394531,
        117.29432678222656
      ],
      "text": "0.025"
    },
    {
      "page_no": 12,
      "bbox": [
        410.26361083984375,
        101.04150390625,
        422.1023254394531,
        105.86054992675781
      ],
      "text": "0.050"
    },
    {
      "page_no": 12,
      "bbox": [
        410.26361083984375,
        89.60771179199219,
        422.1023254394531,
        94.4267578125
      ],
      "text": "0.075"
    },
    {
      "page_no": 12,
      "bbox": [
        431.2568664550781,
        83.5560073852539,
        466.6241149902344,
        89.57981872558594
      ],
      "text": "Decode Mean"
    },
    {
      "page_no": 12,
      "bbox": [
        491.3447265625,
        131.1448974609375,
        538.363525390625,
        135.9639434814453
      ],
      "text": "2\n4\n6\n8"
    },
    {
      "page_no": 12,
      "bbox": [
        481.4474182128906,
        123.90906524658203,
        488.02447509765625,
        128.7281036376953
      ],
      "text": "0.0"
    },
    {
      "page_no": 12,
      "bbox": [
        481.4474182128906,
        111.82356262207031,
        488.02447509765625,
        116.64260864257812
      ],
      "text": "2.5"
    },
    {
      "page_no": 12,
      "bbox": [
        481.4474182128906,
        99.73806762695312,
        488.02447509765625,
        104.55711364746094
      ],
      "text": "5.0"
    },
    {
      "page_no": 12,
      "bbox": [
        484.39190673828125,
        83.5560073852539,
        545.3516845703125,
        89.57981872558594
      ],
      "text": "Decode Execution Time"
    },
    {
      "page_no": 12,
      "bbox": [
        95.84727478027344,
        187.697021484375,
        142.86614990234375,
        198.92721557617188
      ],
      "text": "2\n4\n6\n8\nCV"
    },
    {
      "page_no": 12,
      "bbox": [
        89.89800262451172,
        180.46119689941406,
        92.5288314819336,
        185.28024291992188
      ],
      "text": "0"
    },
    {
      "page_no": 12,
      "bbox": [
        87.26420593261719,
        162.92605590820312,
        92.52586364746094,
        167.74510192871094
      ],
      "text": "50"
    },
    {
      "page_no": 12,
      "bbox": [
        84.63040161132812,
        145.39089965820312,
        92.52288055419922,
        150.20994567871094
      ],
      "text": "100"
    },
    {
      "page_no": 12,
      "bbox": [
        65.79286193847656,
        157.12200927734375,
        71.8166732788086,
        175.83631896972656
      ],
      "text": "Normal"
    },
    {
      "page_no": 12,
      "bbox": [
        77.37081146240234,
        152.07760620117188,
        83.39462280273438,
        180.8884735107422
      ],
      "text": "Latency (s)"
    },
    {
      "page_no": 12,
      "bbox": [
        161.76351928710938,
        187.697021484375,
        208.78237915039062,
        198.92721557617188
      ],
      "text": "2\n4\n6\n8\nCV"
    },
    {
      "page_no": 12,
      "bbox": [
        155.81423950195312,
        180.46119689941406,
        158.445068359375,
        185.28024291992188
      ],
      "text": "0"
    },
    {
      "page_no": 12,
      "bbox": [
        155.81423950195312,
        163.35775756835938,
        158.445068359375,
        168.1768035888672
      ],
      "text": "5"
    },
    {
      "page_no": 12,
      "bbox": [
        153.18045043945312,
        146.25433349609375,
        158.44210815429688,
        151.07337951660156
      ],
      "text": "10"
    },
    {
      "page_no": 12,
      "bbox": [
        227.67974853515625,
        187.697021484375,
        274.6986389160156,
        198.92721557617188
      ],
      "text": "2\n4\n6\n8\nCV"
    },
    {
      "page_no": 12,
      "bbox": [
        221.73049926757812,
        180.46119689941406,
        224.361328125,
        185.28024291992188
      ],
      "text": "0"
    },
    {
      "page_no": 12,
      "bbox": [
        221.73049926757812,
        166.72474670410156,
        224.361328125,
        171.54379272460938
      ],
      "text": "5"
    },
    {
      "page_no": 12,
      "bbox": [
        219.0966796875,
        152.98831176757812,
        224.35833740234375,
        157.80735778808594
      ],
      "text": "10"
    },
    {
      "page_no": 12,
      "bbox": [
        293.59600830078125,
        187.697021484375,
        340.6148681640625,
        198.92721557617188
      ],
      "text": "2\n4\n6\n8\nCV"
    },
    {
      "page_no": 12,
      "bbox": [
        287.646728515625,
        180.46119689941406,
        290.2775573730469,
        185.28024291992188
      ],
      "text": "0"
    },
    {
      "page_no": 12,
      "bbox": [
        287.646728515625,
        161.9734344482422,
        290.2775573730469,
        166.79248046875
      ],
      "text": "1"
    },
    {
      "page_no": 12,
      "bbox": [
        359.5122375488281,
        187.697021484375,
        406.5310974121094,
        198.92721557617188
      ],
      "text": "2\n4\n6\n8\nCV"
    },
    {
      "page_no": 12,
      "bbox": [
        346.9811706542969,
        180.46119689941406,
        356.1890563964844,
        185.28024291992188
      ],
      "text": "0.00"
    },
    {
      "page_no": 12,
      "bbox": [
        346.9811706542969,
        169.78858947753906,
        356.1890563964844,
        174.60763549804688
      ],
      "text": "0.05"
    },
    {
      "page_no": 12,
      "bbox": [
        346.9811706542969,
        159.11599731445312,
        356.1890563964844,
        163.93504333496094
      ],
      "text": "0.10"
    },
    {
      "page_no": 12,
      "bbox": [
        346.9811706542969,
        148.44338989257812,
        356.1890563964844,
        153.26243591308594
      ],
      "text": "0.15"
    },
    {
      "page_no": 12,
      "bbox": [
        425.428466796875,
        187.697021484375,
        472.44732666015625,
        198.92721557617188
      ],
      "text": "2\n4\n6\n8\nCV"
    },
    {
      "page_no": 12,
      "bbox": [
        410.26361083984375,
        180.46119689941406,
        422.1023254394531,
        185.28024291992188
      ],
      "text": "0.000"
    },
    {
      "page_no": 12,
      "bbox": [
        410.26361083984375,
        169.16839599609375,
        422.1023254394531,
        173.98744201660156
      ],
      "text": "0.025"
    },
    {
      "page_no": 12,
      "bbox": [
        410.26361083984375,
        157.8756103515625,
        422.1023254394531,
        162.6946563720703
      ],
      "text": "0.050"
    },
    {
      "page_no": 12,
      "bbox": [
        410.26361083984375,
        146.58282470703125,
        422.1023254394531,
        151.40187072753906
      ],
      "text": "0.075"
    },
    {
      "page_no": 12,
      "bbox": [
        491.3447265625,
        187.697021484375,
        538.363525390625,
        198.92721557617188
      ],
      "text": "2\n4\n6\n8\nCV"
    },
    {
      "page_no": 12,
      "bbox": [
        481.4474182128906,
        180.46119689941406,
        488.02447509765625,
        185.28024291992188
      ],
      "text": "0.0"
    },
    {
      "page_no": 12,
      "bbox": [
        481.4474182128906,
        168.96917724609375,
        488.02447509765625,
        173.78822326660156
      ],
      "text": "2.5"
    },
    {
      "page_no": 12,
      "bbox": [
        481.4474182128906,
        157.47715759277344,
        488.02447509765625,
        162.29620361328125
      ],
      "text": "5.0"
    },
    {
      "page_no": 12,
      "bbox": [
        481.4474182128906,
        145.98513793945312,
        488.02447509765625,
        150.80418395996094
      ],
      "text": "7.5"
    },
    {
      "page_no": 12,
      "bbox": [
        277.2629699707031,
        73.68868255615234,
        357.0909118652344,
        79.71249389648438
      ],
      "text": "Llumnix-base\nLlumnix"
    },
    {
      "page_no": 12,
      "bbox": [
        116.3280029296875,
        208.59547424316406,
        495.67388916015625,
        218.55807495117188
      ],
      "text": "Figure 13: Performance of high-priority and normal requests, as annotated on the Y-axis labels."
    },
    {
      "page_no": 12,
      "bbox": [
        53.64099884033203,
        241.7097930908203,
        295.85955810546875,
        347.6730651855469
      ],
      "text": "2×, through migration to reduce preemptions. Although IN-\nFaaS++ already implements load balancing in dispatching to\nreduce preemptions, migration complements it by reacting\nto the real sequence lengths, which are unknown at request\narrivals. As shown in Figure 11, Llumnix significantly re-\nduces the preemption loss, in many cases down to near zero.\nThe reduction is 70.4% on average across all experiments,\nwhich translates to an average reduction of 1.3 seconds in the\nend-to-end request latency."
    },
    {
      "page_no": 12,
      "bbox": [
        54.0,
        367.7161560058594,
        191.5087127685547,
        379.6713562011719
      ],
      "text": "6.4\nSupport for Priorities"
    },
    {
      "page_no": 12,
      "bbox": [
        53.25299835205078,
        389.1654052734375,
        295.7777404785156,
        722.4310302734375
      ],
      "text": "We evaluate the support for priorities of Llumnix by randomly\npicking 10% of the requests and assigning high scheduling\nand execution priorities. We use traces with the Short-Short\nlength distribution and Gamma arrival distribution. We vary\nthe CV parameter to show the interference to high-priority\nrequests due to bursty workloads and load spikes. We em-\npirically choose a target memory load of 1,600 tokens for\nhigh-priority requests, as we observe that such load preserves\nnear-ideal decode speed (refer to Figure 4). Llumnix translates\nthis target load to the corresponding memory headroom for\nhigh-priority requests. We compare Llumnix with Llumnix-\nbase, which simply treats all requests as the same priority.\nAs shown in the first row in Figure 13, Llumnix improves\nmean request latencies for the high-priority by 1.2× to 1.5×\nwith increasing CVs. Higher CVs leads to more high-load\nperiods, where high-priority requests can suffer more inter-\nference if not protected. Even with higher CVs, Llumnix still\ndelivers similar latencies of high-priority requests, showing\nthe isolation Llumnix provides to such requests. This is be-\ncause Llumnix can handle changing high-priority loads by\ndynamically creating space for them, which is difficult in ap-\nproaches like static resource reservation. For prefill latencies,\nLlumnix shows 2.9× to 8.6× gains for the mean, and 3.6× to\n10× for the P99, respectively. This is achieved by reducing\nthe queuing delays with high scheduling priorities. Llumnix\nalso improves decode latencies by 1.2× to 1.5× for the mean\nand 1.3× to 2.2× for the P99, respectively. This improvement\ncomes from the acceleration of the decode computation by"
    },
    {
      "page_no": 12,
      "bbox": [
        317.8800048828125,
        242.14540100097656,
        558.0047607421875,
        323.7630615234375
      ],
      "text": "giving lower instance loads and interference to high execution\npriorities, shown by the similar gains in the average decode\ncomputation time (the rightmost column). We also notice\nthat Llumnix preserves similar performance of the normal\nrequests (the second row in Figure 13): Llumnix increases the\nmean request, prefill, and decode latencies of normal requests\nby up to 4.5%, 13%, and 2%, respectively."
    },
    {
      "page_no": 12,
      "bbox": [
        317.8800048828125,
        343.47515869140625,
        408.6080322265625,
        355.43035888671875
      ],
      "text": "6.5\nAuto-scaling"
    },
    {
      "page_no": 12,
      "bbox": [
        317.13299560546875,
        364.6593017578125,
        559.7470092773438,
        722.3828735351562
      ],
      "text": "We evaluate the auto-scaling capability of Llumnix using\nlarger ranges of request rates and Gamma CVs to show the\nadaptivity to load variation. By default, Llumnix uses a scaling\nthreshold range of [10, 60], i.e., Llumnix scales instances up\nor down when the average freeness is under 10 or above\n60; recall that this metric represents the most decode steps\nan instance can still run for given the current batch. We let\nINFaaS++ use the same scaling strategy, thus both Llumnix\nand INFaaS++ have the same degree of aggressiveness of\nscaling up instances. We use a maximum instance number of\n16 and the Long-Long sequence length distribution.\nWe first vary the request rates using Poisson distribution.\nAs shown in the first row of Figure 14, Llumnix consistently\nachieves latency improvements across all request rates, e.g.,\nup to 12.2× for P99 prefill latency. We also measure the\nresource cost in terms of average instances used, shown in the\nrightmost column. Llumnix saves costs by up to 16%, because\nLlumnix increases the auto-scaling efficiency by saturating\nor draining out instances more quickly. We also test different\nworkload burstiness with varying CVs of Gamma distribution\n(request rate = 2). As shown in the second row, Llumnix\nshows similar improvements in latencies and costs, e.g., up to\n11× for P99 prefill latency and 18% for the cost.\nFinally, we examine the cost efficiency of Llumnix in terms\nof how aggressively Llumnix needs to scale out instances to\npreserve a certain latency objective, e.g., a given P99 prefill\nlatency. We vary the scaling up threshold t, and the scaling\nthreshold range is determined as [t, t+50]. Higher values of t\nmeans that Llumnix tends to use more instances. Figure 15\nshows the P99 prefill latencies and costs with different scaling"
    },
    {
      "page_no": 12,
      "bbox": [
        301.0190124511719,
        742.3324584960938,
        310.9815979003906,
        752.2950439453125
      ],
      "text": "12"
    },
    {
      "page_no": 13,
      "bbox": [
        96.29658508300781,
        133.1514129638672,
        147.27943420410156,
        137.97213745117188
      ],
      "text": "2.0 2.2 2.4 2.6 2.8 3.0"
    },
    {
      "page_no": 13,
      "bbox": [
        104.53271484375,
        138.35958862304688,
        139.05020141601562,
        144.385498046875
      ],
      "text": "Request Rate"
    },
    {
      "page_no": 13,
      "bbox": [
        92.31993103027344,
        125.91307067871094,
        94.95167541503906,
        130.73379516601562
      ],
      "text": "0"
    },
    {
      "page_no": 13,
      "bbox": [
        87.05049133300781,
        114.54389190673828,
        94.94572448730469,
        119.36460876464844
      ],
      "text": "100"
    },
    {
      "page_no": 13,
      "bbox": [
        87.05049133300781,
        103.17471313476562,
        94.94572448730469,
        107.99542999267578
      ],
      "text": "200"
    },
    {
      "page_no": 13,
      "bbox": [
        87.05049133300781,
        91.8055419921875,
        94.94572448730469,
        96.62625885009766
      ],
      "text": "300"
    },
    {
      "page_no": 13,
      "bbox": [
        68.2063980102539,
        102.24407958984375,
        74.2322998046875,
        121.61792755126953
      ],
      "text": "Poisson"
    },
    {
      "page_no": 13,
      "bbox": [
        79.78837585449219,
        97.51959228515625,
        85.81427764892578,
        126.34048461914062
      ],
      "text": "Latency (s)"
    },
    {
      "page_no": 13,
      "bbox": [
        105.60221862792969,
        85.54595947265625,
        137.95697021484375,
        91.57186126708984
      ],
      "text": "Request P99"
    },
    {
      "page_no": 13,
      "bbox": [
        162.23577880859375,
        133.1514129638672,
        213.2186279296875,
        137.97213745117188
      ],
      "text": "2.0 2.2 2.4 2.6 2.8 3.0"
    },
    {
      "page_no": 13,
      "bbox": [
        170.47189331054688,
        138.35958862304688,
        204.9893798828125,
        144.385498046875
      ],
      "text": "Request Rate"
    },
    {
      "page_no": 13,
      "bbox": [
        158.25912475585938,
        125.91307067871094,
        160.890869140625,
        130.73379516601562
      ],
      "text": "0"
    },
    {
      "page_no": 13,
      "bbox": [
        155.6243896484375,
        115.35575103759766,
        160.88787841796875,
        120.17646789550781
      ],
      "text": "10"
    },
    {
      "page_no": 13,
      "bbox": [
        155.6243896484375,
        104.7984390258789,
        160.88787841796875,
        109.61915588378906
      ],
      "text": "20"
    },
    {
      "page_no": 13,
      "bbox": [
        155.6243896484375,
        94.2411117553711,
        160.88787841796875,
        99.06182861328125
      ],
      "text": "30"
    },
    {
      "page_no": 13,
      "bbox": [
        169.3458251953125,
        85.54595947265625,
        206.09715270996094,
        91.57186126708984
      ],
      "text": "Request Mean"
    },
    {
      "page_no": 13,
      "bbox": [
        228.17495727539062,
        133.1514129638672,
        279.1578063964844,
        137.97213745117188
      ],
      "text": "2.0 2.2 2.4 2.6 2.8 3.0"
    },
    {
      "page_no": 13,
      "bbox": [
        236.41110229492188,
        138.35958862304688,
        270.9285888671875,
        144.385498046875
      ],
      "text": "Request Rate"
    },
    {
      "page_no": 13,
      "bbox": [
        224.19830322265625,
        125.91307067871094,
        226.83004760742188,
        130.73379516601562
      ],
      "text": "0"
    },
    {
      "page_no": 13,
      "bbox": [
        221.5635986328125,
        115.9531478881836,
        226.82708740234375,
        120.77386474609375
      ],
      "text": "20"
    },
    {
      "page_no": 13,
      "bbox": [
        221.5635986328125,
        105.99323272705078,
        226.82708740234375,
        110.81394958496094
      ],
      "text": "40"
    },
    {
      "page_no": 13,
      "bbox": [
        221.5635986328125,
        96.03331756591797,
        226.82708740234375,
        100.85403442382812
      ],
      "text": "60"
    },
    {
      "page_no": 13,
      "bbox": [
        240.81845092773438,
        85.54595947265625,
        266.5227355957031,
        91.57186126708984
      ],
      "text": "Prefill P99"
    },
    {
      "page_no": 13,
      "bbox": [
        294.1141357421875,
        133.1514129638672,
        345.09698486328125,
        137.97213745117188
      ],
      "text": "2.0 2.2 2.4 2.6 2.8 3.0"
    },
    {
      "page_no": 13,
      "bbox": [
        302.35028076171875,
        138.35958862304688,
        336.8677673339844,
        144.385498046875
      ],
      "text": "Request Rate"
    },
    {
      "page_no": 13,
      "bbox": [
        290.13751220703125,
        125.91307067871094,
        292.7692565917969,
        130.73379516601562
      ],
      "text": "0"
    },
    {
      "page_no": 13,
      "bbox": [
        290.13751220703125,
        110.23419189453125,
        292.7692565917969,
        115.0549087524414
      ],
      "text": "1"
    },
    {
      "page_no": 13,
      "bbox": [
        290.13751220703125,
        94.55533599853516,
        292.7692565917969,
        99.37605285644531
      ],
      "text": "2"
    },
    {
      "page_no": 13,
      "bbox": [
        304.56207275390625,
        85.54595947265625,
        334.6629333496094,
        91.57186126708984
      ],
      "text": "Prefill Mean"
    },
    {
      "page_no": 13,
      "bbox": [
        360.0533447265625,
        133.1514129638672,
        411.03619384765625,
        137.97213745117188
      ],
      "text": "2.0 2.2 2.4 2.6 2.8 3.0"
    },
    {
      "page_no": 13,
      "bbox": [
        368.28948974609375,
        138.35958862304688,
        402.8069763183594,
        144.385498046875
      ],
      "text": "Request Rate"
    },
    {
      "page_no": 13,
      "bbox": [
        349.49261474609375,
        125.91307067871094,
        358.7037048339844,
        130.73379516601562
      ],
      "text": "0.00"
    },
    {
      "page_no": 13,
      "bbox": [
        349.49261474609375,
        115.5165023803711,
        358.7037048339844,
        120.33721923828125
      ],
      "text": "0.05"
    },
    {
      "page_no": 13,
      "bbox": [
        349.49261474609375,
        105.11992645263672,
        358.7037048339844,
        109.94064331054688
      ],
      "text": "0.10"
    },
    {
      "page_no": 13,
      "bbox": [
        349.49261474609375,
        94.72337341308594,
        358.7037048339844,
        99.5440902709961
      ],
      "text": "0.15"
    },
    {
      "page_no": 13,
      "bbox": [
        370.05401611328125,
        85.54595947265625,
        401.0369873046875,
        91.57186126708984
      ],
      "text": "Decode P99"
    },
    {
      "page_no": 13,
      "bbox": [
        425.9925537109375,
        133.1514129638672,
        476.975341796875,
        137.97213745117188
      ],
      "text": "2.0 2.2 2.4 2.6 2.8 3.0"
    },
    {
      "page_no": 13,
      "bbox": [
        434.22869873046875,
        138.35958862304688,
        468.7461853027344,
        144.385498046875
      ],
      "text": "Request Rate"
    },
    {
      "page_no": 13,
      "bbox": [
        415.4317626953125,
        125.91307067871094,
        424.6428527832031,
        130.73379516601562
      ],
      "text": "0.00"
    },
    {
      "page_no": 13,
      "bbox": [
        415.4317626953125,
        114.41992950439453,
        424.6428527832031,
        119.24064636230469
      ],
      "text": "0.02"
    },
    {
      "page_no": 13,
      "bbox": [
        415.4317626953125,
        102.92679595947266,
        424.6428527832031,
        107.74751281738281
      ],
      "text": "0.04"
    },
    {
      "page_no": 13,
      "bbox": [
        415.4317626953125,
        91.43367004394531,
        424.6428527832031,
        96.25438690185547
      ],
      "text": "0.06"
    },
    {
      "page_no": 13,
      "bbox": [
        433.79766845703125,
        85.54595947265625,
        469.1772155761719,
        91.57186126708984
      ],
      "text": "Decode Mean"
    },
    {
      "page_no": 13,
      "bbox": [
        491.93170166015625,
        133.1514129638672,
        542.91455078125,
        137.97213745117188
      ],
      "text": "2.0 2.2 2.4 2.6 2.8 3.0"
    },
    {
      "page_no": 13,
      "bbox": [
        500.1678466796875,
        138.35958862304688,
        534.685302734375,
        144.385498046875
      ],
      "text": "Request Rate"
    },
    {
      "page_no": 13,
      "bbox": [
        487.955078125,
        125.91307067871094,
        490.5868225097656,
        130.73379516601562
      ],
      "text": "0"
    },
    {
      "page_no": 13,
      "bbox": [
        487.955078125,
        115.56270599365234,
        490.5868225097656,
        120.3834228515625
      ],
      "text": "5"
    },
    {
      "page_no": 13,
      "bbox": [
        485.32037353515625,
        105.21234893798828,
        490.5838623046875,
        110.03306579589844
      ],
      "text": "10"
    },
    {
      "page_no": 13,
      "bbox": [
        485.32037353515625,
        94.86199188232422,
        490.5838623046875,
        99.68270874023438
      ],
      "text": "15"
    },
    {
      "page_no": 13,
      "bbox": [
        478.0581970214844,
        88.39453125,
        484.0841064453125,
        135.45693969726562
      ],
      "text": "Avg Instance Num"
    },
    {
      "page_no": 13,
      "bbox": [
        498.9932861328125,
        85.54595947265625,
        535.8590698242188,
        91.57186126708984
      ],
      "text": "Resource Cost"
    },
    {
      "page_no": 13,
      "bbox": [
        98.27127075195312,
        189.72323608398438,
        145.3065185546875,
        200.95733642578125
      ],
      "text": "2\n3\n4\n5\n6\nCV"
    },
    {
      "page_no": 13,
      "bbox": [
        92.31993103027344,
        182.48489379882812,
        94.95167541503906,
        187.3056182861328
      ],
      "text": "0"
    },
    {
      "page_no": 13,
      "bbox": [
        87.05049133300781,
        172.70973205566406,
        94.94572448730469,
        177.53045654296875
      ],
      "text": "100"
    },
    {
      "page_no": 13,
      "bbox": [
        87.05049133300781,
        162.9345703125,
        94.94572448730469,
        167.7552947998047
      ],
      "text": "200"
    },
    {
      "page_no": 13,
      "bbox": [
        87.05049133300781,
        153.15940856933594,
        94.94572448730469,
        157.98013305664062
      ],
      "text": "300"
    },
    {
      "page_no": 13,
      "bbox": [
        68.2063980102539,
        158.28367614746094,
        74.2322998046875,
        178.70968627929688
      ],
      "text": "Gamma"
    },
    {
      "page_no": 13,
      "bbox": [
        79.78837585449219,
        154.09141540527344,
        85.81427764892578,
        182.9123077392578
      ],
      "text": "Latency (s)"
    },
    {
      "page_no": 13,
      "bbox": [
        164.21046447753906,
        189.72323608398438,
        211.24569702148438,
        200.95733642578125
      ],
      "text": "2\n3\n4\n5\n6\nCV"
    },
    {
      "page_no": 13,
      "bbox": [
        158.25912475585938,
        182.48489379882812,
        160.890869140625,
        187.3056182861328
      ],
      "text": "0"
    },
    {
      "page_no": 13,
      "bbox": [
        155.6243896484375,
        166.6116485595703,
        160.88787841796875,
        171.432373046875
      ],
      "text": "20"
    },
    {
      "page_no": 13,
      "bbox": [
        155.6243896484375,
        150.73838806152344,
        160.88787841796875,
        155.55911254882812
      ],
      "text": "40"
    },
    {
      "page_no": 13,
      "bbox": [
        230.14964294433594,
        189.72323608398438,
        277.1849060058594,
        200.95733642578125
      ],
      "text": "2\n3\n4\n5\n6\nCV"
    },
    {
      "page_no": 13,
      "bbox": [
        224.19830322265625,
        182.48489379882812,
        226.83004760742188,
        187.3056182861328
      ],
      "text": "0"
    },
    {
      "page_no": 13,
      "bbox": [
        218.9288787841797,
        167.98609924316406,
        226.82411193847656,
        172.80682373046875
      ],
      "text": "100"
    },
    {
      "page_no": 13,
      "bbox": [
        218.9288787841797,
        153.48731994628906,
        226.82411193847656,
        158.30804443359375
      ],
      "text": "200"
    },
    {
      "page_no": 13,
      "bbox": [
        296.0888366699219,
        189.72323608398438,
        343.1240539550781,
        200.95733642578125
      ],
      "text": "2\n3\n4\n5\n6\nCV"
    },
    {
      "page_no": 13,
      "bbox": [
        290.13751220703125,
        182.48489379882812,
        292.7692565917969,
        187.3056182861328
      ],
      "text": "0"
    },
    {
      "page_no": 13,
      "bbox": [
        290.13751220703125,
        170.0191192626953,
        292.7692565917969,
        174.83984375
      ],
      "text": "5"
    },
    {
      "page_no": 13,
      "bbox": [
        287.5027770996094,
        157.55335998535156,
        292.7662658691406,
        162.37408447265625
      ],
      "text": "10"
    },
    {
      "page_no": 13,
      "bbox": [
        362.02801513671875,
        189.72323608398438,
        409.0632629394531,
        200.95733642578125
      ],
      "text": "2\n3\n4\n5\n6\nCV"
    },
    {
      "page_no": 13,
      "bbox": [
        352.1273193359375,
        182.48489379882812,
        358.7066650390625,
        187.3056182861328
      ],
      "text": "0.0"
    },
    {
      "page_no": 13,
      "bbox": [
        352.1273193359375,
        172.2036590576172,
        358.7066650390625,
        177.02438354492188
      ],
      "text": "0.1"
    },
    {
      "page_no": 13,
      "bbox": [
        352.1273193359375,
        161.9224090576172,
        358.7066650390625,
        166.74313354492188
      ],
      "text": "0.2"
    },
    {
      "page_no": 13,
      "bbox": [
        352.1273193359375,
        151.6411895751953,
        358.7066650390625,
        156.4619140625
      ],
      "text": "0.3"
    },
    {
      "page_no": 13,
      "bbox": [
        427.96722412109375,
        189.72323608398438,
        475.0024719238281,
        200.95733642578125
      ],
      "text": "2\n3\n4\n5\n6\nCV"
    },
    {
      "page_no": 13,
      "bbox": [
        412.79705810546875,
        182.48489379882812,
        424.639892578125,
        187.3056182861328
      ],
      "text": "0.000"
    },
    {
      "page_no": 13,
      "bbox": [
        412.79705810546875,
        170.70751953125,
        424.639892578125,
        175.5282440185547
      ],
      "text": "0.025"
    },
    {
      "page_no": 13,
      "bbox": [
        412.79705810546875,
        158.93016052246094,
        424.639892578125,
        163.75088500976562
      ],
      "text": "0.050"
    },
    {
      "page_no": 13,
      "bbox": [
        412.79705810546875,
        147.1527862548828,
        424.639892578125,
        151.9735107421875
      ],
      "text": "0.075"
    },
    {
      "page_no": 13,
      "bbox": [
        493.90643310546875,
        189.72323608398438,
        540.9415893554688,
        200.95733642578125
      ],
      "text": "2\n3\n4\n5\n6\nCV"
    },
    {
      "page_no": 13,
      "bbox": [
        487.955078125,
        182.48489379882812,
        490.5868225097656,
        187.3056182861328
      ],
      "text": "0"
    },
    {
      "page_no": 13,
      "bbox": [
        487.955078125,
        170.22802734375,
        490.5868225097656,
        175.0487518310547
      ],
      "text": "5"
    },
    {
      "page_no": 13,
      "bbox": [
        485.32037353515625,
        157.97117614746094,
        490.5838623046875,
        162.79190063476562
      ],
      "text": "10"
    },
    {
      "page_no": 13,
      "bbox": [
        478.0581970214844,
        144.96633911132812,
        484.0841064453125,
        192.02874755859375
      ],
      "text": "Avg Instance Num"
    },
    {
      "page_no": 13,
      "bbox": [
        283.9689025878906,
        75.67520141601562,
        355.3871154785156,
        81.70110321044922
      ],
      "text": "INFaaS++\nLlumnix"
    },
    {
      "page_no": 13,
      "bbox": [
        61.20600128173828,
        214.0724639892578,
        550.7980346679688,
        224.03506469726562
      ],
      "text": "Figure 14: Auto-scaling of LLaMA-7B instances with Poisson and Gamma distributions, as annotated on the Y-axis labels."
    },
    {
      "page_no": 13,
      "bbox": [
        154.77806091308594,
        323.8953857421875,
        216.3968505859375,
        340.84991455078125
      ],
      "text": "12\n14\nAvg Instance Num"
    },
    {
      "page_no": 13,
      "bbox": [
        120.2559585571289,
        316.6662292480469,
        124.51435852050781,
        324.46661376953125
      ],
      "text": "0"
    },
    {
      "page_no": 13,
      "bbox": [
        115.99797821044922,
        299.8757629394531,
        124.51477813720703,
        307.6761474609375
      ],
      "text": "10"
    },
    {
      "page_no": 13,
      "bbox": [
        115.99797821044922,
        283.0852966308594,
        124.51477813720703,
        290.88568115234375
      ],
      "text": "20"
    },
    {
      "page_no": 13,
      "bbox": [
        115.99797821044922,
        266.2947998046875,
        124.51477813720703,
        274.0951843261719
      ],
      "text": "30"
    },
    {
      "page_no": 13,
      "bbox": [
        115.99797821044922,
        249.50436401367188,
        124.51477813720703,
        257.30474853515625
      ],
      "text": "40"
    },
    {
      "page_no": 13,
      "bbox": [
        105.70809173583984,
        248.82618713378906,
        113.50846862792969,
        321.5332946777344
      ],
      "text": "P99 Prefill Latency (s)"
    },
    {
      "page_no": 13,
      "bbox": [
        142.51425170898438,
        305.2723693847656,
        212.11502075195312,
        313.07275390625
      ],
      "text": "Cost Saving: 36.49%"
    },
    {
      "page_no": 13,
      "bbox": [
        201.34176635742188,
        254.850341796875,
        235.2508087158203,
        272.47442626953125
      ],
      "text": "INFaaS++\nLlumnix"
    },
    {
      "page_no": 13,
      "bbox": [
        54.0,
        356.1822814941406,
        295.7708435058594,
        378.1750793457031
      ],
      "text": "Figure 15: P99 prefill latencies vs. average numbers of in-\nstances with varying scaling thresholds."
    },
    {
      "page_no": 13,
      "bbox": [
        54.0,
        401.71728515625,
        295.768798828125,
        459.5760803222656
      ],
      "text": "thresholds. We observe that Llumnix achieves similar P99\nprefill latency (roughly 5s, the red dash line) while saving 36%\nof the cost compared to INFaaS++, as a result of the combi-\nnation of the ability to reduce queuing delays via migration\nand the higher auto-scaling efficiency."
    },
    {
      "page_no": 13,
      "bbox": [
        54.0,
        476.7991638183594,
        194.17474365234375,
        488.7543640136719
      ],
      "text": "6.6\nScheduling Scalability"
    },
    {
      "page_no": 13,
      "bbox": [
        53.53200149536133,
        497.2677917480469,
        295.7708740234375,
        614.758056640625
      ],
      "text": "We conduct a scheduling stress test to examine the scalability\nof Llumnix with 64 LLaMA-7B instances using higher re-\nquest rates. Since this cluster exceeds the size of our testbed,\nwe replace the real GPU execution in vLLM with a simple\nsleep command, whose duration is determined by offline\nmeasurement on A10 GPUs with different sequence lengths\nand batch sizes. We build a simple centralized scheduler as\nthe baseline by extending the vLLM scheduler to manage all\nrequests across all instances. We issue requests with input and\noutput lengths of 64 tokens with increasing request rates."
    },
    {
      "page_no": 13,
      "bbox": [
        54.0,
        616.7320556640625,
        295.7751770019531,
        722.4310302734375
      ],
      "text": "As shown in Figure 16, with increasing request rates, the\nbaseline experiences scheduling stalls during the inference\ncomputation of up to 40ms per iteration, translating to 1.7×\nslowdown. Such stalls are a result of the communication be-\ntween instances and the centralized scheduler synchronizing\nrequest statuses and scheduling decisions, which becomes a\nbottleneck under high load. By contrast, Llumnix exhibits\nnear-zero scheduling stalls even under high request rates,\nshowing the scalability of the distributed scheduling archi-"
    },
    {
      "page_no": 13,
      "bbox": [
        370.123046875,
        324.1735534667969,
        529.2522583007812,
        339.794189453125
      ],
      "text": "100\n200\n300\n400\n500\nRequest rate"
    },
    {
      "page_no": 13,
      "bbox": [
        351.73516845703125,
        318.66351318359375,
        355.875732421875,
        326.2480163574219
      ],
      "text": "0"
    },
    {
      "page_no": 13,
      "bbox": [
        347.59161376953125,
        305.0758972167969,
        355.87274169921875,
        312.660400390625
      ],
      "text": "20"
    },
    {
      "page_no": 13,
      "bbox": [
        347.59161376953125,
        291.48828125,
        355.87274169921875,
        299.0727844238281
      ],
      "text": "40"
    },
    {
      "page_no": 13,
      "bbox": [
        347.59161376953125,
        277.9006652832031,
        355.87274169921875,
        285.48516845703125
      ],
      "text": "60"
    },
    {
      "page_no": 13,
      "bbox": [
        347.59161376953125,
        264.3130798339844,
        355.87274169921875,
        271.8975830078125
      ],
      "text": "80"
    },
    {
      "page_no": 13,
      "bbox": [
        343.4480895996094,
        250.72543334960938,
        355.8697509765625,
        258.3099365234375
      ],
      "text": "100"
    },
    {
      "page_no": 13,
      "bbox": [
        334.3076171875,
        263.9471740722656,
        341.8921203613281,
        306.5635986328125
      ],
      "text": "Latency (ms)"
    },
    {
      "page_no": 13,
      "bbox": [
        375.5196533203125,
        250.90818786621094,
        463.5748291015625,
        278.9369201660156
      ],
      "text": "Centralized (Decode Inference)\nCentralized (Scheduling Stall)\nLlumnix (Decode Inference)\nLlumnix (Scheduling Stall)"
    },
    {
      "page_no": 13,
      "bbox": [
        317.8800048828125,
        353.4393005371094,
        558.1673583984375,
        375.43206787109375
      ],
      "text": "Figure 16: Per-token latencies and scheduling stalls under\nincreasing request rates using 64 LLaMA-7B instances."
    },
    {
      "page_no": 13,
      "bbox": [
        317.8800048828125,
        390.72430419921875,
        559.65087890625,
        460.5380859375
      ],
      "text": "tecture. Llumnix offloads and distributes the intra-instance\nscheduling logic across llumlets so that it is done in paral-\nlel and asynchronously with the global scheduling. More-\nover, llumlets only report instance-level metrics, instead of\nthe precise status of every single request, further improving\nthe communication efficiency."
    },
    {
      "page_no": 13,
      "bbox": [
        317.8800048828125,
        483.5931701660156,
        406.97015380859375,
        495.5483703613281
      ],
      "text": "7\nRelated Work"
    },
    {
      "page_no": 13,
      "bbox": [
        317.8800048828125,
        509.0393981933594,
        559.6583862304688,
        722.4310302734375
      ],
      "text": "LLM inference.\nAs transformer models show signifi-\ncance in model serving, recent works, such as FasterTrans-\nformer [46], TurboTransformer [25], LightSeq [61], and\nFlashAttention [21, 22], optimize GPU kernels to improve\nthe inference performance. SpotServe [41] supports LLM\ninference using preemptible instances for improving cost ef-\nficiency. FastServe [63] optimizes request completion times\nusing a preemptive time-slicing approach. AlpaServe [35]\nexploits pipeline parallelism to reduce serving latency for\nbursty workloads. To further increase the GPU utilization\nand serving throughput, Orca [67] proposes iteration-level\nscheduling (referred to as continuous batching in recent works\nand this paper) and selective batching, while vLLM [34] opti-\nmizes the memory usage with PageAttention. [55] proposes\nfair scheduling of requests on an LLM instance. Prior works\nmostly target solo-instance serving, therefore complementing\nto Llumnix. Llumnix explores the challenges and opportu-\nnities of deploying multi-instance LLM serving. The key"
    },
    {
      "page_no": 13,
      "bbox": [
        301.0190124511719,
        742.3324584960938,
        310.9815979003906,
        752.2950439453125
      ],
      "text": "13"
    },
    {
      "page_no": 14,
      "bbox": [
        53.64099884033203,
        74.4834213256836,
        295.7774353027344,
        420.5860595703125
      ],
      "text": "append-only characteristic of KV cache is exploited to enable\nmigration capability of requests in the inference engine. Such\na mechanism opens great policy design space to offer prior-\nity and performance isolation, improve memory efficiency,\nand enable instance auto-scaling. We also plan to explore\nthe interplay between the global scheduling across instances\nwith local scheduling techniques inside each instance (e.g.,\npreemptive [63] and fair [55] scheduling) as future works.\nRequest scheduling.\nTo support deep learning model de-\nployment, numerous systems (e.g., Clipper [19], Nexus [54],\nDVABatch [20], and TritonServer [47]) have been proposed\nto optimize request scheduling for DNN inference serving. To\nmeet the SLOs of DNN inference requests, Clockwork [29]\nutilizes the execution predictability of traditional DNNs, while\nReef [33] and Shepherd [68] perform preemptions to serve\nhigh-priority requests. AlpaServe [35] uses a simple load-\nbalancing dispatching policy based on queue lengths. These\nworks mostly focus on traditional DNN model serving, where\na request requires only one-time inference on the model. How-\never, LLM inference service requires autoregressive com-\nputation on models for unpredictable numbers of iterations\nand introduces intermediate states (i.e., KV cache), showing\nbrand new characteristics. DeepSpeed-MII [4], albeit target-\ning multi-instance LLM serving, uses a simple round-robin\ndispatching policy that ignores LLM characteristics. Llumnix\nsteps further to incorporate request migration and ensures\nhigh throughput and low latency, provides SLO for prioritized\nrequests, and auto-scales instances for resource efficiency\nwith a unified load-aware dynamic scheduling policy."
    },
    {
      "page_no": 14,
      "bbox": [
        53.64099884033203,
        424.12542724609375,
        295.8622131347656,
        722.4310302734375
      ],
      "text": "Beyond multiple model instances, INFaaS [53] further sup-\nports scheduling across multiple model types/variants, con-\nsidering the performance and accuracy requirements in differ-\nence applications. This is also a typical scenario for LLMs:\nfor example, fine-tuned models for a specific task (e.g., cod-\ning [3, 13, 30]); variants with different sizes or precisions\n( [26,37,39]) of the base LLM. We plan to extend Llumnix to\nsupport multiple model types in future work, considering the\nlarger tradeoff space of latency/throughput and accuracy.\nIsolation vs. fragmentation.\nThe tradeoff between iso-\nlation and fragmentation, or that between workload pack-\ning and spreading, have been a classic scheduling challenge.\nThat is, workload packing improves resource utilization, at\nthe expense of potential interference between co-located\nworkloads; spreading workloads, on the contrary, provides\nbetter isolation but also increases resource fragmentation.\nMany research efforts have been devoted to better balanc-\ning isolation and fragmentation in datacenters for big-data\njobs and virtual machines, by identifying the interference-\nsensitivity of workloads and optimized scheduling policies\n( [16,18,23,24,27,31,32,40,60,66]). This challenge was also\nidentified in GPU clusters for deep learning workloads. Ama-\nral et al proposed a topology-aware placement algorithm to ad-\ndress the tradeoff between packing and spreading deep learn-\ning training jobs on multi-GPU servers [12]. Gandiva [64]"
    },
    {
      "page_no": 14,
      "bbox": [
        317.5710144042969,
        74.4377670288086,
        559.7423706054688,
        323.9678649902344
      ],
      "text": "addresses the heterogeneous sensitivity to packing/spreading\nof different jobs with introspective job migration. This chal-\nlenge becomes more complex for LLM serving due to the\nunpredictable autoregressive execution. Llumnix exploits re-\nquest migration at runtime to react to the workload dynamics\nto better reconcile these two goals.\nMigration.\nGandiva [64] enables introspective migration\nfor deep learning training jobs during scheduling. It utilizes\nthe inherent iterative behavior of deep learning, and conducts\ncheckpoint-resume approach on the minimal working set (i.e.,\nmini-batch boundary) to migrate model weights. Even though\nLLM inference is iterative as well, directly migrating the\nentire states of a request is unacceptable, because the latency\nSLO of an inference request is crucial. Moreover, the working\nset per request is linear to the sequence length, which can\nbe considerable given the trend of longer contexts [49, 50].\nThe migration approach in Llumnix is inspired by virtual\nmachine live migration [17]. By carrying out the majority of\nmigration while LLM requests continue decoding tokens on\nGPUs, Llumnix minimizes the downtime of request migration,\nmaking the cost negligible regardless of the sequence lengths."
    },
    {
      "page_no": 14,
      "bbox": [
        317.8800048828125,
        344.90216064453125,
        392.94671630859375,
        356.85736083984375
      ],
      "text": "8\nConclusion"
    },
    {
      "page_no": 14,
      "bbox": [
        317.8800048828125,
        369.69927978515625,
        559.6583251953125,
        535.155029296875
      ],
      "text": "Llumnix, as implied by the name, represents our vision of\nserving LLMs as Unix. This vision originates in the observa-\ntion that LLMs and modern operating systems have common\nnatures such as the universality, multi-tenancy, and dynamism,\nand hence share similar requirements and challenges. This\npaper takes an important step towards this vision by draw-\ning lessons from conventional OS wisdom including: defini-\ntion of classic abstractions like isolation and priorities in the\nnew context of LLM serving; implementation of the “con-\ntext switching” as the key approach with inference request\nmigration; and continuous, dynamic request rescheduling ex-\nploiting the migration. All these combined, Llumnix delivers\nbetter latency, cost efficiency, and support for differentiated\nSLOs, pointing to a new way of LLM serving."
    },
    {
      "page_no": 14,
      "bbox": [
        317.8800048828125,
        556.0651245117188,
        412.0630798339844,
        568.0203247070312
      ],
      "text": "Acknowledgement"
    },
    {
      "page_no": 14,
      "bbox": [
        317.4119873046875,
        580.89599609375,
        559.7432250976562,
        722.392578125
      ],
      "text": "We thank the anonymous OSDI reviewers and our shepherd\nfor their valuable feedback, which helped improve the pre-\nsentation of this paper. We thank Shiru Ren for early dis-\ncussion on VM live migration techniques. This work was\nsupported by Alibaba Group through the Alibaba Research\nIntern Program. This work was also supported by National\nKey Research and Development Program of China (Grant\nNo. 2023YFB3001801), National Natural Science Founda-\ntion of China (Grant No. 62322201, 62072018, U23B2020\nand U22A2028), Fundamental Research Funds for the Central\nUniversities (YWF-23-L-1121), and State Key Laboratory of\nSoftware Development Environment (SKLSDE-2023ZX-05)."
    },
    {
      "page_no": 14,
      "bbox": [
        301.0190124511719,
        742.3324584960938,
        310.9815979003906,
        752.2950439453125
      ],
      "text": "14"
    },
    {
      "page_no": 15,
      "bbox": [
        54.0,
        72.78716278076172,
        109.54385375976562,
        84.74236297607422
      ],
      "text": "References"
    },
    {
      "page_no": 15,
      "bbox": [
        58.98099899291992,
        96.67347717285156,
        236.6639404296875,
        106.63607788085938
      ],
      "text": "[1] Nccl, https://developer.nvidia.com/nccl/."
    },
    {
      "page_no": 15,
      "bbox": [
        58.98099899291992,
        115.05365753173828,
        295.1363830566406,
        137.45010375976562
      ],
      "text": "[2] Chatgpt plus, 2023.\nhttps://openai.com/blog/\nchatgpt-plus."
    },
    {
      "page_no": 15,
      "bbox": [
        58.98100280761719,
        145.8666534423828,
        295.13671875,
        168.26309204101562
      ],
      "text": "[3] Code\nllama, 2023.\nhttps://github.com/\nfacebookresearch/codellama."
    },
    {
      "page_no": 15,
      "bbox": [
        58.98101806640625,
        176.68067932128906,
        295.13671875,
        199.07711791992188
      ],
      "text": "[4] Deepspeed-mii, 2023.\nhttps://github.com/\nmicrosoft/DeepSpeed-MII."
    },
    {
      "page_no": 15,
      "bbox": [
        58.98100280761719,
        207.49464416503906,
        296.66058349609375,
        229.89108276367188
      ],
      "text": "[5] Gloo collective communication library, 2023. https:\n//github.com/facebookincubator/gloo."
    },
    {
      "page_no": 15,
      "bbox": [
        58.980987548828125,
        238.30763244628906,
        280.5196533203125,
        248.74905395507812
      ],
      "text": "[6] Google bard, 2023. https://bard.google.com/."
    },
    {
      "page_no": 15,
      "bbox": [
        58.980987548828125,
        257.1666259765625,
        295.13671875,
        279.5630798339844
      ],
      "text": "[7] Longllama,\n2023.\nhttps://github.com/\nCStanKonrad/long_llama."
    },
    {
      "page_no": 15,
      "bbox": [
        58.98100280761719,
        287.98065185546875,
        291.587646484375,
        298.4220886230469
      ],
      "text": "[8] Openai chatgpt, 2023. https://chat.openai.com/."
    },
    {
      "page_no": 15,
      "bbox": [
        58.980987548828125,
        306.838623046875,
        295.1359558105469,
        329.23504638671875
      ],
      "text": "[9] Ray serve, 2023. https://docs.ray.io/en/latest/\nserve/index.html."
    },
    {
      "page_no": 15,
      "bbox": [
        53.99999237060547,
        337.65264892578125,
        295.1364440917969,
        360.049072265625
      ],
      "text": "[10] Sharegpt_gpt4, 2023.\nhttps://huggingface.co/\ndatasets/shibing624/sharegpt_gpt4."
    },
    {
      "page_no": 15,
      "bbox": [
        54.0,
        368.46563720703125,
        295.365478515625,
        390.8630676269531
      ],
      "text": "[11] vllm.\nhttps://github.com/vllm-project/vllm,\n2023."
    },
    {
      "page_no": 15,
      "bbox": [
        54.0,
        399.7584533691406,
        295.8674011230469,
        481.45208740234375
      ],
      "text": "[12] Marcelo Amaral, Jordà Polo, David Carrera, Seetharami\nSeelam, and Malgorzata Steinder. Topology-aware GPU\nscheduling for learning workloads in cloud environ-\nments. In Proceedings of the International Conference\nfor High Performance Computing, Networking, Stor-\nage and Analysis, page 17, New York, NY, USA, 2017.\nACM."
    },
    {
      "page_no": 15,
      "bbox": [
        54.0,
        490.3446960449219,
        295.7721252441406,
        643.7730102539062
      ],
      "text": "[13] Jinze Bai, Shuai Bai, Yunfei Chu, Zeyu Cui, Kai Dang,\nXiaodong Deng, Yang Fan, Wenbin Ge, Yu Han, Fei\nHuang, Binyuan Hui, Luo Ji, Mei Li, Junyang Lin, Runji\nLin, Dayiheng Liu, Gao Liu, Chengqiang Lu, Keming\nLu, Jianxin Ma, Rui Men, Xingzhang Ren, Xuancheng\nRen, Chuanqi Tan, Sinan Tan, Jianhong Tu, Peng Wang,\nShijie Wang, Wei Wang, Shengguang Wu, Benfeng Xu,\nJin Xu, An Yang, Hao Yang, Jian Yang, Shusheng Yang,\nYang Yao, Bowen Yu, Hongyi Yuan, Zheng Yuan, Jian-\nwei Zhang, Xingxuan Zhang, Yichang Zhang, Zhenru\nZhang, Chang Zhou, Jingren Zhou, Xiaohuan Zhou, and\nTianhang Zhu. Qwen technical report. arXiv preprint\narXiv:2309.16609, 2023."
    },
    {
      "page_no": 15,
      "bbox": [
        54.0,
        652.59326171875,
        295.7728576660156,
        722.4070434570312
      ],
      "text": "[14] Tom Brown, Benjamin Mann, Nick Ryder, Melanie\nSubbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind\nNeelakantan, Pranav Shyam, Girish Sastry, Amanda\nAskell, et al.\nLanguage models are few-shot learn-\ners. Advances in neural information processing systems,\n33:1877–1901, 2020."
    },
    {
      "page_no": 15,
      "bbox": [
        317.8800048828125,
        74.3773193359375,
        559.65185546875,
        263.6970520019531
      ],
      "text": "[15] Tom B. Brown, Benjamin Mann, Nick Ryder, Melanie\nSubbiah, Jared Kaplan, Prafulla Dhariwal, Arvind\nNeelakantan, Pranav Shyam, Girish Sastry, Amanda\nAskell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen\nKrueger, Tom Henighan, Rewon Child, Aditya Ramesh,\nDaniel M. Ziegler, Jeffrey Wu, Clemens Winter, Christo-\npher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin,\nScott Gray, Benjamin Chess, Jack Clark, Christopher\nBerner, Sam McCandlish, Alec Radford, Ilya Sutskever,\nand Dario Amodei.\nLanguage models are few-shot\nlearners. In Hugo Larochelle, Marc’Aurelio Ranzato,\nRaia Hadsell, Maria-Florina Balcan, and Hsuan-Tien\nLin, editors, Advances in Neural Information Process-\ning Systems 33: Annual Conference on Neural Informa-\ntion Processing Systems 2020, NeurIPS 2020, December\n6-12, 2020, virtual, 2020."
    },
    {
      "page_no": 15,
      "bbox": [
        317.8800048828125,
        278.4522705078125,
        559.6564331054688,
        360.2210693359375
      ],
      "text": "[16] Quan Chen, Hailong Yang, Minyi Guo, Ram Srivatsa\nKannan, Jason Mars, and Lingjia Tang. Prophet: Precise\nqos prediction on non-preemptive accelerators to im-\nprove utilization in warehouse-scale computers. In Pro-\nceedings of the Twenty-Second International Conference\non Architectural Support for Programming Languages\nand Operating Systems, pages 17–32, 2017."
    },
    {
      "page_no": 15,
      "bbox": [
        317.8800354003906,
        374.9762878417969,
        559.7413330078125,
        456.7450866699219
      ],
      "text": "[17] Christopher Clark, Keir Fraser, Steven\nHand, Ja-\ncob Gorm Hansen, Eric Jul, Christian Limpach, Ian\nPratt, and Andrew Warfield. Live migration of virtual\nmachines. In Amin Vahdat and David Wetherall, edi-\ntors, 2nd Symposium on Networked Systems Design and\nImplementation (NSDI 2005), May 2-4, 2005, Boston,\nMassachusetts, USA, Proceedings. USENIX, 2005."
    },
    {
      "page_no": 15,
      "bbox": [
        317.8800048828125,
        471.50030517578125,
        559.7430419921875,
        541.3140258789062
      ],
      "text": "[18] Eli Cortez, Anand Bonde, Alexandre Muzio, Mark\nRussinovich, Marcus Fontoura, and Ricardo Bianchini.\nResource central: Understanding and predicting work-\nloads for improved resource management in large cloud\nplatforms. In Proceedings of the 26th Symposium on\nOperating Systems Principles, pages 153–167, 2017."
    },
    {
      "page_no": 15,
      "bbox": [
        317.8800048828125,
        556.1181030273438,
        559.7390747070312,
        625.883056640625
      ],
      "text": "[19] Daniel Crankshaw, Xin Wang, Guilio Zhou, Michael J.\nFranklin, Joseph E. Gonzalez, and Ion Stoica. Clipper:\nA low-latency online prediction serving system. In 14th\nUSENIX Symposium on Networked Systems Design and\nImplementation (NSDI 17), pages 613–627, Boston, MA,\nMarch 2017. USENIX Association."
    },
    {
      "page_no": 15,
      "bbox": [
        317.8800048828125,
        640.6382446289062,
        559.657470703125,
        722.4070434570312
      ],
      "text": "[20] Weihao Cui, Han Zhao, Quan Chen, Hao Wei, Zirui\nLi, Deze Zeng, Chao Li, and Minyi Guo. DVABatch:\nDiversity-aware Multi-Entry Multi-Exit batching for ef-\nficient processing of DNN services on GPUs. In 2022\nUSENIX Annual Technical Conference (USENIX ATC\n22), pages 183–198, Carlsbad, CA, July 2022. USENIX\nAssociation."
    },
    {
      "page_no": 15,
      "bbox": [
        301.0190124511719,
        742.3324584960938,
        310.9815979003906,
        752.2950439453125
      ],
      "text": "15"
    },
    {
      "page_no": 16,
      "bbox": [
        54.0,
        74.33230590820312,
        295.365478515625,
        108.28005981445312
      ],
      "text": "[21] Tri Dao.\nFlashattention-2: Faster attention with\nbetter parallelism and work partitioning.\nCoRR,\nabs/2307.08691, 2023."
    },
    {
      "page_no": 16,
      "bbox": [
        54.0,
        118.22128295898438,
        295.7686767578125,
        152.16909790039062
      ],
      "text": "[22] Tri Dao, Daniel Y. Fu, Stefano Ermon, Atri Rudra,\nand Christopher Ré. Flashattention: Fast and memory-\nefficient exact attention with io-awareness, 2022."
    },
    {
      "page_no": 16,
      "bbox": [
        54.0,
        162.1817169189453,
        295.7747497558594,
        243.87905883789062
      ],
      "text": "[23] Christina Delimitrou and Christos Kozyrakis. Paragon:\nQoS-aware scheduling for heterogeneous datacenters. In\nProceedings of the Eighteenth International Conference\non Architectural Support for Programming Languages\nand Operating Systems, ASPLOS ’13, page 77–88, New\nYork, NY, USA, 2013. Association for Computing Ma-\nchinery."
    },
    {
      "page_no": 16,
      "bbox": [
        54.0,
        253.82028198242188,
        295.86761474609375,
        335.5890808105469
      ],
      "text": "[24] Christina Delimitrou and Christos Kozyrakis. Quasar:\nresource-efficient and qos-aware cluster management.\nIn Proceedings of the 19th International Conference\non Architectural Support for Programming Languages\nand Operating Systems, ASPLOS ’14, page 127–144,\nNew York, NY, USA, 2014. Association for Computing\nMachinery."
    },
    {
      "page_no": 16,
      "bbox": [
        54.0,
        345.5303039550781,
        295.86773681640625,
        427.299072265625
      ],
      "text": "[25] Jiarui Fang, Yang Yu, Chengduo Zhao, and Jie Zhou.\nTurbotransformers: An efficient gpu serving system for\ntransformer models. In Proceedings of the 26th ACM\nSIGPLAN Symposium on Principles and Practice of\nParallel Programming, PPoPP ’21, page 389–402, New\nYork, NY, USA, 2021. Association for Computing Ma-\nchinery."
    },
    {
      "page_no": 16,
      "bbox": [
        54.0,
        437.3154602050781,
        294.1217956542969,
        483.14306640625
      ],
      "text": "[26] Elias Frantar, Saleh Ashkboos, Torsten Hoefler, and Dan\nAlistarh. OPTQ: Accurate quantization for generative\npre-trained transformers. In The Eleventh International\nConference on Learning Representations, 2023."
    },
    {
      "page_no": 16,
      "bbox": [
        54.0,
        493.1142578125,
        295.77276611328125,
        550.9420776367188
      ],
      "text": "[27] Panagiotis Garefalakis, Konstantinos Karanasos, Peter\nPietzuch, Arun Suresh, and Sriram Rao. Medea: schedul-\ning of long running applications in shared production\nclusters. In Proceedings of the thirteenth EuroSys con-\nference, pages 1–13, 2018."
    },
    {
      "page_no": 16,
      "bbox": [
        54.0,
        560.9472045898438,
        295.7710876464844,
        630.697021484375
      ],
      "text": "[28] Arpan Gujarati, Reza Karimi, Safya Alzayat, Wei Hao,\nAntoine Kaufmann, Ymir Vigfusson, and Jonathan\nMace. Serving {DNNs} like clockwork: Performance\npredictability from the bottom up. In 14th USENIX\nSymposium on Operating Systems Design and Imple-\nmentation (OSDI 20), pages 443–462, 2020."
    },
    {
      "page_no": 16,
      "bbox": [
        53.99999237060547,
        640.7021484375,
        295.7735290527344,
        722.4070434570312
      ],
      "text": "[29] Arpan Gujarati, Reza Karimi, Safya Alzayat, Wei Hao,\nAntoine Kaufmann, Ymir Vigfusson, and Jonathan\nMace. Serving dnns like clockwork: Performance pre-\ndictability from the bottom up. In 14th USENIX Sym-\nposium on Operating Systems Design and Implementa-\ntion (OSDI 20), pages 443–462. USENIX Association,\nNovember 2020."
    },
    {
      "page_no": 16,
      "bbox": [
        317.8800048828125,
        74.33230590820312,
        559.74560546875,
        132.19009399414062
      ],
      "text": "[30] Daya Guo, Qihao Zhu, Dejian Yang, Zhenda Xie, Kai\nDong, Wentao Zhang, Guanting Chen, Xiao Bi, Y. Wu,\nY.K. Li, Fuli Luo, Yingfei Xiong, and Wenfeng Liang.\nDeepseek-coder: When the large language model meets\nprogramming – the rise of code intelligence, 2024."
    },
    {
      "page_no": 16,
      "bbox": [
        317.8800048828125,
        142.8885040283203,
        559.6497802734375,
        212.62704467773438
      ],
      "text": "[31] Ori Hadary, Luke Marshall, Ishai Menache, Abhisek Pan,\nEsaias E Greeff, David Dion, Star Dorminey, Shailesh\nJoshi, Yang Chen, Mark Russinovich, et al. Protean:\nVM allocation service at scale. In 14th USENIX Sympo-\nsium on Operating Systems Design and Implementation\n(OSDI 20), pages 845–861, 2020."
    },
    {
      "page_no": 16,
      "bbox": [
        317.8800048828125,
        223.26524353027344,
        559.6544799804688,
        316.97406005859375
      ],
      "text": "[32] Jaeung Han, Seungheun Jeon, Young-ri Choi, and Jae-\nhyuk Huh. Interference management for distributed\nparallel applications in consolidated clusters. In Pro-\nceedings of the Twenty-First International Conference\non Architectural Support for Programming Languages\nand Operating Systems, ASPLOS ’16, page 443–456,\nNew York, NY, USA, 2016. Association for Computing\nMachinery."
    },
    {
      "page_no": 16,
      "bbox": [
        317.8800048828125,
        327.60101318359375,
        559.6512451171875,
        397.41107177734375
      ],
      "text": "[33] Mingcong Han, Hanze Zhang, Rong Chen, and Haibo\nChen. Microsecond-scale preemption for concurrent\nGPU-accelerated DNN inferences. In 16th USENIX\nSymposium on Operating Systems Design and Imple-\nmentation (OSDI 22), pages 539–558, Carlsbad, CA,\nJuly 2022. USENIX Association."
    },
    {
      "page_no": 16,
      "bbox": [
        317.8800048828125,
        408.0343017578125,
        559.6563110351562,
        501.7580871582031
      ],
      "text": "[34] Woosuk Kwon, Zhuohan Li, Siyuan Zhuang, Ying\nSheng, Lianmin Zheng, Cody Hao Yu, Joseph Gonzalez,\nHao Zhang, and Ion Stoica. Efficient memory man-\nagement for large language model serving with page-\ndattention. In Proceedings of the 29th Symposium on\nOperating Systems Principles, SOSP ’23, page 611–626,\nNew York, NY, USA, 2023. Association for Computing\nMachinery."
    },
    {
      "page_no": 16,
      "bbox": [
        317.8800048828125,
        512.3812255859375,
        559.7452392578125,
        606.1050415039062
      ],
      "text": "[35] Zhuohan Li, Lianmin Zheng, Yinmin Zhong, Vincent\nLiu, Ying Sheng, Xin Jin, Yanping Huang, Zhifeng Chen,\nHao Zhang, Joseph E. Gonzalez, and Ion Stoica. Al-\npaServe: Statistical multiplexing with model parallelism\nfor deep learning serving.\nIn 17th USENIX Sympo-\nsium on Operating Systems Design and Implementa-\ntion (OSDI 23), pages 663–679, Boston, MA, July 2023.\nUSENIX Association."
    },
    {
      "page_no": 16,
      "bbox": [
        317.8800048828125,
        616.728271484375,
        559.6564331054688,
        722.3877563476562
      ],
      "text": "[36] Percy Liang, Rishi Bommasani, Tony Lee, Dimitris\nTsipras, Dilara Soylu, Michihiro Yasunaga, Yian Zhang,\nDeepak Narayanan, Yuhuai Wu, Ananya Kumar, Ben-\njamin Newman, Binhang Yuan, Bobby Yan, Ce Zhang,\nChristian Cosgrove, Christopher D. Manning, Christo-\npher Ré, Diana Acosta-Navas, Drew A. Hudson, Eric\nZelikman, Esin Durmus, Faisal Ladhak, Frieda Rong,\nHongyu Ren, Huaxiu Yao, Jue Wang, Keshav San-\nthanam, Laurel J. Orr, Lucia Zheng, Mert Yüksekgönül,"
    },
    {
      "page_no": 16,
      "bbox": [
        301.0190124511719,
        742.3324584960938,
        310.9815979003906,
        752.2950439453125
      ],
      "text": "16"
    },
    {
      "page_no": 17,
      "bbox": [
        75.22000122070312,
        74.4834213256836,
        295.7919006347656,
        156.0926055908203
      ],
      "text": "Mirac Suzgun, Nathan Kim, Neel Guha, Niladri S. Chat-\nterji, Omar Khattab, Peter Henderson, Qian Huang, Ryan\nChi, Sang Michael Xie, Shibani Santurkar, Surya Gan-\nguli, Tatsunori Hashimoto, Thomas Icard, Tianyi Zhang,\nVishrav Chaudhary, William Wang, Xuechen Li, Yifan\nMai, Yuhui Zhang, and Yuta Koreeda. Holistic evalua-\ntion of language models. CoRR, abs/2211.09110, 2022."
    },
    {
      "page_no": 17,
      "bbox": [
        54.0,
        166.0637664794922,
        295.7762145996094,
        223.90005493164062
      ],
      "text": "[37] Ji Lin, Jiaming Tang, Haotian Tang, Shang Yang, Wei-\nMing Chen, Wei-Chen Wang, Guangxuan Xiao, Xingyu\nDang, Chuang Gan, and Song Han. Awq: Activation-\naware weight quantization for llm compression and ac-\nceleration. In MLSys, 2024."
    },
    {
      "page_no": 17,
      "bbox": [
        53.99999237060547,
        233.84127807617188,
        295.7762145996094,
        267.7890930175781
      ],
      "text": "[38] Hao Liu, Matei Zaharia, and Pieter Abbeel. Ring at-\ntention with blockwise transformers for near-infinite\ncontext. CoRR, abs/2310.01889, 2023."
    },
    {
      "page_no": 17,
      "bbox": [
        54.00000762939453,
        277.7565002441406,
        295.364990234375,
        323.6340637207031
      ],
      "text": "[39] Shuming Ma, Hongyu Wang, Lingxiao Ma, Lei Wang,\nWenhui Wang, Shaohan Huang, Li Dong, Ruiping Wang,\nJilong Xue, and Furu Wei. The era of 1-bit llms: All\nlarge language models are in 1.58 bits, 2024."
    },
    {
      "page_no": 17,
      "bbox": [
        54.0,
        333.6494445800781,
        295.7704162597656,
        403.3880615234375
      ],
      "text": "[40] Jason Mars, Lingjia Tang, Robert Hundt, Kevin Skadron,\nand Mary Lou Soffa. Bubble-up: Increasing utilization\nin modern warehouse scale computers via sensible co-\nlocations. In Proceedings of the 44th annual IEEE/ACM\nInternational Symposium on Microarchitecture, pages\n248–259, 2011."
    },
    {
      "page_no": 17,
      "bbox": [
        54.0,
        413.32928466796875,
        295.7762756347656,
        459.2330627441406
      ],
      "text": "[41] Xupeng Miao, Chunan Shi, Jiangfei Duan, Xiaoli Xi,\nDahua Lin, Bin Cui, and Zhihao Jia. Spotserve: Serv-\ning generative large language models on preemptible\ninstances, 2023."
    },
    {
      "page_no": 17,
      "bbox": [
        54.0,
        469.17327880859375,
        295.776611328125,
        562.8980102539062
      ],
      "text": "[42] Philipp Moritz, Robert Nishihara, Stephanie Wang,\nAlexey Tumanov, Richard Liaw, Eric Liang, Melih Eli-\nbol, Zongheng Yang, William Paul, Michael I. Jordan,\nand Ion Stoica. Ray: A distributed framework for emerg-\ning AI applications. In 13th USENIX Symposium on Op-\nerating Systems Design and Implementation (OSDI 18),\npages 561–577, Carlsbad, CA, October 2018. USENIX\nAssociation."
    },
    {
      "page_no": 17,
      "bbox": [
        54.0,
        572.9144287109375,
        295.7718200683594,
        606.7870483398438
      ],
      "text": "[43] Avanika Narayan, Ines Chami, Laurel J. Orr, and Christo-\npher Ré. Can foundation models wrangle your data?\nProc. VLDB Endow., 16(4):738–746, 2022."
    },
    {
      "page_no": 17,
      "bbox": [
        53.99999237060547,
        616.803466796875,
        295.8596496582031,
        722.3865356445312
      ],
      "text": "[44] Deepak Narayanan, Mohammad Shoeybi, Jared Casper,\nPatrick LeGresley, Mostofa Patwary, Vijay Korthikanti,\nDmitri Vainbrand, Prethvi Kashinkunti, Julie Bernauer,\nBryan Catanzaro, Amar Phanishayee, and Matei Zaharia.\nEfficient large-scale language model training on gpu\nclusters using megatron-lm. In Proceedings of the Inter-\nnational Conference for High Performance Computing,\nNetworking, Storage and Analysis, SC ’21, New York,\nNY, USA, 2021. Association for Computing Machinery."
    },
    {
      "page_no": 17,
      "bbox": [
        317.8800048828125,
        74.33230590820312,
        577.6148681640625,
        132.1658935546875
      ],
      "text": "[45] NVIDIA.\nUsing\nmultiple\nnccl\ncom-\nmunicators\nconcurrently.\nhttps://\ndocs.nvidia.com/deeplearning/nccl/\nuser-guide/docs/usage/communicators.html#\nusing-multiple-nccl-communicators-concurrently."
    },
    {
      "page_no": 17,
      "bbox": [
        317.8800048828125,
        142.7996368408203,
        559.0167236328125,
        165.19705200195312
      ],
      "text": "[46] NVIDIA. Fastertransformer. https://github.com/\nNVIDIA/FasterTransformer, 2023."
    },
    {
      "page_no": 17,
      "bbox": [
        317.8800048828125,
        175.80665588378906,
        561.5569458007812,
        198.20309448242188
      ],
      "text": "[47] NVIDIA. Triton inference server. https://github.\ncom/triton-inference-server/server, 2023."
    },
    {
      "page_no": 17,
      "bbox": [
        317.8799743652344,
        208.81263732910156,
        559.0167236328125,
        231.20907592773438
      ],
      "text": "[48] OpenAI. Openai api, 2020. https://openai.com/\nblog/openai-api."
    },
    {
      "page_no": 17,
      "bbox": [
        317.8800048828125,
        242.29750061035156,
        493.0024719238281,
        252.26010131835938
      ],
      "text": "[49] OpenAI. Gpt-4 technical report, 2023."
    },
    {
      "page_no": 17,
      "bbox": [
        317.8800048828125,
        262.86962890625,
        559.016357421875,
        285.26605224609375
      ],
      "text": "[50] OpenAI. Gpt-4 turbo. https://help.openai.com/\nen/articles/8555510-gpt-4-turbo, 2023."
    },
    {
      "page_no": 17,
      "bbox": [
        317.8800354003906,
        296.2792663574219,
        559.73974609375,
        390.0040588378906
      ],
      "text": "[51] Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida,\nCarroll L. Wainwright, Pamela Mishkin, Chong Zhang,\nSandhini Agarwal, Katarina Slama, Alex Ray, John\nSchulman, Jacob Hilton, Fraser Kelton, Luke Miller,\nMaddie Simens, Amanda Askell, Peter Welinder, Paul F.\nChristiano, Jan Leike, and Ryan Lowe. Training lan-\nguage models to follow instructions with human feed-\nback. In NeurIPS, 2022."
    },
    {
      "page_no": 17,
      "bbox": [
        317.8800048828125,
        401.01727294921875,
        559.6563110351562,
        446.9200744628906
      ],
      "text": "[52] Reiner Pope, Sholto Douglas, Aakanksha Chowdh-\nery, Jacob Devlin, James Bradbury, Anselm Levskaya,\nJonathan Heek, Kefan Xiao, Shivani Agrawal, and Jeff\nDean. Efficiently scaling transformer inference, 2022."
    },
    {
      "page_no": 17,
      "bbox": [
        317.8800048828125,
        457.9895935058594,
        558.0001220703125,
        503.8370666503906
      ],
      "text": "[53] Francisco Romero, Qian Li, Neeraja J Yadwadkar, and\nChristos Kozyrakis. {INFaaS}: Automated model-less\ninference serving. In 2021 USENIX Annual Technical\nConference (USENIX ATC 21), pages 397–411, 2021."
    },
    {
      "page_no": 17,
      "bbox": [
        317.8800048828125,
        514.9254150390625,
        559.6517333984375,
        596.6190795898438
      ],
      "text": "[54] Haichen Shen, Lequn Chen, Yuchen Jin, Liangyu Zhao,\nBingyu Kong, Matthai Philipose, Arvind Krishnamurthy,\nand Ravi Sundaram. Nexus: A gpu cluster engine for\naccelerating dnn-based video analysis. In Proceedings\nof the 27th ACM Symposium on Operating Systems Prin-\nciples, SOSP ’19, page 322–337, New York, NY, USA,\n2019. Association for Computing Machinery."
    },
    {
      "page_no": 17,
      "bbox": [
        317.8800048828125,
        607.6322631835938,
        559.249755859375,
        653.5350341796875
      ],
      "text": "[55] Ying Sheng, Shiyi Cao, Dacheng Li, Banghua Zhu,\nZhuohan Li, Danyang Zhuo, Joseph E. Gonzalez, and\nIon Stoica. Fairness in serving large language models,\n2023."
    },
    {
      "page_no": 17,
      "bbox": [
        317.8800048828125,
        664.5482788085938,
        559.7469482421875,
        722.4070434570312
      ],
      "text": "[56] Mohammad Shoeybi, Mostofa Patwary, Raul Puri,\nPatrick LeGresley, Jared Casper, and Bryan Catanzaro.\nMegatron-LM: Training Multi-Billion Parameter Lan-\nguage Models Using Model Parallelism. arXiv preprint\narXiv:1909.08053, 2019."
    },
    {
      "page_no": 17,
      "bbox": [
        301.0190124511719,
        742.3324584960938,
        310.9815979003906,
        752.2950439453125
      ],
      "text": "17"
    },
    {
      "page_no": 18,
      "bbox": [
        54.0,
        74.40748596191406,
        295.7718505859375,
        144.14505004882812
      ],
      "text": "[57] Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier\nMartinet, Marie-Anne Lachaux, Timothée Lacroix, Bap-\ntiste Rozière, Naman Goyal, Eric Hambro, Faisal Azhar,\nAurelien Rodriguez, Armand Joulin, Edouard Grave,\nand Guillaume Lample. Llama: Open and efficient foun-\ndation language models, 2023."
    },
    {
      "page_no": 18,
      "bbox": [
        54.0,
        154.11825561523438,
        295.7778625488281,
        403.26007080078125
      ],
      "text": "[58] Hugo Touvron, Louis Martin, Kevin Stone, Peter Al-\nbert, Amjad Almahairi, Yasmine Babaei, Nikolay Bash-\nlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale,\nDan Bikel, Lukas Blecher, Cristian Canton Ferrer, Moya\nChen, Guillem Cucurull, David Esiobu, Jude Fernan-\ndes, Jeremy Fu, Wenyin Fu, Brian Fuller, Cynthia Gao,\nVedanuj Goswami, Naman Goyal, Anthony Hartshorn,\nSaghar Hosseini, Rui Hou, Hakan Inan, Marcin Kardas,\nViktor Kerkez, Madian Khabsa, Isabel Kloumann, Artem\nKorenev, Punit Singh Koura, Marie-Anne Lachaux,\nThibaut Lavril, Jenya Lee, Diana Liskovich, Yinghai Lu,\nYuning Mao, Xavier Martinet, Todor Mihaylov, Pushkar\nMishra, Igor Molybog, Yixin Nie, Andrew Poulton,\nJeremy Reizenstein, Rashi Rungta, Kalyan Saladi, Alan\nSchelten, Ruan Silva, Eric Michael Smith, Ranjan Sub-\nramanian, Xiaoqing Ellen Tan, Binh Tang, Ross Taylor,\nAdina Williams, Jian Xiang Kuan, Puxin Xu, Zheng\nYan, Iliyan Zarov, Yuchen Zhang, Angela Fan, Melanie\nKambadur, Sharan Narang, Aurelien Rodriguez, Robert\nStojnic, Sergey Edunov, and Thomas Scialom. Llama 2:\nOpen foundation and fine-tuned chat models, 2023."
    },
    {
      "page_no": 18,
      "bbox": [
        54.0,
        413.2332763671875,
        295.365478515625,
        471.091064453125
      ],
      "text": "[59] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob\nUszkoreit, Llion Jones, Aidan N Gomez, Łukasz Kaiser,\nand Illia Polosukhin.\nAttention is all you need.\nIn\nAdvances in Neural Information Processing Systems,\npages 6000–6010, 2017."
    },
    {
      "page_no": 18,
      "bbox": [
        54.0,
        481.06427001953125,
        295.8663635253906,
        550.8780517578125
      ],
      "text": "[60] Abhishek Verma, Luis Pedrosa, Madhukar Korupolu,\nDavid Oppenheimer, Eric Tune, and John Wilkes. Large-\nscale cluster management at Google with Borg. In Pro-\nceedings of the Tenth European Conference on Com-\nputer Systems, page 18, New York, NY, USA, 2015.\nACM."
    },
    {
      "page_no": 18,
      "bbox": [
        54.0,
        560.9264526367188,
        295.7747497558594,
        666.5310668945312
      ],
      "text": "[61] Xiaohui Wang, Ying Xiong, Yang Wei, Mingxuan Wang,\nand Lei Li. Lightseq: A high performance inference li-\nbrary for transformers. In Young-bum Kim, Yunyao Li,\nand Owen Rambow, editors, Proceedings of the 2021\nConference of the North American Chapter of the Associ-\nation for Computational Linguistics: Human Language\nTechnologies: Industry Papers, NAACL-HLT 2021, On-\nline, June 6-11, 2021, pages 113–120. Association for\nComputational Linguistics, 2021."
    },
    {
      "page_no": 18,
      "bbox": [
        54.0,
        676.5032958984375,
        295.3697814941406,
        722.4070434570312
      ],
      "text": "[62] Yuxin Wang, Yuhan Chen, Zeyu Li, Zhenheng Tang,\nRui Guo, Xin Wang, Qiang Wang, Amelie Chi Zhou,\nand Xiaowen Chu. Towards efficient and reliable llm\nserving: A real-world workload study, 2024."
    },
    {
      "page_no": 18,
      "bbox": [
        317.8800048828125,
        74.40748596191406,
        559.2416381835938,
        108.28005981445312
      ],
      "text": "[63] Bingyang Wu, Yinmin Zhong, Zili Zhang, Gang Huang,\nXuanzhe Liu, and Xin Jin. Fast distributed inference\nserving for large language models, 2023."
    },
    {
      "page_no": 18,
      "bbox": [
        317.8800048828125,
        118.23111724853516,
        559.6583251953125,
        211.89108276367188
      ],
      "text": "[64] Wencong Xiao, Romil Bhardwaj, Ramachandran Ram-\njee, Muthian Sivathanu, Nipun Kwatra, Zhenhua Han,\nPratyush Patel, Xuan Peng, Hanyu Zhao, Quanlu Zhang,\nFan Yang, and Lidong Zhou. Gandiva: Introspective\ncluster scheduling for deep learning. In 13th USENIX\nSymposium on Operating Systems Design and Imple-\nmentation, OSDI 2018, Carlsbad, CA, USA, October 8-\n10, 2018, pages 595–610. USENIX Association, 2018."
    },
    {
      "page_no": 18,
      "bbox": [
        317.8800048828125,
        221.85450744628906,
        559.656494140625,
        315.5030822753906
      ],
      "text": "[65] Wenhan Xiong, Jingyu Liu, Igor Molybog, Hejia Zhang,\nPrajjwal Bhargava, Rui Hou, Louis Martin, Rashi\nRungta, Karthik Abinav Sankararaman, Barlas Oguz,\nMadian Khabsa, Han Fang, Yashar Mehdad, Sharan\nNarang, Kshitiz Malik, Angela Fan, Shruti Bhosale,\nSergey Edunov, Mike Lewis, Sinong Wang, and Hao\nMa. Effective long-context scaling of foundation mod-\nels, 2023."
    },
    {
      "page_no": 18,
      "bbox": [
        317.8800048828125,
        325.39776611328125,
        559.6563110351562,
        407.1590881347656
      ],
      "text": "[66] Hailong Yang, Alex Breslow, Jason Mars, and Lingjia\nTang.\nBubble-flux: precise online qos management\nfor increased utilization in warehouse scale comput-\ners. In Proceedings of the 40th Annual International\nSymposium on Computer Architecture, ISCA ’13, page\n607–618, New York, NY, USA, 2013. Association for\nComputing Machinery."
    },
    {
      "page_no": 18,
      "bbox": [
        317.8800048828125,
        417.1214599609375,
        559.6524658203125,
        486.8600769042969
      ],
      "text": "[67] Gyeong-In Yu, Joo Seong Jeong, Geon-Woo Kim, Soo-\njeong Kim, and Byung-Gon Chun. Orca: A distributed\nserving system for Transformer-Based generative mod-\nels. In 16th USENIX Symposium on Operating Systems\nDesign and Implementation (OSDI 22), pages 521–538,\nCarlsbad, CA, July 2022. USENIX Association."
    },
    {
      "page_no": 18,
      "bbox": [
        317.8800048828125,
        496.748291015625,
        559.24560546875,
        554.6060180664062
      ],
      "text": "[68] Hong Zhang, Yupeng Tang, Anurag Khandelwal, and\nIon Stoica. SHEPHERD: Serving DNNs in the wild. In\n20th USENIX Symposium on Networked Systems Design\nand Implementation (NSDI 23), pages 787–808, Boston,\nMA, April 2023. USENIX Association."
    },
    {
      "page_no": 18,
      "bbox": [
        301.0190124511719,
        742.3324584960938,
        310.9815979003906,
        752.2950439453125
      ],
      "text": "18"
    },
    {
      "page_no": 19,
      "bbox": [
        54.0,
        72.78716278076172,
        167.5983123779297,
        84.74236297607422
      ],
      "text": "A\nArtifact Appendix"
    },
    {
      "page_no": 19,
      "bbox": [
        54.0,
        98.30516815185547,
        98.48529052734375,
        110.26036834716797
      ],
      "text": "Abstract"
    },
    {
      "page_no": 19,
      "bbox": [
        53.691001892089844,
        119.78829956054688,
        295.8674621582031,
        141.75787353515625
      ],
      "text": "This artifact includes the source code and scripts to run the\nexperiments and reproduce the evaluation results of this paper."
    },
    {
      "page_no": 19,
      "bbox": [
        54.0,
        162.36114501953125,
        83.88800048828125,
        174.31634521484375
      ],
      "text": "Scope"
    },
    {
      "page_no": 19,
      "bbox": [
        53.691001892089844,
        183.9964141845703,
        295.77325439453125,
        205.83810424804688
      ],
      "text": "The artifact can be used to reproduce the results of the follow-\ning experiments."
    },
    {
      "page_no": 19,
      "bbox": [
        55.49399948120117,
        220.44349670410156,
        191.4037322998047,
        230.40609741210938
      ],
      "text": "• Migration efficiency: Figure 10."
    },
    {
      "page_no": 19,
      "bbox": [
        55.49399948120117,
        236.3834991455078,
        194.00399780273438,
        246.34609985351562
      ],
      "text": "• Serving performance: Figure 11."
    },
    {
      "page_no": 19,
      "bbox": [
        55.49399948120117,
        252.32350158691406,
        194.30288696289062,
        262.2861022949219
      ],
      "text": "• Support for priorities: Figure 13."
    },
    {
      "page_no": 19,
      "bbox": [
        55.49399948120117,
        268.26446533203125,
        219.11965942382812,
        278.2270812988281
      ],
      "text": "• Auto-scaling: Figure 14 and Figure 15."
    },
    {
      "page_no": 19,
      "bbox": [
        54.0,
        298.80615234375,
        99.82427978515625,
        310.7613525390625
      ],
      "text": "Contents"
    },
    {
      "page_no": 19,
      "bbox": [
        53.691001892089844,
        320.3654479980469,
        231.5432891845703,
        330.32806396484375
      ],
      "text": "This artifact includes the following contents."
    },
    {
      "page_no": 19,
      "bbox": [
        55.49400329589844,
        344.9334411621094,
        286.4369812011719,
        354.89605712890625
      ],
      "text": "• Source code of a prototype implementation of Llumnix."
    },
    {
      "page_no": 19,
      "bbox": [
        55.49400329589844,
        360.79827880859375,
        295.7704162597656,
        394.7460632324219
      ],
      "text": "• Scripts to prepare the environment, run the experiments,\nplot the figures, and validate the claims in this paper auto-\nmatically."
    },
    {
      "page_no": 19,
      "bbox": [
        55.49400329589844,
        400.2456359863281,
        294.12347412109375,
        422.6420593261719
      ],
      "text": "• A README file including detailed instructions on how to use\nthis artifact."
    },
    {
      "page_no": 19,
      "bbox": [
        54.0,
        443.22113037109375,
        93.858642578125,
        455.17633056640625
      ],
      "text": "Hosting"
    },
    {
      "page_no": 19,
      "bbox": [
        53.691001892089844,
        464.3016357421875,
        295.13671875,
        510.6080627441406
      ],
      "text": "The artifact is publicly available at https://github.com/\nAlibabaPAI/llumnix (the osdi24ae branch). Note that this\nis not the same branch as the official release of Llumnix (the\nmain branch). We will describe their difference later."
    },
    {
      "page_no": 19,
      "bbox": [
        53.999996185302734,
        531.1881713867188,
        125.50404357910156,
        543.1433715820312
      ],
      "text": "Requirements"
    },
    {
      "page_no": 19,
      "bbox": [
        53.64097595214844,
        552.7805786132812,
        295.775390625,
        622.4850463867188
      ],
      "text": "The artifact runs on GPU machines, with software dependen-\ncies mostly the same as those of vLLM. To reproduce our\nresults, you would need 4 GPU machines each with 4 A10\nGPUs (24 GB). We recommend that you use the same VM\ntype as in our experiments (ecs.gn7i-c32g1.32xlarge on\nAlibaba Cloud)."
    },
    {
      "page_no": 19,
      "bbox": [
        53.999977111816406,
        643.0641479492188,
        236.1613311767578,
        655.0193481445312
      ],
      "text": "Difference from the Official Release"
    },
    {
      "page_no": 19,
      "bbox": [
        53.64099884033203,
        664.5482788085938,
        295.861083984375,
        722.4070434570312
      ],
      "text": "This artifact is a research prototype and was used during\nthe experiments of this paper. After the paper submission,\nwe refactored it into a new implementation that is more\nproduction-ready, i.e., the official release, as described in §5.\nMajor differences between the two versions include:"
    },
    {
      "page_no": 19,
      "bbox": [
        319.3739929199219,
        71.12429809570312,
        559.2445678710938,
        117.02706909179688
      ],
      "text": "• The artifact is directly based on the vLLM code base,\nwhereas the official release is a standalone Python library,\nmaking it more extensible and non-intrusive to backend\ninference engines."
    },
    {
      "page_no": 19,
      "bbox": [
        319.3739929199219,
        123.00447082519531,
        557.9976806640625,
        144.92208862304688
      ],
      "text": "• The artifact is not fault-tolerant, whereas the official release\nprovides fault tolerance for each component."
    },
    {
      "page_no": 19,
      "bbox": [
        319.3739929199219,
        150.82528686523438,
        559.2488403320312,
        208.68307495117188
      ],
      "text": "• The official release is still being actively developed, and\nhas supported or will support a series of new features, such\nas scalable API servicing via distributed request frontends,\nsupport for newer versions of vLLM and more models,\nfurther improvements of the scheduling policies, etc."
    },
    {
      "page_no": 19,
      "bbox": [
        317.8800048828125,
        220.56326293945312,
        559.6553344726562,
        266.4670715332031
      ],
      "text": "The artifact is sufficient to reproduce the experiment re-\nsults in this paper. However, if you want to use Llumnix in\nproduction or conduct further research, we do recommend the\nofficial release."
    },
    {
      "page_no": 19,
      "bbox": [
        301.0190124511719,
        742.3324584960938,
        310.9815979003906,
        752.2950439453125
      ],
      "text": "19"
    }
  ],
  "pictures": [
    {
      "page_no": 1,
      "bbox": [
        412.0,
        54.0,
        420.0,
        64.0
      ],
      "xref": 0,
      "image_path": "../data/parsed_documents/2406.03243/images/2406.03243_p1_blk1_crop.png"
    },
    {
      "page_no": 1,
      "bbox": [
        413.0,
        59.0,
        423.0,
        66.0
      ],
      "xref": 1,
      "image_path": "../data/parsed_documents/2406.03243/images/2406.03243_p1_blk2_crop.png"
    },
    {
      "page_no": 1,
      "bbox": [
        465.0,
        54.0,
        473.0,
        64.0
      ],
      "xref": 2,
      "image_path": "../data/parsed_documents/2406.03243/images/2406.03243_p1_blk3_crop.png"
    },
    {
      "page_no": 1,
      "bbox": [
        466.0,
        59.0,
        477.0,
        66.0
      ],
      "xref": 3,
      "image_path": "../data/parsed_documents/2406.03243/images/2406.03243_p1_blk4_crop.png"
    },
    {
      "page_no": 1,
      "bbox": [
        518.0,
        54.0,
        526.0,
        64.0
      ],
      "xref": 4,
      "image_path": "../data/parsed_documents/2406.03243/images/2406.03243_p1_blk5_crop.png"
    },
    {
      "page_no": 1,
      "bbox": [
        519.0,
        59.0,
        530.0,
        66.0
      ],
      "xref": 5,
      "image_path": "../data/parsed_documents/2406.03243/images/2406.03243_p1_blk6_crop.png"
    },
    {
      "page_no": 2,
      "bbox": [
        356.1029968261719,
        125.26959228515625,
        359.539794921875,
        128.70639038085938
      ],
      "xref": 1,
      "image_path": "../data/parsed_documents/2406.03243/images/2406.03243_p2_blk1_crop.png"
    },
    {
      "page_no": 2,
      "bbox": [
        421.4022216796875,
        121.83279418945312,
        424.8390197753906,
        125.26959228515625
      ],
      "xref": 2,
      "image_path": "../data/parsed_documents/2406.03243/images/2406.03243_p2_blk2_crop.png"
    },
    {
      "page_no": 2,
      "bbox": [
        527.9429931640625,
        121.83279418945312,
        531.3798217773438,
        125.26959228515625
      ],
      "xref": 3,
      "image_path": "../data/parsed_documents/2406.03243/images/2406.03243_p2_blk3_crop.png"
    },
    {
      "page_no": 2,
      "bbox": [
        472.9542236328125,
        114.95919799804688,
        476.3910217285156,
        118.39599609375
      ],
      "xref": 4,
      "image_path": "../data/parsed_documents/2406.03243/images/2406.03243_p2_blk4_crop.png"
    },
    {
      "page_no": 2,
      "bbox": [
        393.90777587890625,
        84.02798461914062,
        397.3445739746094,
        87.46478271484375
      ],
      "xref": 8,
      "image_path": "../data/parsed_documents/2406.03243/images/2406.03243_p2_blk5_crop.png"
    },
    {
      "page_no": 5,
      "bbox": [
        367.03460693359375,
        108.48259735107422,
        369.3882141113281,
        110.83619689941406
      ],
      "xref": 4,
      "image_path": "../data/parsed_documents/2406.03243/images/2406.03243_p5_blk1_crop.png"
    },
    {
      "page_no": 5,
      "bbox": [
        371.7417907714844,
        108.48259735107422,
        374.09539794921875,
        110.83619689941406
      ],
      "xref": 5,
      "image_path": "../data/parsed_documents/2406.03243/images/2406.03243_p5_blk2_crop.png"
    },
    {
      "page_no": 5,
      "bbox": [
        376.448974609375,
        108.48259735107422,
        378.8025817871094,
        110.83619689941406
      ],
      "xref": 6,
      "image_path": "../data/parsed_documents/2406.03243/images/2406.03243_p5_blk3_crop.png"
    },
    {
      "page_no": 5,
      "bbox": [
        381.15618896484375,
        108.48259735107422,
        383.5097961425781,
        110.83619689941406
      ],
      "xref": 7,
      "image_path": "../data/parsed_documents/2406.03243/images/2406.03243_p5_blk4_crop.png"
    },
    {
      "page_no": 5,
      "bbox": [
        385.8634033203125,
        108.48259735107422,
        388.2170104980469,
        110.83619689941406
      ],
      "xref": 8,
      "image_path": "../data/parsed_documents/2406.03243/images/2406.03243_p5_blk5_crop.png"
    },
    {
      "page_no": 5,
      "bbox": [
        390.5705871582031,
        108.48259735107422,
        392.9241943359375,
        110.83619689941406
      ],
      "xref": 9,
      "image_path": "../data/parsed_documents/2406.03243/images/2406.03243_p5_blk6_crop.png"
    },
    {
      "page_no": 5,
      "bbox": [
        395.27777099609375,
        108.48259735107422,
        397.6313781738281,
        110.83619689941406
      ],
      "xref": 10,
      "image_path": "../data/parsed_documents/2406.03243/images/2406.03243_p5_blk7_crop.png"
    },
    {
      "page_no": 5,
      "bbox": [
        399.9849853515625,
        108.48259735107422,
        402.3385925292969,
        110.83619689941406
      ],
      "xref": 11,
      "image_path": "../data/parsed_documents/2406.03243/images/2406.03243_p5_blk8_crop.png"
    },
    {
      "page_no": 5,
      "bbox": [
        404.69219970703125,
        108.48259735107422,
        407.0458068847656,
        110.83619689941406
      ],
      "xref": 12,
      "image_path": "../data/parsed_documents/2406.03243/images/2406.03243_p5_blk9_crop.png"
    },
    {
      "page_no": 5,
      "bbox": [
        418.81378173828125,
        108.48259735107422,
        421.1673889160156,
        110.83619689941406
      ],
      "xref": 19,
      "image_path": "../data/parsed_documents/2406.03243/images/2406.03243_p5_blk10_crop.png"
    },
    {
      "page_no": 5,
      "bbox": [
        437.642578125,
        108.48259735107422,
        439.9961853027344,
        110.83619689941406
      ],
      "xref": 20,
      "image_path": "../data/parsed_documents/2406.03243/images/2406.03243_p5_blk11_crop.png"
    },
    {
      "page_no": 5,
      "bbox": [
        439.9961853027344,
        108.48259735107422,
        442.34979248046875,
        110.83619689941406
      ],
      "xref": 21,
      "image_path": "../data/parsed_documents/2406.03243/images/2406.03243_p5_blk12_crop.png"
    },
    {
      "page_no": 5,
      "bbox": [
        444.703369140625,
        108.48259735107422,
        447.0569763183594,
        110.83619689941406
      ],
      "xref": 22,
      "image_path": "../data/parsed_documents/2406.03243/images/2406.03243_p5_blk13_crop.png"
    },
    {
      "page_no": 5,
      "bbox": [
        449.41058349609375,
        108.48259735107422,
        451.7641906738281,
        110.83619689941406
      ],
      "xref": 23,
      "image_path": "../data/parsed_documents/2406.03243/images/2406.03243_p5_blk14_crop.png"
    },
    {
      "page_no": 5,
      "bbox": [
        454.1177978515625,
        108.48259735107422,
        456.4714050292969,
        110.83619689941406
      ],
      "xref": 24,
      "image_path": "../data/parsed_documents/2406.03243/images/2406.03243_p5_blk15_crop.png"
    },
    {
      "page_no": 5,
      "bbox": [
        458.82501220703125,
        108.48259735107422,
        461.1786193847656,
        110.83619689941406
      ],
      "xref": 25,
      "image_path": "../data/parsed_documents/2406.03243/images/2406.03243_p5_blk16_crop.png"
    },
    {
      "page_no": 5,
      "bbox": [
        472.94659423828125,
        108.48259735107422,
        475.3002014160156,
        110.83619689941406
      ],
      "xref": 27,
      "image_path": "../data/parsed_documents/2406.03243/images/2406.03243_p5_blk17_crop.png"
    },
    {
      "page_no": 5,
      "bbox": [
        477.65380859375,
        108.48259735107422,
        480.0074157714844,
        110.83619689941406
      ],
      "xref": 28,
      "image_path": "../data/parsed_documents/2406.03243/images/2406.03243_p5_blk18_crop.png"
    },
    {
      "page_no": 5,
      "bbox": [
        381.15618896484375,
        164.968994140625,
        383.5097961425781,
        167.32260131835938
      ],
      "xref": 30,
      "image_path": "../data/parsed_documents/2406.03243/images/2406.03243_p5_blk19_crop.png"
    },
    {
      "page_no": 5,
      "bbox": [
        385.8634033203125,
        164.968994140625,
        388.2170104980469,
        167.32260131835938
      ],
      "xref": 31,
      "image_path": "../data/parsed_documents/2406.03243/images/2406.03243_p5_blk20_crop.png"
    },
    {
      "page_no": 5,
      "bbox": [
        390.5705871582031,
        164.968994140625,
        392.9241943359375,
        167.32260131835938
      ],
      "xref": 32,
      "image_path": "../data/parsed_documents/2406.03243/images/2406.03243_p5_blk21_crop.png"
    },
    {
      "page_no": 5,
      "bbox": [
        395.27777099609375,
        164.968994140625,
        397.6313781738281,
        167.32260131835938
      ],
      "xref": 33,
      "image_path": "../data/parsed_documents/2406.03243/images/2406.03243_p5_blk22_crop.png"
    },
    {
      "page_no": 5,
      "bbox": [
        399.9849853515625,
        164.968994140625,
        402.3385925292969,
        167.32260131835938
      ],
      "xref": 34,
      "image_path": "../data/parsed_documents/2406.03243/images/2406.03243_p5_blk23_crop.png"
    },
    {
      "page_no": 5,
      "bbox": [
        404.69219970703125,
        164.968994140625,
        407.0458068847656,
        167.32260131835938
      ],
      "xref": 35,
      "image_path": "../data/parsed_documents/2406.03243/images/2406.03243_p5_blk24_crop.png"
    },
    {
      "page_no": 5,
      "bbox": [
        447.0570068359375,
        164.968994140625,
        449.4106140136719,
        167.32260131835938
      ],
      "xref": 39,
      "image_path": "../data/parsed_documents/2406.03243/images/2406.03243_p5_blk25_crop.png"
    },
    {
      "page_no": 5,
      "bbox": [
        451.7641906738281,
        164.968994140625,
        454.1177978515625,
        167.32260131835938
      ],
      "xref": 40,
      "image_path": "../data/parsed_documents/2406.03243/images/2406.03243_p5_blk26_crop.png"
    },
    {
      "page_no": 5,
      "bbox": [
        454.1177978515625,
        164.968994140625,
        456.4714050292969,
        167.32260131835938
      ],
      "xref": 41,
      "image_path": "../data/parsed_documents/2406.03243/images/2406.03243_p5_blk27_crop.png"
    },
    {
      "page_no": 5,
      "bbox": [
        458.82501220703125,
        164.968994140625,
        461.1786193847656,
        167.32260131835938
      ],
      "xref": 42,
      "image_path": "../data/parsed_documents/2406.03243/images/2406.03243_p5_blk28_crop.png"
    },
    {
      "page_no": 5,
      "bbox": [
        463.5321960449219,
        164.968994140625,
        465.88580322265625,
        167.32260131835938
      ],
      "xref": 43,
      "image_path": "../data/parsed_documents/2406.03243/images/2406.03243_p5_blk29_crop.png"
    },
    {
      "page_no": 5,
      "bbox": [
        468.2393798828125,
        164.968994140625,
        470.5929870605469,
        167.32260131835938
      ],
      "xref": 44,
      "image_path": "../data/parsed_documents/2406.03243/images/2406.03243_p5_blk30_crop.png"
    },
    {
      "page_no": 5,
      "bbox": [
        409.3993835449219,
        164.968994140625,
        411.75299072265625,
        167.32260131835938
      ],
      "xref": 45,
      "image_path": "../data/parsed_documents/2406.03243/images/2406.03243_p5_blk31_crop.png"
    },
    {
      "page_no": 5,
      "bbox": [
        414.1065979003906,
        164.968994140625,
        416.460205078125,
        167.32260131835938
      ],
      "xref": 46,
      "image_path": "../data/parsed_documents/2406.03243/images/2406.03243_p5_blk32_crop.png"
    },
    {
      "page_no": 5,
      "bbox": [
        418.81378173828125,
        164.968994140625,
        421.1673889160156,
        167.32260131835938
      ],
      "xref": 47,
      "image_path": "../data/parsed_documents/2406.03243/images/2406.03243_p5_blk33_crop.png"
    },
    {
      "page_no": 5,
      "bbox": [
        430.581787109375,
        164.968994140625,
        432.9353942871094,
        167.32260131835938
      ],
      "xref": 49,
      "image_path": "../data/parsed_documents/2406.03243/images/2406.03243_p5_blk34_crop.png"
    },
    {
      "page_no": 5,
      "bbox": [
        501.1897888183594,
        108.48259735107422,
        503.54339599609375,
        110.83619689941406
      ],
      "xref": 54,
      "image_path": "../data/parsed_documents/2406.03243/images/2406.03243_p5_blk35_crop.png"
    },
    {
      "page_no": 5,
      "bbox": [
        482.3609924316406,
        164.968994140625,
        484.714599609375,
        167.32260131835938
      ],
      "xref": 55,
      "image_path": "../data/parsed_documents/2406.03243/images/2406.03243_p5_blk36_crop.png"
    },
    {
      "page_no": 5,
      "bbox": [
        487.06817626953125,
        164.968994140625,
        489.4217834472656,
        167.32260131835938
      ],
      "xref": 56,
      "image_path": "../data/parsed_documents/2406.03243/images/2406.03243_p5_blk37_crop.png"
    },
    {
      "page_no": 5,
      "bbox": [
        503.54339599609375,
        164.968994140625,
        505.8970031738281,
        167.32260131835938
      ],
      "xref": 57,
      "image_path": "../data/parsed_documents/2406.03243/images/2406.03243_p5_blk38_crop.png"
    },
    {
      "page_no": 5,
      "bbox": [
        515.3114013671875,
        101.42179107666016,
        517.6649780273438,
        103.775390625
      ],
      "xref": 61,
      "image_path": "../data/parsed_documents/2406.03243/images/2406.03243_p5_blk39_crop.png"
    },
    {
      "page_no": 6,
      "bbox": [
        409.15447998046875,
        113.43408966064453,
        413.45928955078125,
        117.7388916015625
      ],
      "xref": 33,
      "image_path": "../data/parsed_documents/2406.03243/images/2406.03243_p6_blk1_crop.png"
    },
    {
      "page_no": 6,
      "bbox": [
        396.2400817871094,
        87.60529327392578,
        400.5448913574219,
        91.91009521484375
      ],
      "xref": 35,
      "image_path": "../data/parsed_documents/2406.03243/images/2406.03243_p6_blk2_crop.png"
    },
    {
      "page_no": 6,
      "bbox": [
        422.0688781738281,
        87.60529327392578,
        426.3736877441406,
        91.91009521484375
      ],
      "xref": 36,
      "image_path": "../data/parsed_documents/2406.03243/images/2406.03243_p6_blk3_crop.png"
    },
    {
      "page_no": 6,
      "bbox": [
        460.8121032714844,
        87.60529327392578,
        465.1169128417969,
        91.91009521484375
      ],
      "xref": 37,
      "image_path": "../data/parsed_documents/2406.03243/images/2406.03243_p6_blk4_crop.png"
    },
    {
      "page_no": 7,
      "bbox": [
        402.7364196777344,
        93.9773178100586,
        405.99224853515625,
        97.233154296875
      ],
      "xref": 3,
      "image_path": "../data/parsed_documents/2406.03243/images/2406.03243_p7_blk1_crop.png"
    },
    {
      "page_no": 7,
      "bbox": [
        523.2025146484375,
        126.53571319580078,
        526.4583740234375,
        129.7915496826172
      ],
      "xref": 4,
      "image_path": "../data/parsed_documents/2406.03243/images/2406.03243_p7_blk2_crop.png"
    },
    {
      "page_no": 7,
      "bbox": [
        471.10906982421875,
        120.02404022216797,
        474.3648986816406,
        123.27987670898438
      ],
      "xref": 5,
      "image_path": "../data/parsed_documents/2406.03243/images/2406.03243_p7_blk3_crop.png"
    },
    {
      "page_no": 7,
      "bbox": [
        503.6674499511719,
        103.74483489990234,
        506.92327880859375,
        107.00067138671875
      ],
      "xref": 6,
      "image_path": "../data/parsed_documents/2406.03243/images/2406.03243_p7_blk4_crop.png"
    },
    {
      "page_no": 7,
      "bbox": [
        451.57403564453125,
        116.76819610595703,
        454.8298645019531,
        120.02403259277344
      ],
      "xref": 7,
      "image_path": "../data/parsed_documents/2406.03243/images/2406.03243_p7_blk5_crop.png"
    },
    {
      "page_no": 7,
      "bbox": [
        402.7364196777344,
        71.1864242553711,
        405.99224853515625,
        74.4422607421875
      ],
      "xref": 9,
      "image_path": "../data/parsed_documents/2406.03243/images/2406.03243_p7_blk6_crop.png"
    },
    {
      "page_no": 7,
      "bbox": [
        360.4104919433594,
        129.7915496826172,
        363.66632080078125,
        133.04739379882812
      ],
      "xref": 11,
      "image_path": "../data/parsed_documents/2406.03243/images/2406.03243_p7_blk7_crop.png"
    },
    {
      "page_no": 7,
      "bbox": [
        422.2714538574219,
        126.53571319580078,
        425.52728271484375,
        129.7915496826172
      ],
      "xref": 12,
      "image_path": "../data/parsed_documents/2406.03243/images/2406.03243_p7_blk8_crop.png"
    }
  ],
  "tables": [
    {
      "page_no": 1,
      "index": 1,
      "flavor": "stream",
      "nrows": 71,
      "ncols": 2,
      "csv_path": "../data/parsed_documents/2406.03243/2406.03243_p1_table1_stream.csv"
    },
    {
      "page_no": 2,
      "index": 1,
      "flavor": "stream",
      "nrows": 68,
      "ncols": 2,
      "csv_path": "../data/parsed_documents/2406.03243/2406.03243_p2_table1_stream.csv"
    },
    {
      "page_no": 3,
      "index": 1,
      "flavor": "stream",
      "nrows": 17,
      "ncols": 9,
      "csv_path": "../data/parsed_documents/2406.03243/2406.03243_p3_table1_stream.csv"
    },
    {
      "page_no": 3,
      "index": 2,
      "flavor": "stream",
      "nrows": 61,
      "ncols": 2,
      "csv_path": "../data/parsed_documents/2406.03243/2406.03243_p3_table2_stream.csv"
    },
    {
      "page_no": 4,
      "index": 1,
      "flavor": "stream",
      "nrows": 11,
      "ncols": 9,
      "csv_path": "../data/parsed_documents/2406.03243/2406.03243_p4_table1_stream.csv"
    },
    {
      "page_no": 4,
      "index": 2,
      "flavor": "stream",
      "nrows": 49,
      "ncols": 2,
      "csv_path": "../data/parsed_documents/2406.03243/2406.03243_p4_table2_stream.csv"
    },
    {
      "page_no": 5,
      "index": 1,
      "flavor": "stream",
      "nrows": 70,
      "ncols": 2,
      "csv_path": "../data/parsed_documents/2406.03243/2406.03243_p5_table1_stream.csv"
    },
    {
      "page_no": 6,
      "index": 1,
      "flavor": "stream",
      "nrows": 86,
      "ncols": 2,
      "csv_path": "../data/parsed_documents/2406.03243/2406.03243_p6_table1_stream.csv"
    },
    {
      "page_no": 7,
      "index": 1,
      "flavor": "stream",
      "nrows": 81,
      "ncols": 2,
      "csv_path": "../data/parsed_documents/2406.03243/2406.03243_p7_table1_stream.csv"
    },
    {
      "page_no": 8,
      "index": 1,
      "flavor": "stream",
      "nrows": 19,
      "ncols": 4,
      "csv_path": "../data/parsed_documents/2406.03243/2406.03243_p8_table1_stream.csv"
    },
    {
      "page_no": 8,
      "index": 2,
      "flavor": "stream",
      "nrows": 29,
      "ncols": 3,
      "csv_path": "../data/parsed_documents/2406.03243/2406.03243_p8_table2_stream.csv"
    },
    {
      "page_no": 8,
      "index": 3,
      "flavor": "stream",
      "nrows": 51,
      "ncols": 2,
      "csv_path": "../data/parsed_documents/2406.03243/2406.03243_p8_table3_stream.csv"
    },
    {
      "page_no": 9,
      "index": 1,
      "flavor": "stream",
      "nrows": 25,
      "ncols": 2,
      "csv_path": "../data/parsed_documents/2406.03243/2406.03243_p9_table1_stream.csv"
    },
    {
      "page_no": 9,
      "index": 2,
      "flavor": "stream",
      "nrows": 73,
      "ncols": 2,
      "csv_path": "../data/parsed_documents/2406.03243/2406.03243_p9_table2_stream.csv"
    },
    {
      "page_no": 10,
      "index": 1,
      "flavor": "stream",
      "nrows": 16,
      "ncols": 3,
      "csv_path": "../data/parsed_documents/2406.03243/2406.03243_p10_table1_stream.csv"
    },
    {
      "page_no": 10,
      "index": 2,
      "flavor": "stream",
      "nrows": 48,
      "ncols": 2,
      "csv_path": "../data/parsed_documents/2406.03243/2406.03243_p10_table2_stream.csv"
    },
    {
      "page_no": 10,
      "index": 3,
      "flavor": "stream",
      "nrows": 76,
      "ncols": 2,
      "csv_path": "../data/parsed_documents/2406.03243/2406.03243_p10_table3_stream.csv"
    },
    {
      "page_no": 11,
      "index": 1,
      "flavor": "stream",
      "nrows": 69,
      "ncols": 28,
      "csv_path": "../data/parsed_documents/2406.03243/2406.03243_p11_table1_stream.csv"
    },
    {
      "page_no": 11,
      "index": 2,
      "flavor": "stream",
      "nrows": 13,
      "ncols": 9,
      "csv_path": "../data/parsed_documents/2406.03243/2406.03243_p11_table2_stream.csv"
    },
    {
      "page_no": 11,
      "index": 3,
      "flavor": "stream",
      "nrows": 14,
      "ncols": 2,
      "csv_path": "../data/parsed_documents/2406.03243/2406.03243_p11_table3_stream.csv"
    },
    {
      "page_no": 12,
      "index": 1,
      "flavor": "stream",
      "nrows": 22,
      "ncols": 31,
      "csv_path": "../data/parsed_documents/2406.03243/2406.03243_p12_table1_stream.csv"
    },
    {
      "page_no": 12,
      "index": 2,
      "flavor": "stream",
      "nrows": 42,
      "ncols": 2,
      "csv_path": "../data/parsed_documents/2406.03243/2406.03243_p12_table2_stream.csv"
    },
    {
      "page_no": 13,
      "index": 1,
      "flavor": "lattice",
      "nrows": 1,
      "ncols": 3,
      "csv_path": "../data/parsed_documents/2406.03243/2406.03243_p13_table1_lattice.csv"
    },
    {
      "page_no": 14,
      "index": 1,
      "flavor": "stream",
      "nrows": 69,
      "ncols": 2,
      "csv_path": "../data/parsed_documents/2406.03243/2406.03243_p14_table1_stream.csv"
    },
    {
      "page_no": 15,
      "index": 1,
      "flavor": "stream",
      "nrows": 77,
      "ncols": 2,
      "csv_path": "../data/parsed_documents/2406.03243/2406.03243_p15_table1_stream.csv"
    },
    {
      "page_no": 16,
      "index": 1,
      "flavor": "stream",
      "nrows": 81,
      "ncols": 2,
      "csv_path": "../data/parsed_documents/2406.03243/2406.03243_p16_table1_stream.csv"
    },
    {
      "page_no": 17,
      "index": 1,
      "flavor": "stream",
      "nrows": 71,
      "ncols": 2,
      "csv_path": "../data/parsed_documents/2406.03243/2406.03243_p17_table1_stream.csv"
    },
    {
      "page_no": 18,
      "index": 1,
      "flavor": "stream",
      "nrows": 80,
      "ncols": 2,
      "csv_path": "../data/parsed_documents/2406.03243/2406.03243_p18_table1_stream.csv"
    },
    {
      "page_no": 19,
      "index": 1,
      "flavor": "stream",
      "nrows": 20,
      "ncols": 2,
      "csv_path": "../data/parsed_documents/2406.03243/2406.03243_p19_table1_stream.csv"
    }
  ]
}