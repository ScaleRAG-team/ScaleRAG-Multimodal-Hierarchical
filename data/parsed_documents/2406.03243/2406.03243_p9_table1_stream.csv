"We evaluate Llumnix on a 16-GPU cluster using realistic mod-",""
"","(CVs) to adjust the burstiness of the requests. Each trace has"
"els and various workloads. Overall, our key findings include:",""
"","10,000 requests. We choose an appropriate range of request"
"","rates or CVs for the traces to maintain the loads within a rea-"
"• Llumnix introduces near-zero downtime to requests being",""
"","sonable range: nearly no queuing delays and preemptions for"
"migrated and near-zero overhead to other running requests.",""
"","P50 requests, and queuing delays within a few tens of seconds"
"• Llumnix improves prefill
latencies by up to 15×/7.7×","for P99 requests when using Llumnix."
"(P99/mean) over INFaaS on 16 LLaMA-7B instances via",""
"","For the input/output lengths of requests, we use two public"
"de-fragmentation. Llumnix also improves P99 decode la-",""
"","ChatGPT-4 conversation datasets, ShareGPT (GPT4) [10] and"
"tency by up to 2× by reducing preemptions.",""
"","BurstGPT (GPT4-Conversation) [62], for an evaluation on"
"• Llumnix improves high-priority request latencies by up to","real workloads. Considering that Llumnix targets more diver-"
"1.5× by reducing their queuing delays and accelerating","sified applications, we also use generated power-law length"
"their execution, while preserving similar performance of","distributions to emulate long-tail workloads that mix both fre-"
"the normal requests.","quent, short sequences (e.g., for interactive applications like"
"","chatbots and personal assistants) and seldom, long sequences"
"• Llumnix achieves up to 36% cost saving while preserving",""
"","(e.g., summarizing or writing articles). We generate multiple"
"similar P99 latencies with efficient auto-scaling.",""
"","distributions with different long-tail degrees and mean lengths"
