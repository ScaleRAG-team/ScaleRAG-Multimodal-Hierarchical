"","2048+2048","","6.7B
24","throughput (token/s)","494.1","918.9"
"","2048+2048","","6.7B
64","throughput (token/s)","OOM","1161.0"
"","We implement our KV cache eviction policy in a","","","Table 4: Results of generation throughput (token/s)","",""
"","state-of-the-art inference engine, FlexGen [19], and","","","on a T4 GPU with different systems on real-world","",""
"report","the","throughput","and latency improvements.","datasets, XSUM.","",""
"","H2O is orthogonal to existing optimizations in Flex-","","","","",""
"","","","","Model size","6.7B","30B"
"","Gen, such as offloading and quantization, so they can","","","","",""
"","be combined to achieve better performance.","","","","",""
"","","","","Accelerate","11.98 (1, G)","0.23 (2, C)"
"Setup","","We conducted experiments on two GPUs:","","DeepSpeed","3.52 (6, C)","0.31 (2, C)"
"","an NVIDIA T4 (16GB) GPU and an NVIDIA A100","","","FlexGen","10.80 (1, G)","3.29 (44, C)"
"(80GB) GPU. On the T4 GPU, we evaluate the gen-","","","","","",""
"","","","","H2O (20%)","30.40 (1, G)","6.70 (180, C)"
"","eration throughput following the settings in the Flex-","","","","",""
"","Gen paper. The evaluated models are OPT-6.7B and","","","","",""
"","OPT-30B. When the model and KV cache do not fit into a single GPU, we turn on CPU offloading.","","","","",""
