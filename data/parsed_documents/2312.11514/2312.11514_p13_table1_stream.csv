"Todor Mihaylov, Myle Ott, Sam Shleifer, Kurt Shus-"
"ter, Daniel Simig, Punit Singh Koura, Anjali Srid-"
"har, Tianlu Wang,
and Luke Zettlemoyer. 2022b."
"OPT: open pre-trained transformer
language mod-"
"els. CoRR, abs/2205.01068."
"Zhengyan Zhang, Yixin Song, Guanghui Yu, Xu Han,"
"Yankai Lin, Chaojun Xiao, Chenyang Song, Zhiyuan"
"Liu, Zeyu Mi, and Maosong Sun. 2024. Relu2 wins:"
"Discovering efficient activation functions for sparse"
"llms."
"Yilong Zhao, Chien-Yu Lin, Kan Zhu, Zihao Ye, Lequn"
"Chen, Size Zheng, Luis Ceze, Arvind Krishnamurthy,"
"Tianqi Chen, and Baris Kasikci. 2023. Atom: Low-"
"bit quantization for efficient and accurate llm serving."
"ArXiv, abs/2310.19102."
