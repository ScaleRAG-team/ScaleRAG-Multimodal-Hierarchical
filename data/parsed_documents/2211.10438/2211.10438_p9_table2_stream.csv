"","number of GPUs, which allows serving the 530B model","","","","","token to per-tensor, dynamic to static, O1 to O3, defined","","",""
"within a single node.","","","","","","in Table 2), the lower the latency. SmoothQuant achieves","","",""
"","","","","","","lower latency compared to FP16 under all settings, while","","",""
"SeqLen","Prec.","#GPUs","Latency","Memory","","LLM.int8() is mostly slower. The batch size is 4.","","",""
"128","FP16","16","232ms","1040GB","","","","",""
"","INT8","8","253ms","527GB","Model","OPT-13B","","OPT-30B",""
"256","FP16","16","451ms","1054GB","Sequence Length","256","512","256","512"
"","INT8","8","434ms","533GB","","","","",""
"","","","","","FP16","152.6","296.3","343.0","659.9"
"512","FP16","16","838ms","1068GB","LLM.int8()","237.1","371.5","387.9","654.9"
"","INT8","8","839ms","545GB","","","","",""
"","","","","","SmoothQuant-O1","124.5","243.3","246.7","490.7"
"1024","FP16","16","1707ms","1095GB","SmoothQuant-O2","120.5","235.1","240.2","478.3"
"","INT8","8","1689ms","570GB","SmoothQuant-O3","112.1","223.1","227.6","458.4"
