"","AWQ: Activation-aware Weight Quantization for On-Device LLM Compression and Acceleration","","","","","","","","",""
"","","180","Generation Stage:","","","","","","",""
"","","","","","","103","","Weight","","Activation"
"10 ms","","","Arith. Inten. = 4,","","","","","","",""
"","","144","","","","102","","","",""
"","","","4TFLOPS (W4A16)","Context stage:","","","","","271",""
"","","","","","","","134","","",""
"","","108","","Arith. Inten. >= 165","","","","","",""
"","","","","","","","","79x","",""
"","","","","","","10","","","","1700x"
"Context (200 tokens)","Peak TFLOPS","72","","","","","","","",""
"Generation (20 tokens)","","","","Generation Stage:","","","","","",""
"","","36","","","Memory footprint (MB)","1","","","",""
"","","","","","","","","1.7","",""
"","","","","Arith. Inten. = 1, 1TFLOPS (W16A16)","","","","","",""
"","","0","","","","","","","",""
"","","","","","","10-1","","","","0.2"
