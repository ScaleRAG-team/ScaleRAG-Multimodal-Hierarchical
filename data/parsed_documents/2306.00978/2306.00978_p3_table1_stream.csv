"","AWQ: Activation-aware Weight Quantization for On-Device LLM Compression and Acceleration","","","","","","","","","","",""
"","","","","","","","bad hardware efficiency","","","","",""
"WFP16","","Q(W)INT3","","","","","","Q(W)MixPrec","","","","Q(W)INT3"
"+1.2 −0.2 −2.4 −3.4","+1","+0","−2","−3","","","+1","+0","−2","−3","",""
"","","","","","","","","","","","","scale before quantize"
"−2.5 −3.5 +1.9 +1.4","−3","−4","+2","+1","determine the salient","","","−2.5 −3.5 +1.9 +1.4","","FP16","",""
"","","","","","","","","","","channel","",""
"−0.9 +1.6 −2.5 −1.9","−1","+2","−3","−2","weights by","","−1","+2","−3","−2","","α"
"Q
−3.5 +1.5 +0.5 −0.1","−4","+2","+1","+0","activation","","−4","+2","+1","+0","",""
"","","","","","","","","","","","","average mag."
"+1.8 −1.6 −3.2 −3.4","+2","−2","−3","−3","","","+2","−2","−3","−3","",""
"+2.4 −3.5 −2.8 −3.9","+2","−4","−3","−4","","","+2","−4","−3","−4","",""
"+0.1 −3.8 +2.4 +3.4","+0","−4","+2","+3","X","*","+0","−4","+2","+3","X","*"
"+0.9 +3.3 −1.9 −2.3","+1","+3","−2","−2","","","+1","+3","−2","−2","",""
"(a) RTN quantization (PPL 43.2)","","","","","","(b) Keep 1% salient weights in FP16 (PPL 13.0)","","","","","","(c) Scale the weights before quantization (PPL 13.0)"
