"system throughput. Finally, we conduct convergence evaluation in-",""
"","Algorithm 1: ZeRO algorithm"
"dicating that ZeRO++ has negligible impact on model convergence",""
"","Input
:ğ‘šğ‘œğ‘‘ğ‘’ğ‘™,ğ‘¤ğ‘œğ‘Ÿğ‘™ğ‘‘ğ‘†ğ‘–ğ‘§ğ‘’"
"and maintains similar model training accuracy as ZeRO baseline.",""
"","Output :ğ‘šğ‘œğ‘‘ğ‘’ğ‘™"
"The main contributions of this paper are as follows:",""
"","1 while ğ‘šğ‘œğ‘‘ğ‘’ğ‘™ not converged do"
"","ğ‘ğ‘™ğ‘™_ğ‘”ğ‘ğ‘¡â„ğ‘’ğ‘Ÿ _ğ‘ƒğ‘ğ‘Ÿğ‘ğ‘šğ‘’ğ‘¡ğ‘’ğ‘Ÿğ‘  (ğ‘¤ğ‘œğ‘Ÿğ‘™ğ‘‘ğ‘†ğ‘–ğ‘§ğ‘’ );"
"â€¢ Blocked quantized weights (ğ‘ğ‘¤ğ‘ ) reduces communication","2"
"volume of all-gather of weights by 50%.","ğ‘šğ‘œğ‘‘ğ‘’ğ‘™ .ğ‘“ ğ‘œğ‘Ÿ ğ‘¤ğ‘ğ‘Ÿğ‘‘ ();
3"
"","ğ‘ğ‘ğ‘Ÿğ‘¡ğ‘–ğ‘¡ğ‘–ğ‘œğ‘› (ğ‘¤ğ‘œğ‘Ÿğ‘™ğ‘‘ğ‘†ğ‘–ğ‘§ğ‘’ );"
"â€¢ Hierarchical partitioning of model weights (â„ğ‘ğ‘ ) completely","4"
"eliminates inter-node all-gather communication in backward","ğ‘ğ‘™ğ‘™_ğ‘”ğ‘ğ‘¡â„ğ‘’ğ‘Ÿ _ğ‘ƒğ‘ğ‘Ÿğ‘ğ‘šğ‘’ğ‘¡ğ‘’ğ‘Ÿğ‘  (ğ‘¤ğ‘œğ‘Ÿğ‘™ğ‘‘ğ‘†ğ‘–ğ‘§ğ‘’ );
5"
"propagation.","ğ‘šğ‘œğ‘‘ğ‘’ğ‘™ .ğ‘ğ‘ğ‘ğ‘˜ğ‘¤ğ‘ğ‘Ÿğ‘‘ ();
6"
"","ğ‘ğ‘ğ‘Ÿğ‘¡ğ‘–ğ‘¡ğ‘–ğ‘œğ‘› (ğ‘¤ğ‘œğ‘Ÿğ‘™ğ‘‘ğ‘†ğ‘–ğ‘§ğ‘’ );"
"â€¢ Novel, all-to-all quantized gradient reduction collective (ğ‘ğ‘”ğ‘ )","7"
"reduces gradient communication by 75% comparing with","ğ‘Ÿğ‘’ğ‘‘ğ‘¢ğ‘ğ‘’_ğ‘ ğ‘ğ‘ğ‘¡ğ‘¡ğ‘’ğ‘Ÿ _ğºğ‘Ÿğ‘ğ‘‘ğ‘–ğ‘’ğ‘›ğ‘¡ğ‘  (ğ‘¤ğ‘œğ‘Ÿğ‘™ğ‘‘ğ‘†ğ‘–ğ‘§ğ‘’ );
8"
"reduce-scatter.","ğ‘œğ‘ğ‘¡ğ‘–ğ‘šğ‘–ğ‘§ğ‘’ğ‘Ÿ .ğ‘ ğ‘¡ğ‘’ğ‘ ();
9"
"â€¢ Optimized Integration of each of the above techniques into","10
end while"
"existing ZeRO implementation, that enables communication","11 Return: ğ‘šğ‘œğ‘‘ğ‘’ğ‘™"
"and computation overlapping, and leverages custom high",""
"performance CUDA kernels for quantization, dequantiza-",""
"tion, as well as operator fusion (section 4). Our implementa-",""
"","2.2
ZeRO Optimizer"
"tion translates the 4x communication volume reduction of",""
"","ZeRO is a memory-optimized solution for data parallel training."
"ZeRO++ into real throughput improvement.",""
"","ZeRO partitions and distributes all model states (i.e., parameters,"
"â€¢ Extensive experiments shows that i) over 45% of sustained",""
"","gradients, optimizer states) among GPUs in use and recollects model"
"peak throughput even at small batch sizes, ii) up to 2.4x end-",""
"","states only when the layer needs to be computed. There are three"
"to-end system improvement over ZeRO, and iii) achieving",""
"","different stages for using ZeRO to optimize on-device memory"
"similar throughput in low-bandwidth cluster compared to",""
"","usage. In ZeRO stage 1 (ZeRO-1), only optimizer states are split and"
"baseline in high-bandwidth cluster. In addition, we present",""
"","spread across all GPUs in use. ZeRO stage 2 (ZeRO-2) partitions"
"performance breakdown and analysis of diffrent components",""
"","both optimizer states and gradients, where ZeRO stage 3 (ZeRO-3)"
"of ZeRO++.Our end-to-end training shows that ZeRO++ does",""
"","splits all three components of model states as parameters, gradients,"
"not affect model convergence.",""
"","and optimizer states."
"â€¢ ZeRO++ is open-sourced and released as part of https://",""
"","ZeRO-3 is the most memory efficient solution for model training"
"github.com/microsoft/DeepSpeed",""
"","at large scale, but at the cost of more collective communications. Al-"
"","gorithm 1 illustrates the high-level pseudocode for ZeRO-3. During"
"2
BACKGROUND AND RELATED WORK",""
"","model training, ZeRO-3 lazy-schedules the fetching of parameters"
"2.1
Data, Model and 3D parallelism","until the computation needs to happen on a particular layer. Before"
"Data parallelism (DP), pipeline parallelism (PP), and tensor paral-","forward propagation, ZeRO launches an all-gather to collect the"
