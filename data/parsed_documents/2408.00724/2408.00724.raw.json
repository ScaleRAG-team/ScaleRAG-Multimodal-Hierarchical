{
  "title": null,
  "authors": [],
  "source_path": "../data/pdf/2408.00724.pdf",
  "page_count": 22,
  "processed_pages": [
    1,
    2,
    3,
    4,
    5,
    6,
    7,
    8,
    9,
    10,
    11,
    12,
    13,
    14,
    15,
    16,
    17,
    18,
    19,
    20,
    21,
    22
  ],
  "counts": {
    "texts": 647,
    "pictures": 4,
    "tables": 30
  },
  "stats_per_page": [
    {
      "page": 1,
      "text_blocks": 35,
      "layout_blocks": 1,
      "xobjects_found": 1,
      "xobjects_exported": 1,
      "reused_exported": 0,
      "rasterized": 1,
      "tables_found": 3
    },
    {
      "page": 2,
      "text_blocks": 10,
      "layout_blocks": 0,
      "xobjects_found": 0,
      "xobjects_exported": 0,
      "reused_exported": 0,
      "rasterized": 0,
      "tables_found": 1
    },
    {
      "page": 3,
      "text_blocks": 11,
      "layout_blocks": 0,
      "xobjects_found": 0,
      "xobjects_exported": 0,
      "reused_exported": 0,
      "rasterized": 0,
      "tables_found": 1
    },
    {
      "page": 4,
      "text_blocks": 14,
      "layout_blocks": 1,
      "xobjects_found": 0,
      "xobjects_exported": 0,
      "reused_exported": 0,
      "rasterized": 1,
      "tables_found": 1
    },
    {
      "page": 5,
      "text_blocks": 53,
      "layout_blocks": 0,
      "xobjects_found": 0,
      "xobjects_exported": 0,
      "reused_exported": 0,
      "rasterized": 0,
      "tables_found": 1
    },
    {
      "page": 6,
      "text_blocks": 10,
      "layout_blocks": 2,
      "xobjects_found": 0,
      "xobjects_exported": 0,
      "reused_exported": 0,
      "rasterized": 2,
      "tables_found": 1
    },
    {
      "page": 7,
      "text_blocks": 36,
      "layout_blocks": 0,
      "xobjects_found": 0,
      "xobjects_exported": 0,
      "reused_exported": 0,
      "rasterized": 0,
      "tables_found": 1
    },
    {
      "page": 8,
      "text_blocks": 30,
      "layout_blocks": 0,
      "xobjects_found": 0,
      "xobjects_exported": 0,
      "reused_exported": 0,
      "rasterized": 0,
      "tables_found": 2
    },
    {
      "page": 9,
      "text_blocks": 107,
      "layout_blocks": 0,
      "xobjects_found": 0,
      "xobjects_exported": 0,
      "reused_exported": 0,
      "rasterized": 0,
      "tables_found": 3
    },
    {
      "page": 10,
      "text_blocks": 15,
      "layout_blocks": 0,
      "xobjects_found": 0,
      "xobjects_exported": 0,
      "reused_exported": 0,
      "rasterized": 0,
      "tables_found": 1
    },
    {
      "page": 11,
      "text_blocks": 18,
      "layout_blocks": 0,
      "xobjects_found": 0,
      "xobjects_exported": 0,
      "reused_exported": 0,
      "rasterized": 0,
      "tables_found": 1
    },
    {
      "page": 12,
      "text_blocks": 16,
      "layout_blocks": 0,
      "xobjects_found": 0,
      "xobjects_exported": 0,
      "reused_exported": 0,
      "rasterized": 0,
      "tables_found": 1
    },
    {
      "page": 13,
      "text_blocks": 17,
      "layout_blocks": 0,
      "xobjects_found": 0,
      "xobjects_exported": 0,
      "reused_exported": 0,
      "rasterized": 0,
      "tables_found": 1
    },
    {
      "page": 14,
      "text_blocks": 15,
      "layout_blocks": 0,
      "xobjects_found": 0,
      "xobjects_exported": 0,
      "reused_exported": 0,
      "rasterized": 0,
      "tables_found": 1
    },
    {
      "page": 15,
      "text_blocks": 3,
      "layout_blocks": 0,
      "xobjects_found": 0,
      "xobjects_exported": 0,
      "reused_exported": 0,
      "rasterized": 0,
      "tables_found": 1
    },
    {
      "page": 16,
      "text_blocks": 33,
      "layout_blocks": 0,
      "xobjects_found": 0,
      "xobjects_exported": 0,
      "reused_exported": 0,
      "rasterized": 0,
      "tables_found": 1
    },
    {
      "page": 17,
      "text_blocks": 23,
      "layout_blocks": 0,
      "xobjects_found": 0,
      "xobjects_exported": 0,
      "reused_exported": 0,
      "rasterized": 0,
      "tables_found": 1
    },
    {
      "page": 18,
      "text_blocks": 15,
      "layout_blocks": 0,
      "xobjects_found": 0,
      "xobjects_exported": 0,
      "reused_exported": 0,
      "rasterized": 0,
      "tables_found": 1
    },
    {
      "page": 19,
      "text_blocks": 8,
      "layout_blocks": 0,
      "xobjects_found": 0,
      "xobjects_exported": 0,
      "reused_exported": 0,
      "rasterized": 0,
      "tables_found": 1
    },
    {
      "page": 20,
      "text_blocks": 72,
      "layout_blocks": 0,
      "xobjects_found": 0,
      "xobjects_exported": 0,
      "reused_exported": 0,
      "rasterized": 0,
      "tables_found": 2
    },
    {
      "page": 21,
      "text_blocks": 73,
      "layout_blocks": 0,
      "xobjects_found": 0,
      "xobjects_exported": 0,
      "reused_exported": 0,
      "rasterized": 0,
      "tables_found": 2
    },
    {
      "page": 22,
      "text_blocks": 33,
      "layout_blocks": 0,
      "xobjects_found": 0,
      "xobjects_exported": 0,
      "reused_exported": 0,
      "rasterized": 0,
      "tables_found": 2
    }
  ],
  "texts": [
    {
      "page_no": 1,
      "bbox": [
        108.0,
        27.81348991394043,
        293.0951843261719,
        37.77608871459961
      ],
      "text": "Published as a conference paper at ICLR 2025"
    },
    {
      "page_no": 1,
      "bbox": [
        108.42996215820312,
        80.49504852294922,
        478.004150390625,
        137.56146240234375
      ],
      "text": "INFERENCE SCALING LAWS:\nAN EMPIRICAL ANALYSIS OF COMPUTE-OPTIMAL\nINFERENCE FOR LLM PROBLEM-SOLVING"
    },
    {
      "page_no": 1,
      "bbox": [
        113.97796630859375,
        155.34439086914062,
        424.09698486328125,
        166.81715393066406
      ],
      "text": "Yangzhen Wu1∗, Zhiqing Sun2, Shanda Li2, Sean Welleck2, Yiming Yang2"
    },
    {
      "page_no": 1,
      "bbox": [
        113.97789001464844,
        166.83277893066406,
        407.2029113769531,
        222.06895446777344
      ],
      "text": "1Institute for Interdisciplinary Information Sciences, Tsinghua University\n2School of Computer Science, Carnegie Mellon University\nwuyangch21@mails.tsinghua.edu.cn\n{zhiqings, shandal, swelleck, yiming}@cs.cmu.edu\nhttps://thu-wyz.github.io/inference-scaling/"
    },
    {
      "page_no": 1,
      "bbox": [
        278.28790283203125,
        252.3522491455078,
        333.7220458984375,
        264.3074645996094
      ],
      "text": "ABSTRACT"
    },
    {
      "page_no": 1,
      "bbox": [
        143.86590576171875,
        273.0414123535156,
        468.13861083984375,
        458.3458557128906
      ],
      "text": "While the scaling laws of large language models (LLMs) training have been exten-\nsively studied, optimal inference configurations of LLMs remain underexplored.\nWe study inference scaling laws (aka test-time scaling laws) and compute-optimal\ninference, focusing on the trade-offs between model sizes and generating ad-\nditional tokens with different inference strategies. As a first step towards un-\nderstanding and designing compute-optimal inference methods, we studied cost-\nperformance trade-offs for inference strategies such as greedy search, majority\nvoting, best-of-n, weighted voting, and two different tree search algorithms, us-\ning different model sizes and compute budgets. Our findings suggest that scal-\ning inference compute with inference strategies can be more computationally ef-\nficient than scaling model parameters. Additionally, smaller models combined\nwith advanced inference algorithms offer Pareto-optimal trade-offs in cost and\nperformance. For example, the Llemma-7B model, when paired with our novel\ntree search algorithm, consistently outperforms the Llemma-34B model across all\ntested inference strategies on the MATH benchmark. We hope these insights con-\ntribute to a deeper understanding of inference scaling laws (test-time scaling laws)\nfor LLMs."
    },
    {
      "page_no": 1,
      "bbox": [
        144.0455322265625,
        587.5936279296875,
        283.18487548828125,
        608.6704711914062
      ],
      "text": "2\n8\n32\n128\n512\n2048\nInference FLOPs per question (×1011)"
    },
    {
      "page_no": 1,
      "bbox": [
        131.50564575195312,
        557.6630249023438,
        139.9622802734375,
        568.9385375976562
      ],
      "text": "30"
    },
    {
      "page_no": 1,
      "bbox": [
        131.50564575195312,
        534.6411743164062,
        139.9622802734375,
        545.9166870117188
      ],
      "text": "40"
    },
    {
      "page_no": 1,
      "bbox": [
        131.50564575195312,
        516.7839965820312,
        139.9622802734375,
        528.0595092773438
      ],
      "text": "50"
    },
    {
      "page_no": 1,
      "bbox": [
        131.50564575195312,
        502.1935729980469,
        139.9622802734375,
        513.4691162109375
      ],
      "text": "60"
    },
    {
      "page_no": 1,
      "bbox": [
        131.50564575195312,
        489.85760498046875,
        139.9622802734375,
        501.13311767578125
      ],
      "text": "70"
    },
    {
      "page_no": 1,
      "bbox": [
        119.38496398925781,
        498.973876953125,
        131.91331481933594,
        573.9918823242188
      ],
      "text": "Test error on GSM8K"
    },
    {
      "page_no": 1,
      "bbox": [
        132.72772216796875,
        472.6091003417969,
        284.8062438964844,
        486.3902893066406
      ],
      "text": "Inference scaling (Weighted Majority)"
    },
    {
      "page_no": 1,
      "bbox": [
        263.0759582519531,
        487.3662109375,
        279.4514465332031,
        532.084716796875
      ],
      "text": "410M\n1.4B\n2.8B\n6.9B\n12B"
    },
    {
      "page_no": 1,
      "bbox": [
        328.1734619140625,
        589.6895751953125,
        446.56573486328125,
        609.7891845703125
      ],
      "text": "0.5\n1\n2\n4\n8\n16\nModel size (B)"
    },
    {
      "page_no": 1,
      "bbox": [
        304.1974182128906,
        559.2476806640625,
        312.6559143066406,
        570.5256958007812
      ],
      "text": "30"
    },
    {
      "page_no": 1,
      "bbox": [
        304.1974182128906,
        535.7525024414062,
        312.6559143066406,
        547.030517578125
      ],
      "text": "40"
    },
    {
      "page_no": 1,
      "bbox": [
        304.1974182128906,
        517.5282592773438,
        312.6559143066406,
        528.8062744140625
      ],
      "text": "50"
    },
    {
      "page_no": 1,
      "bbox": [
        304.1974182128906,
        502.6380310058594,
        312.6559143066406,
        513.916015625
      ],
      "text": "60"
    },
    {
      "page_no": 1,
      "bbox": [
        304.1974182128906,
        490.0484619140625,
        312.6559143066406,
        501.326416015625
      ],
      "text": "70"
    },
    {
      "page_no": 1,
      "bbox": [
        292.0741271972656,
        500.00006103515625,
        304.6051940917969,
        575.0343017578125
      ],
      "text": "Test error on GSM8K"
    },
    {
      "page_no": 1,
      "bbox": [
        306.2522277832031,
        472.5788879394531,
        458.3636779785156,
        486.363037109375
      ],
      "text": "Inference scaling (Weighted Majority)"
    },
    {
      "page_no": 1,
      "bbox": [
        465.58770751953125,
        574.2816162109375,
        478.7453308105469,
        584.3064575195312
      ],
      "text": "11.5"
    },
    {
      "page_no": 1,
      "bbox": [
        465.58770751953125,
        559.7760620117188,
        478.7453308105469,
        569.8009033203125
      ],
      "text": "12.0"
    },
    {
      "page_no": 1,
      "bbox": [
        465.58770751953125,
        545.2705078125,
        478.7453308105469,
        555.2953491210938
      ],
      "text": "12.5"
    },
    {
      "page_no": 1,
      "bbox": [
        465.58770751953125,
        530.764892578125,
        478.7453308105469,
        540.7897338867188
      ],
      "text": "13.0"
    },
    {
      "page_no": 1,
      "bbox": [
        465.58770751953125,
        516.2593383789062,
        478.7453308105469,
        526.2841796875
      ],
      "text": "13.5"
    },
    {
      "page_no": 1,
      "bbox": [
        465.58770751953125,
        501.7537536621094,
        478.7453308105469,
        511.7785949707031
      ],
      "text": "14.0"
    },
    {
      "page_no": 1,
      "bbox": [
        465.58770751953125,
        487.2481994628906,
        478.7453308105469,
        497.2730407714844
      ],
      "text": "14.5"
    },
    {
      "page_no": 1,
      "bbox": [
        476.7442321777344,
        517.957763671875,
        489.2752990722656,
        557.085205078125
      ],
      "text": "log(FLOPs)"
    },
    {
      "page_no": 1,
      "bbox": [
        108.0,
        622.12353515625,
        504.004638671875,
        686.9720458984375
      ],
      "text": "Figure 1: Inference scaling laws exhibited for Pythia (Biderman et al., 2023) models and GSM8K\ntest error. We evaluate the error rate (lower is better) of models using various sizes and numbers of\nsampled solutions for weighted majority voting. Left: the error rate for each model size decreases\nsteadily as inference-compute increases, and converges at the end. Right: the optimal model size\n(shown as stars for 241, 244, and 247 FLOPs) varies based on the inference-time compute budget.\nFor instance, smaller models are compute-optimal at 241 and 244 FLOPs. Both axes are log scale."
    },
    {
      "page_no": 1,
      "bbox": [
        119.8219985961914,
        721.3038330078125,
        331.12835693359375,
        732.0283813476562
      ],
      "text": "∗Work done during the visit at Carnegie Mellon University"
    },
    {
      "page_no": 1,
      "bbox": [
        303.5090026855469,
        752.1944580078125,
        308.49029541015625,
        762.1570434570312
      ],
      "text": "1"
    },
    {
      "page_no": 1,
      "bbox": [
        10.940000534057617,
        219.5,
        37.619998931884766,
        555.0
      ],
      "text": "arXiv:2408.00724v3  [cs.AI]  3 Mar 2025"
    },
    {
      "page_no": 2,
      "bbox": [
        108.0,
        27.81348991394043,
        293.0951843261719,
        37.77608871459961
      ],
      "text": "Published as a conference paper at ICLR 2025"
    },
    {
      "page_no": 2,
      "bbox": [
        108.29900360107422,
        82.75727844238281,
        205.98883056640625,
        94.71247863769531
      ],
      "text": "1\nINTRODUCTION"
    },
    {
      "page_no": 2,
      "bbox": [
        108.0,
        104.10743713378906,
        504.0033264160156,
        179.82394409179688
      ],
      "text": "Scaling laws of neural networks (Hestness et al., 2017; Rosenfeld et al., 2020) have been established\nacross a range of domains, including language modeling (Kaplan et al., 2020; Hoffmann et al., 2022;\nOpenAI, 2023), image modeling (Henighan et al., 2020; Yu et al., 2022; Peebles & Xie, 2023),\nvideo modeling (Brooks et al., 2024), reward modeling (Gao et al., 2023), and board games (Jones,\n2021). These studies have demonstrated how model performance is influenced by both the size of\nthe model and the amount of training compute. However, there is limited knowledge on how varying\nthe compute during inference affects model performance after the model has been trained."
    },
    {
      "page_no": 2,
      "bbox": [
        107.99996948242188,
        189.99134826660156,
        504.0046691894531,
        298.5838317871094
      ],
      "text": "To improve the task performance of large language models (LLMs), inference techniques typically\ninvolve additional compute as a performance maximization step at inference time (Nye et al., 2021;\nWei et al., 2022; Wang et al., 2023b; Yao et al., 2023; Chen et al., 2024b). The computational cost\nof these techniques must be taken into account for compute-optimal inference. For example, Monte\nCarlo Tree Search (MCTS) may improve task performance, but it potentially requires much more\ncompute than simply sampling solutions multiple times (Jones, 2021). Generally speaking, we need\na comprehensive understanding of how various inference-time methods (e.g., best-of-n, majority\nvoting (Wang et al., 2023a; Li et al., 2023)) trade off between performance and cost. To improve\nour understanding, this paper presents a thorough empirical evaluation with careful analysis over\nvarious configurations of representative LLMs and inference algorithms."
    },
    {
      "page_no": 2,
      "bbox": [
        107.99996948242188,
        308.7502136230469,
        504.0033264160156,
        417.3437194824219
      ],
      "text": "Specifically, we explore how to select an optimal size for the language model and an effective in-\nference strategy (e.g., greedy search, majority voting, best-of-n, weighted voting, and their tree-\nsearch variants) to maximize performance (i.e., accuracy) with a given compute budget. We control\nthe inference compute (FLOPs) of a fixed model by generating more tokens through the language\nmodel1, sampling further candidate solutions, and ranking them with a reward model. We analyze\nthe performance of fine-tuned models of various sizes given different inference FLOPs on mathe-\nmatical reasoning benchmarks (e.g., GSM8K test set (Cobbe et al., 2021) and MATH500 test set\n(Hendrycks et al., 2021b; Lightman et al., 2024)). Our experiments cover several model families,\nincluding general-purpose LLMs (e.g., Pythia (Biderman et al., 2023) & Mistral (Jiang et al., 2023))\nas well as math-specialized ones (e.g., Llemma (Azerbayev et al., 2024))."
    },
    {
      "page_no": 2,
      "bbox": [
        107.9999771118164,
        427.5101013183594,
        504.0033264160156,
        536.1026000976562
      ],
      "text": "Our results on Pythia (Fig. 1) illustrate how performance scales with increased inference compute\nacross various model sizes. Typically, increasing the compute budget leads to higher accuracy until\nthe accuracy reaches saturation. As the compute budget increases, smaller models initially perform\nbetter than larger ones, but once the accuracy of the smaller models saturates, the larger models have\nfavorable performance. The right panel of Figure 1 demonstrates that the optimal model size for\ninference varies with different levels of computational budgets. However, in real-world deployment,\nthe available compute is typically much lower than the point where the accuracy of relatively small\nmodels saturates and larger models begin to show their advantage (as shown in Fig. 4, where the 7B\nmodel outperforms the 34B model until 128 Llemma 7B solutions are sampled). This indicates that\nrelatively smaller models could be more compute-optimal for inference."
    },
    {
      "page_no": 2,
      "bbox": [
        107.9999771118164,
        546.27001953125,
        504.0033264160156,
        621.9866333007812
      ],
      "text": "We analyze the asymptotic behavior of sampling and voting-based inference strategies, showing\ntheir convergence upper bound and rate of convergence. Given a dataset, the accuracy of the lan-\nguage model will ultimately saturate to a fixed limit which is determined by the output probabilities\nassigned by the model, exhibiting exponential convergence speed through sampling and voting. This\nimplies that, without an oracle verifier, simple strategies like sampling cannot achieve perfect ac-\ncuracy even with an infinite number of samples, leading to diminishing returns. Therefore, this\nhighlights the necessity for more sophisticated inference algorithms."
    },
    {
      "page_no": 2,
      "bbox": [
        107.9999771118164,
        632.1530151367188,
        504.0037841796875,
        696.9105834960938
      ],
      "text": "We have also found that the commonly-used MCTS method does not perform well with weighted\nvoting, as it often yields many unfinished solutions, hence having less effective votes. To address this\nissue, we propose a novel tree search algorithm, REward BAlanced SEarch (REBASE), which pairs\nwell with weighted voting and achieves a Pareto-optimal trade-off between accuracy and inference\ncompute. The key idea of REBASE is to use a node-quality reward to control node expansion, which\neliminates the need for explicit rollouts while ensuring enough candidate solutions for voting."
    },
    {
      "page_no": 2,
      "bbox": [
        108.00003051757812,
        711.556640625,
        504.0006103515625,
        732.0283813476562
      ],
      "text": "1Following Uesato et al. (2022), we refer to the main language model generating outputs as the policy model.\nIt can be paired with a reward model, which scores outputs from the policy model to facilitate inference."
    },
    {
      "page_no": 2,
      "bbox": [
        303.509033203125,
        752.1944580078125,
        308.4903259277344,
        762.1570434570312
      ],
      "text": "2"
    },
    {
      "page_no": 3,
      "bbox": [
        108.0,
        27.81348991394043,
        293.0951843261719,
        37.77608871459961
      ],
      "text": "Published as a conference paper at ICLR 2025"
    },
    {
      "page_no": 3,
      "bbox": [
        108.0,
        84.26844787597656,
        504.0032958984375,
        170.94393920898438
      ],
      "text": "In our experiments, REBASE consistently outperforms sampling and MCTS methods across all set-\ntings, models, and tasks. Importantly, we find that REBASE with a smaller language model typi-\ncally achieves a Pareto-optimal trade-off. For instance, we show that the Llemma-7B model can\nachieve competitive accuracy to a Llemma-34B model while using 2× less FLOPs when evaluat-\ning on MATH500 (Fig. 4) or GSM8K (Fig. 5). Moreover, Llemma-7B with REBASE outperforms\nLlemma-34B with standard majority voting across all compute budgets. Our results show the value\nof using smaller models with advanced inference-time algorithms, and the benefits of new algo-\nrithms for achieving better returns on inference-time compute."
    },
    {
      "page_no": 3,
      "bbox": [
        108.00001525878906,
        178.06336975097656,
        289.89715576171875,
        188.02597045898438
      ],
      "text": "Our contributions are summarized as follows:"
    },
    {
      "page_no": 3,
      "bbox": [
        135.3970184326172,
        195.14637756347656,
        504.00396728515625,
        237.98593139648438
      ],
      "text": "• We explore new inference scaling laws and compute-optimal inference by evaluating the\nperformance of various model sizes under a fixed inference strategy. We show that smaller\nmodels can outperform larger ones under the same compute budget by increasing the num-\nber of samples."
    },
    {
      "page_no": 3,
      "bbox": [
        135.3970184326172,
        245.10536193847656,
        504.00390625,
        276.9859313964844
      ],
      "text": "• We provide new theoretical analysis of the scaling behavior of voting methods, presenting\nconvergence bounds and rates. Our analysis shows performance limits and diminishing\nreturns from sampling, pointing to the need for more sophisticated inference algorithms."
    },
    {
      "page_no": 3,
      "bbox": [
        135.3970184326172,
        284.1053161621094,
        504.0040283203125,
        326.9449157714844
      ],
      "text": "• We formulate a new compute-optimal inference problem and propose a novel tree search\nalgorithm, REBASE, which is compute-optimal compared to widely-used sampling and\nMCTS methods. Our results show benefits of using smaller models with advanced infer-\nence algorithms, and new algorithms for achieving better cost-performance tradeoffs."
    },
    {
      "page_no": 3,
      "bbox": [
        108.29901123046875,
        338.5491638183594,
        217.0968475341797,
        350.5043640136719
      ],
      "text": "2\nRELATED WORKS"
    },
    {
      "page_no": 3,
      "bbox": [
        108.0,
        357.7523498535156,
        504.00347900390625,
        488.3537902832031
      ],
      "text": "Scaling laws.\nRecent research on scaling laws has established that model performance follows\npredictable power-law relationships with respect to the number of parameters, the size of the train-\ning dataset, and the available compute (Hestness et al., 2017; Rosenfeld et al., 2020). The seminal\nwork by Kaplan et al. (2020) demonstrates that the test loss of language models decays as a function\nof model size and data in a highly regular manner. Subsequent studies refine these initial observa-\ntions and extend them into more diverse settings (Hoffmann et al., 2022; Alabdulmohsin et al., 2022;\nMuennighoff et al., 2023; Lin et al., 2024; Goyal et al., 2024b). However, most of these existing\nworks are primarily focused on the training regime. Sardana et al. (2024) study scaling laws taking\nboth training and inference into account, but only a fixed inference algorithm is considered. In com-\nparison, our work systematically demonstrate inference scaling laws, i.e., LLM problem-solving\nperformance improves with increased inference-time compute budget, and we propose and study\ncompute-optimal inference."
    },
    {
      "page_no": 3,
      "bbox": [
        108.0,
        496.1482238769531,
        504.0033874511719,
        692.5027465820312
      ],
      "text": "Inference strategies and inference-time compute utilization in LLM problem-solving.\nA vari-\nety of inference strategies have been developed to generate sequences with a trained model (Welleck\net al., 2024). Deterministic methods such as greedy decoding and beam search (Teller, 2000; Graves,\n2012) find highly probable sequences which typically have decent quality but lacks diversity. Sam-\npling algorithms (e.g., temperature sampling (Ackley et al., 1985)) can produce a diverse set of\nresults which are then aggregated to achieve higher accuracy (e.g., via the self-consistency ap-\nproach (Wang et al., 2023a)). Recent methods combine search algorithms with LLMs, including\nbreadth-first or depth-first search (Yao et al., 2023), Monte-Carlo Tree Search (MCTS) (Zhang\net al., 2023; Zhou et al., 2024; Liu et al., 2024; Choi et al., 2023), and guided beam search (Xie\net al., 2023). Several prior studies also find that LLM problem-solving performance can be im-\nproved by outputting “dummy” tokens at inference time (Goyal et al., 2024a; Pfau et al., 2024). All\nof these methods show that using search at inference time can lead to performance gains at the cost\nof increased inference-time compute, but they do not characterize the cost-performance trade-off\nsystematically. We are the first to formulate and study compute-optimal inference, analyzing the\ntrade-off between compute budget and problem-solving performance and proposing the REBASE\nmethod that is empirically Pareto-optimal. Concurrently, Snell et al. (2025) also study how to scale\ninference-compute optimally and provide complementary insights, since we consider more model\nfamilies and sizes while they study several different inference strategies."
    },
    {
      "page_no": 3,
      "bbox": [
        108.0,
        700.2972412109375,
        504.0032958984375,
        732.268798828125
      ],
      "text": "Mathematical Reasoning with LLMs.\nLarge language models have made significant progress\nin recent years, and have exhibited strong reasoning abilities (Brown et al., 2020; Hoffmann et al.,\n2022; Lewkowycz et al., 2022; Chowdhery et al., 2023). Mathematical problem solving is a key"
    },
    {
      "page_no": 3,
      "bbox": [
        303.5090026855469,
        752.1942138671875,
        308.49029541015625,
        762.1567993164062
      ],
      "text": "3"
    },
    {
      "page_no": 4,
      "bbox": [
        108.0,
        27.81348991394043,
        293.0951843261719,
        37.77608871459961
      ],
      "text": "Published as a conference paper at ICLR 2025"
    },
    {
      "page_no": 4,
      "bbox": [
        108.0,
        257.71954345703125,
        504.00323486328125,
        300.6500549316406
      ],
      "text": "Figure 2: Illustration of compute-optimal scaling laws in training and inference. The Chinchilla\nscaling law (Hoffmann et al., 2022) shows how to choose a model size and number of training tokens\nunder a training-compute budget, while our work shows how to choose a model size and an inference\nstrategy under an inference-compute budget."
    },
    {
      "page_no": 4,
      "bbox": [
        108.0,
        325.2434387207031,
        504.0033264160156,
        400.9590148925781
      ],
      "text": "task for measuring LLM reasoning abilities (Cobbe et al., 2021; Hendrycks et al., 2021b). Ling\net al. (2017) first developed the method of producing step by step solutions that lead to the final\nanswer. Later, Cobbe et al. (2021) extended the work by training a verifier for evaluating and ranking\nsolutions. Subsequent research has shown the performance benefits of inference-time techniques\nsuch as majority voting and weighted majority voting (Lewkowycz et al., 2022; Li et al., 2023).\nWe choose problem solving in mathematics as the task to study compute-optimal strategies since it\nallows us to accurately evaluate problem solving ability."
    },
    {
      "page_no": 4,
      "bbox": [
        108.29900360107422,
        413.9532470703125,
        419.96942138671875,
        425.908447265625
      ],
      "text": "3\nCOMPUTE-OPTIMAL INFERENCE FOR PROBLEM-SOLVING"
    },
    {
      "page_no": 4,
      "bbox": [
        108.00003051757812,
        433.9029235839844,
        504.0034484863281,
        476.9189758300781
      ],
      "text": "We explore the following question: Given a fixed FLOPs budget, how should one select an optimal\nmodel size for the policy model, and an effective inference strategy to maximize performance (i.e.,\naccuracy)? We are the first to formulate this problem and study the associated inference-time scaling\nlaws, setting our work apart from previous scaling law studies (Fig. 2)."
    },
    {
      "page_no": 4,
      "bbox": [
        107.99996948242188,
        484.9136962890625,
        504.0010986328125,
        528.1119384765625
      ],
      "text": "To address this, we represent the problem-solving error rate E(N, T; S) as a function of the number\nof model parameters N, the number of generated tokens T and the inference strategy S. The com-\nputational budget C is a deterministic function FLOPs(N, T; S), based on N and T. Our goal is to\nminimize E under the test-time compute constraint FLOPs(N, T, S) = C:"
    },
    {
      "page_no": 4,
      "bbox": [
        177.89198303222656,
        537.1036987304688,
        434.10943603515625,
        555.5318603515625
      ],
      "text": "(Nopt(C), Topt(C); S) =\narg min\n(N,T,S) s.t. FLOPs(N,T,S)=C\nE(N, T; S)"
    },
    {
      "page_no": 4,
      "bbox": [
        107.99996948242188,
        565.622802734375,
        461.0106201171875,
        576.4264526367188
      ],
      "text": "where Nopt(C) and Topt(C) denote the optimal allocation of a computational budget C."
    },
    {
      "page_no": 4,
      "bbox": [
        107.99996948242188,
        584.1703491210938,
        504.0032043457031,
        637.9689331054688
      ],
      "text": "Here, the inference compute (FLOPs) for a fixed model can be modulated by generating more tokens\nwith the policy model and an inference strategy, e.g., sampling additional candidate solutions and\nsubsequently ranking them using a reward model. As the inference strategies, we primarily consider\nsampling and tree-search approaches paired with re-ranking or majority voting. This includes greedy\nsearch, majority voting, best-of-n, weighted voting, and their tree-search variants."
    },
    {
      "page_no": 4,
      "bbox": [
        108.24896240234375,
        648.5873413085938,
        236.0467529296875,
        658.5499267578125
      ],
      "text": "3.1\nINFERENCE STRATEGIES"
    },
    {
      "page_no": 4,
      "bbox": [
        107.99996185302734,
        663.7543334960938,
        442.4045104980469,
        673.7169189453125
      ],
      "text": "We consider the following inference strategies which are popularly used in practice:"
    },
    {
      "page_no": 4,
      "bbox": [
        119.45696258544922,
        681.9804077148438,
        503.9955139160156,
        702.992919921875
      ],
      "text": "• Greedy search. This strategy generates tokens one at a time by selecting the highest probability\ntoken at each step. It is computationally efficient but often suboptimal in terms of diversity."
    },
    {
      "page_no": 4,
      "bbox": [
        119.45696258544922,
        711.1168212890625,
        503.9952697753906,
        732.2689208984375
      ],
      "text": "• best-of-n. This strategy, also known as rejection sampling, generates a set of candidates and\nchooses the one with the highest score given by the reward model."
    },
    {
      "page_no": 4,
      "bbox": [
        303.50897216796875,
        752.1943359375,
        308.4902648925781,
        762.1569213867188
      ],
      "text": "4"
    },
    {
      "page_no": 5,
      "bbox": [
        108.0,
        27.81348991394043,
        293.0951843261719,
        37.77608871459961
      ],
      "text": "Published as a conference paper at ICLR 2025"
    },
    {
      "page_no": 5,
      "bbox": [
        119.45700073242188,
        84.17748260498047,
        503.99639892578125,
        105.19003295898438
      ],
      "text": "• Majority voting. In this strategy, a set of candidates are generated, and the final answer to the\nproblem is determined by the most frequently occurring answer in all the outputs."
    },
    {
      "page_no": 5,
      "bbox": [
        119.45700073242188,
        112.07347869873047,
        504.00433349609375,
        133.08602905273438
      ],
      "text": "• Weighted majority voting. This strategy is a variant of majority voting in which the candidates\nare weighted based on the scores given by the reward model."
    },
    {
      "page_no": 5,
      "bbox": [
        108.0,
        139.96844482421875,
        504.00323486328125,
        182.89895629882812
      ],
      "text": "We say a strategy is sampling-based if it uses a standard autoregressive sampling algorithm (e.g.,\ntemperature sampling) to generate the candidate set (greedy search is separate, in that it only has a\nsingle deterministic candidate). A tree-search variant uses a tree search to generate the candidate\nset. Before discussing tree-search methods, we analyze sampling-based voting below."
    },
    {
      "page_no": 5,
      "bbox": [
        108.00001525878906,
        190.0714111328125,
        504.00335693359375,
        254.91891479492188
      ],
      "text": "Theoretical analysis of sampling-based voting.\nWe present theoretical results on the asymptotic\nbehavior of voting-based strategies given infinite compute in Theorems 1 & 2. Informally, we show\nthat the accuracy of standard/weighted majority voting converges with infinite samples, and the\nlimit only depends on the distribution modeled by the language model (and the reward model).\nThis theoretical finding is also aligned with our empirical findings shown in Sec. 4.2, which show\nsaturation at high sampling budgets. The proofs are presented in Appendix A."
    },
    {
      "page_no": 5,
      "bbox": [
        108.00001525878906,
        260.5822448730469,
        504.0048522949219,
        337.8988342285156
      ],
      "text": "Notations and assumptions.\nLet V be a finite vocabulary and V∗its Kleene closure, i.e., the set\nof all strings. Given a problem x, we say a language model answers y to this problem if the model\noutputs rey where r ∈V∗can be any “reasoning path” and e ∈V denotes a special token that marks\nthe end of reasoning. We further assume that the answer string is always shorter than L tokens, i.e.,\n|y| ≤L for some fixed L ∈N∗where |y| denotes the length of y. For a language model π, denote\nby π(v|w) the probability of generating v given input (prompt) w. For a reward model ρ, denote by\nρ(v) the score it assigns to the string v. We use I to denote the indicator function."
    },
    {
      "page_no": 5,
      "bbox": [
        108.00003051757812,
        343.3625183105469,
        504.0022277832031,
        377.58740234375
      ],
      "text": "Theorem 1. Consider a dataset D = {(xi, yi)}m\ni=1 where xi and yi denotes input and true answer,\nrespectively. For a language model π, denote by accMV\nn\n(D; π) the accuracy on D using majority\nvoting with n samples. Following the notations and assumptions defined above, we have:"
    },
    {
      "page_no": 5,
      "bbox": [
        150.3310546875,
        385.7497253417969,
        253.9263458251953,
        407.7773742675781
      ],
      "text": "lim\nn→+∞accMV\nn\n(D; π) = 1"
    },
    {
      "page_no": 5,
      "bbox": [
        247.06199645996094,
        399.32391357421875,
        255.8091583251953,
        409.2864990234375
      ],
      "text": "m"
    },
    {
      "page_no": 5,
      "bbox": [
        258.66497802734375,
        382.37274169921875,
        273.0609436035156,
        400.1519470214844
      ],
      "text": "m\nX"
    },
    {
      "page_no": 5,
      "bbox": [
        259.406982421875,
        390.31341552734375,
        278.5914306640625,
        413.5545654296875
      ],
      "text": "i=1\nI"
    },
    {
      "page_no": 5,
      "bbox": [
        280.2509765625,
        382.6173400878906,
        286.0591735839844,
        392.5799255371094
      ],
      "text": "\""
    },
    {
      "page_no": 5,
      "bbox": [
        286.0619812011719,
        392.48992919921875,
        341.75311279296875,
        410.6275634765625
      ],
      "text": "yi = arg max\n|y|≤L"
    },
    {
      "page_no": 5,
      "bbox": [
        345.74298095703125,
        390.1893615722656,
        360.1389465332031,
        400.1519470214844
      ],
      "text": "X"
    },
    {
      "page_no": 5,
      "bbox": [
        343.4119873046875,
        392.3608093261719,
        404.13043212890625,
        413.70556640625
      ],
      "text": "r∈V∗\nπ(rey|xi)"
    },
    {
      "page_no": 5,
      "bbox": [
        404.12896728515625,
        382.6173400878906,
        409.9371643066406,
        392.5799255371094
      ],
      "text": "#"
    },
    {
      "page_no": 5,
      "bbox": [
        411.6009521484375,
        392.54400634765625,
        474.59442138671875,
        402.506591796875
      ],
      "text": "(almost surely);"
    },
    {
      "page_no": 5,
      "bbox": [
        137.40594482421875,
        420.5998840332031,
        253.92623901367188,
        439.1115417480469
      ],
      "text": "and\nE\n\u0002\naccMV\nn\n(D; π)\n\u0003\n= 1"
    },
    {
      "page_no": 5,
      "bbox": [
        247.06199645996094,
        434.1729431152344,
        255.8091583251953,
        444.1355285644531
      ],
      "text": "m"
    },
    {
      "page_no": 5,
      "bbox": [
        258.66497802734375,
        417.2217712402344,
        273.0609436035156,
        435.0009765625
      ],
      "text": "m\nX"
    },
    {
      "page_no": 5,
      "bbox": [
        259.406982421875,
        425.1624450683594,
        278.5914306640625,
        448.4035949707031
      ],
      "text": "i=1\nI"
    },
    {
      "page_no": 5,
      "bbox": [
        280.2509765625,
        417.46636962890625,
        286.0591735839844,
        427.428955078125
      ],
      "text": "\""
    },
    {
      "page_no": 5,
      "bbox": [
        286.0619812011719,
        427.3389587402344,
        341.75311279296875,
        445.4765930175781
      ],
      "text": "yi = arg max\n|y|≤L"
    },
    {
      "page_no": 5,
      "bbox": [
        345.74298095703125,
        425.03839111328125,
        360.1389465332031,
        435.0009765625
      ],
      "text": "X"
    },
    {
      "page_no": 5,
      "bbox": [
        343.4119873046875,
        427.2098388671875,
        404.13043212890625,
        448.5545959472656
      ],
      "text": "r∈V∗\nπ(rey|xi)"
    },
    {
      "page_no": 5,
      "bbox": [
        404.12896728515625,
        417.46636962890625,
        409.9371643066406,
        427.428955078125
      ],
      "text": "#"
    },
    {
      "page_no": 5,
      "bbox": [
        412.15496826171875,
        425.4714050292969,
        454.03643798828125,
        437.3015441894531
      ],
      "text": "−O(c−n)"
    },
    {
      "page_no": 5,
      "bbox": [
        107.99996948242188,
        453.01495361328125,
        206.40061950683594,
        463.0316162109375
      ],
      "text": "for some constant c > 1."
    },
    {
      "page_no": 5,
      "bbox": [
        107.99990844726562,
        468.6717834472656,
        504.0048522949219,
        502.89764404296875
      ],
      "text": "Theorem 2. Consider a dataset D = {(xi, yi)}m\ni=1. For a language model π and a reward model\nρ, denote by accWV\nn\n(D; π, ρ) the accuracy on D using weighted majority voting with n samples.\nFollowing the notations and assumptions defined above, we have:"
    },
    {
      "page_no": 5,
      "bbox": [
        126.9369125366211,
        511.0599365234375,
        240.96820068359375,
        533.0866088867188
      ],
      "text": "lim\nn→+∞accWV\nn\n(D; π, ρ) = 1"
    },
    {
      "page_no": 5,
      "bbox": [
        234.10400390625,
        524.6329345703125,
        242.85116577148438,
        534.5955200195312
      ],
      "text": "m"
    },
    {
      "page_no": 5,
      "bbox": [
        245.70701599121094,
        507.6817626953125,
        260.10296630859375,
        525.4609985351562
      ],
      "text": "m\nX"
    },
    {
      "page_no": 5,
      "bbox": [
        246.45001220703125,
        515.6224365234375,
        265.6334533691406,
        538.8635864257812
      ],
      "text": "i=1\nI"
    },
    {
      "page_no": 5,
      "bbox": [
        267.2929992675781,
        507.9263610839844,
        273.1011962890625,
        517.8889770507812
      ],
      "text": "\""
    },
    {
      "page_no": 5,
      "bbox": [
        273.1050109863281,
        517.7989501953125,
        328.7951354980469,
        535.9365844726562
      ],
      "text": "yi = arg max\n|y|≤L"
    },
    {
      "page_no": 5,
      "bbox": [
        332.78497314453125,
        515.4983520507812,
        347.1809387207031,
        525.4609985351562
      ],
      "text": "X"
    },
    {
      "page_no": 5,
      "bbox": [
        330.4549865722656,
        517.6697998046875,
        427.52447509765625,
        539.0145874023438
      ],
      "text": "r∈V∗\nπ(rey|xi)ρ(xirey)"
    },
    {
      "page_no": 5,
      "bbox": [
        427.52301025390625,
        507.9263610839844,
        433.3312072753906,
        517.8889770507812
      ],
      "text": "#"
    },
    {
      "page_no": 5,
      "bbox": [
        434.9949951171875,
        517.85302734375,
        497.98846435546875,
        527.8156127929688
      ],
      "text": "(almost surely);"
    },
    {
      "page_no": 5,
      "bbox": [
        114.01199340820312,
        545.908935546875,
        240.96827697753906,
        564.4215698242188
      ],
      "text": "and\nE\n\u0002\naccWV\nn\n(D; π, ρ)\n\u0003\n= 1"
    },
    {
      "page_no": 5,
      "bbox": [
        234.10400390625,
        559.48291015625,
        242.85116577148438,
        569.4454956054688
      ],
      "text": "m"
    },
    {
      "page_no": 5,
      "bbox": [
        245.70701599121094,
        542.53076171875,
        260.10296630859375,
        560.3099365234375
      ],
      "text": "m\nX"
    },
    {
      "page_no": 5,
      "bbox": [
        246.45001220703125,
        550.472412109375,
        265.6334533691406,
        573.7125244140625
      ],
      "text": "i=1\nI"
    },
    {
      "page_no": 5,
      "bbox": [
        267.2929992675781,
        542.7753295898438,
        273.1011962890625,
        552.7379760742188
      ],
      "text": "\""
    },
    {
      "page_no": 5,
      "bbox": [
        273.1050109863281,
        552.64892578125,
        328.7951354980469,
        570.7865600585938
      ],
      "text": "yi = arg max\n|y|≤L"
    },
    {
      "page_no": 5,
      "bbox": [
        332.78497314453125,
        550.3472900390625,
        347.1809387207031,
        560.3099365234375
      ],
      "text": "X"
    },
    {
      "page_no": 5,
      "bbox": [
        330.4549865722656,
        552.519775390625,
        427.52447509765625,
        573.863525390625
      ],
      "text": "r∈V∗\nπ(rey|xi)ρ(xirey)"
    },
    {
      "page_no": 5,
      "bbox": [
        427.52301025390625,
        542.7753295898438,
        433.3312072753906,
        552.7379760742188
      ],
      "text": "#"
    },
    {
      "page_no": 5,
      "bbox": [
        435.54901123046875,
        550.7803344726562,
        477.43048095703125,
        562.6115112304688
      ],
      "text": "−O(c−n)"
    },
    {
      "page_no": 5,
      "bbox": [
        108.00003051757812,
        578.3239135742188,
        206.4006805419922,
        588.340576171875
      ],
      "text": "for some constant c > 1."
    },
    {
      "page_no": 5,
      "bbox": [
        108.00003051757812,
        595.6895141601562,
        504.00341796875,
        660.5380249023438
      ],
      "text": "Remarks.\nTheorems 1 & 2 state the convergence of the accuracy with increasing number of sam-\nples, indicating that the performance gains of using more samples will saturate for any fixed models.\nThe limit is determined by the likelihood of generating the correct answers through all possible rea-\nsoning paths (and the likelihood should be viewed as a weighted sum for weighted majority voting).\nThis motivates us to consider inference algorithms that search for “good” reasoning paths, such as\nthe tree-search-based variants detailed in Sec. 3.1.1 & 3.1.2."
    },
    {
      "page_no": 5,
      "bbox": [
        108.00003051757812,
        667.511474609375,
        504.0032958984375,
        732.26904296875
      ],
      "text": "Theorem 1 & 2 also present insights to compare standard majority voting with weighted majority\nvoting. Informally, as long as the reward model is “better than random”, i.e., assigning higher\nrewards to correct solutions on average, the accuracy limit of weighted majority voting is higher\nthan that of majority voting. In our experiments, we consistently find that weighted majority voting\ndominates majority voting. Thus, we focus on best-of-n and weighted majority voting in the main\npaper and defer majority voting results to Appendix D."
    },
    {
      "page_no": 5,
      "bbox": [
        303.509033203125,
        752.1944580078125,
        308.4903259277344,
        762.1570434570312
      ],
      "text": "5"
    },
    {
      "page_no": 6,
      "bbox": [
        108.0,
        27.81348991394043,
        293.0951843261719,
        37.77608871459961
      ],
      "text": "Published as a conference paper at ICLR 2025"
    },
    {
      "page_no": 6,
      "bbox": [
        150.156005859375,
        252.5753936767578,
        461.8442077636719,
        262.5379943847656
      ],
      "text": "Figure 3: Illustration of one iteration of REward BAlanced SEarch (REBASE)."
    },
    {
      "page_no": 6,
      "bbox": [
        108.2490234375,
        289.71038818359375,
        308.8349609375,
        299.6730041503906
      ],
      "text": "3.1.1\nMONTE CARLO TREE SEARCH (MCTS)"
    },
    {
      "page_no": 6,
      "bbox": [
        108.00003051757812,
        304.6923828125,
        504.0033874511719,
        369.4489440917969
      ],
      "text": "Monte Carlo Tree Search (MCTS) has proven effective in domains such as board games where\nstrategic decision-making is required (Silver et al., 2016; 2017; Jones, 2021). Recent work has\nshown that adapting MCTS to the context of LLMs can enhance the text generation process (Zhang\net al., 2023; Zhou et al., 2024; Liu et al., 2024; Choi et al., 2023; Chen et al., 2024a; Tian et al.,\n2024; Chen et al., 2024a). In this context, MCTS is paired with a value model to score and guide\nthe exploration steps. For additional background, we provide a review of MCTS in Appendix B."
    },
    {
      "page_no": 6,
      "bbox": [
        108.00003051757812,
        380.38232421875,
        504.00341796875,
        510.8918151855469
      ],
      "text": "Recent work in MCTS or its variants mainly focus on improving the performance (e.g., accuracy) on\nthe studied tasks. However, generic comparisons of MCTS with conventional methods like best-of-n\nand majority voting in terms of computational budget, measured in generated tokens or processing\ntime are scarce or indicate potentially unfavorable cost-performance tradeoffs. For example, MCTS\nconsumes substantially more resources, often requiring dozens of times more generated tokens than\nsimpler methods. Specifically, a significant portion of the paths in the search tree are used to estimate\nand select nodes, and these paths do not necessarily become a part of the final candidate solution,\nalthough MCTS ensures that the sampled solutions comprise high-quality intermediate steps. In\ncontrast, sampling methods generate multiple solutions in parallel and independently, and all the\ngenerated sequences are included in the candidate solutions. However, the intermediate steps in\nthese sequences are not guaranteed to be of high quality, as there is no mechanism for pruning poor\nsteps or exploiting promising ones."
    },
    {
      "page_no": 6,
      "bbox": [
        108.00003051757812,
        521.8251953125,
        504.0033874511719,
        553.7057495117188
      ],
      "text": "This highlights the need for a new tree search method that can achieve a comparable (or better) per-\nformance as MCTS, and that is computationally less costly, with a cost similar to weighted majority\nvoting and best-of-n. This motivates our new method, Reward Balanced SEarch (REBASE)."
    },
    {
      "page_no": 6,
      "bbox": [
        108.2490234375,
        565.8801879882812,
        311.5145568847656,
        575.8427734375
      ],
      "text": "3.1.2\nREWARD BALANCED SEARCH (REBASE)"
    },
    {
      "page_no": 6,
      "bbox": [
        108.00001525878906,
        580.8621826171875,
        504.0033874511719,
        656.5787963867188
      ],
      "text": "The REBASE tree search method, illustrated in Fig. 3, inherits the exploitation and pruning proper-\nties of tree search, while using a reward model alone to estimate quality of intermediate nodes. This\nsaves inference compute compared to methods such as MCTS, since it does not involve estimate\nnode quality with explicit rollouts. In short, the underlying idea is to use a process reward model to\ndetermine how much each node should be expanded at each depth. Namely, REBASE expands nodes\nat a given depth according to their softmax-normalized reward scores, subject to a total expansion\nbudget. We describe this procedure in more detail below."
    },
    {
      "page_no": 6,
      "bbox": [
        107.9998779296875,
        667.2806396484375,
        504.0038757324219,
        733.7627563476562
      ],
      "text": "Notations. We view the fine-tuned LLM as a policy πθ which generates the solution step by step.\nGiven a question x and the first k steps of a solution r1 · · · rk, the (k + 1)-th step is sampled from\nπθ(·|xr1 · · · rk). REBASE generates a solution tree during inference, in which the root node is the\nquestion x, and other nodes corresponds to solution steps. When generating solution trees, we\ngenerate children of rk by sampling from πθ(·|xr1 · · · rk). We use the corresponding solution step\nto denote a node. The reward of a node rk is generated by the PRM: R(rk) := R(xr1 · · · rk)."
    },
    {
      "page_no": 6,
      "bbox": [
        303.5087890625,
        752.1942138671875,
        308.4900817871094,
        762.1567993164062
      ],
      "text": "6"
    },
    {
      "page_no": 7,
      "bbox": [
        108.0,
        27.81348991394043,
        293.0951843261719,
        37.77608871459961
      ],
      "text": "Published as a conference paper at ICLR 2025"
    },
    {
      "page_no": 7,
      "bbox": [
        141.40879821777344,
        194.14671325683594,
        299.2080993652344,
        216.74179077148438
      ],
      "text": "4\n16\n64\n256\n1024\nInference FLOPs per question (×1012)"
    },
    {
      "page_no": 7,
      "bbox": [
        124.14595794677734,
        180.01678466796875,
        133.4508819580078,
        192.42333984375
      ],
      "text": "50"
    },
    {
      "page_no": 7,
      "bbox": [
        124.14595794677734,
        159.80795288085938,
        133.4508819580078,
        172.21450805664062
      ],
      "text": "55"
    },
    {
      "page_no": 7,
      "bbox": [
        124.14595794677734,
        141.35874938964844,
        133.4508819580078,
        153.7653045654297
      ],
      "text": "60"
    },
    {
      "page_no": 7,
      "bbox": [
        124.14595794677734,
        124.3871078491211,
        133.4508819580078,
        136.79367065429688
      ],
      "text": "65"
    },
    {
      "page_no": 7,
      "bbox": [
        124.14595794677734,
        108.67384338378906,
        133.4508819580078,
        121.08040618896484
      ],
      "text": "70"
    },
    {
      "page_no": 7,
      "bbox": [
        124.14595794677734,
        94.04513549804688,
        133.4508819580078,
        106.45169830322266
      ],
      "text": "75"
    },
    {
      "page_no": 7,
      "bbox": [
        111.5113754272461,
        108.52471923828125,
        124.57091522216797,
        181.0841827392578
      ],
      "text": "Test error on MATH"
    },
    {
      "page_no": 7,
      "bbox": [
        139.12429809570312,
        81.9515151977539,
        297.6507263183594,
        96.31700897216797
      ],
      "text": "Inference scaling (Weighted Majority)"
    },
    {
      "page_no": 7,
      "bbox": [
        254.02835083007812,
        97.00718688964844,
        295.73724365234375,
        145.70263671875
      ],
      "text": "Sampling (7B)\nSampling (34B)\nMCTS (7B)\nMCTS (34B)\nREBASE (7B)\nREBASE (34B)"
    },
    {
      "page_no": 7,
      "bbox": [
        337.9418029785156,
        194.14671325683594,
        495.7410888671875,
        216.74179077148438
      ],
      "text": "4\n16\n64\n256\n1024\nInference FLOPs per question (×1012)"
    },
    {
      "page_no": 7,
      "bbox": [
        320.678955078125,
        174.3546600341797,
        329.98388671875,
        186.76121520996094
      ],
      "text": "55"
    },
    {
      "page_no": 7,
      "bbox": [
        320.678955078125,
        152.14369201660156,
        329.98388671875,
        164.5502471923828
      ],
      "text": "60"
    },
    {
      "page_no": 7,
      "bbox": [
        320.678955078125,
        131.71157836914062,
        329.98388671875,
        144.11813354492188
      ],
      "text": "65"
    },
    {
      "page_no": 7,
      "bbox": [
        320.678955078125,
        112.79438781738281,
        329.98388671875,
        125.2009506225586
      ],
      "text": "70"
    },
    {
      "page_no": 7,
      "bbox": [
        320.678955078125,
        95.18291473388672,
        329.98388671875,
        107.5894775390625
      ],
      "text": "75"
    },
    {
      "page_no": 7,
      "bbox": [
        308.04437255859375,
        108.52471923828125,
        321.1039123535156,
        181.0841827392578
      ],
      "text": "Test error on MATH"
    },
    {
      "page_no": 7,
      "bbox": [
        354.6430969238281,
        81.9515151977539,
        475.22308349609375,
        96.31700897216797
      ],
      "text": "Inference scaling (Best-of-N)"
    },
    {
      "page_no": 7,
      "bbox": [
        450.56134033203125,
        97.00718688964844,
        492.2702331542969,
        145.70263671875
      ],
      "text": "Sampling (7B)\nSampling (34B)\nMCTS (7B)\nMCTS (34B)\nREBASE (7B)\nREBASE (34B)"
    },
    {
      "page_no": 7,
      "bbox": [
        108.0,
        230.4525146484375,
        504.00323486328125,
        273.3830261230469
      ],
      "text": "Figure 4: MATH inference scaling across inference strategies and model sizes (lower is better).\nDetailed MCTS configurations can be found in Appendix B. The left/right panel shows the error\nrate on MATH based on weighted majority/best-of-n. REBASE is the compute-optimal strategy at\nall budgets, with 7B typically the optimal model size."
    },
    {
      "page_no": 7,
      "bbox": [
        108.00003051757812,
        296.52886962890625,
        503.9983215332031,
        329.2504577636719
      ],
      "text": "Initialization. Given the question x, a balance temperature Tb > 0, and target number of generated\nsolutions N, we sample N instances of the first step for the question, yielding all the nodes of depth\n1 in the search tree. We let the sampling budget of depth 0, B0, to N at initialization."
    },
    {
      "page_no": 7,
      "bbox": [
        108.00001525878906,
        335.5468444824219,
        504.0007629394531,
        379.8804016113281
      ],
      "text": "Reward assignment and update. In the i-th iteration, the PRM assigns the rewards to all the nodes\nat depth i. After that, the algorithm examines whether the solutions up to depth i are complete.\nSupposing there are Ci completed solutions, we update the sampling budget using Bi ←Bi−1−Ci.\nIf Bi = 0, the process ends, and we obtain N solutions."
    },
    {
      "page_no": 7,
      "bbox": [
        108.00009155273438,
        385.5238342285156,
        503.9999694824219,
        408.16998291015625
      ],
      "text": "Exploration balancing and expansion. For all of the nodes nj with reward R(nj) in the depth i of\nthe tree, we calculate the expansion width of the nj as:"
    },
    {
      "page_no": 7,
      "bbox": [
        219.69216918945312,
        415.02825927734375,
        370.4606628417969,
        438.3999328613281
      ],
      "text": "Wj = Round\n\u0012\nBi\nexp (R(nj)/Tb)\nP"
    },
    {
      "page_no": 7,
      "bbox": [
        307.0820007324219,
        428.74591064453125,
        379.35150146484375,
        441.697509765625
      ],
      "text": "k exp (R(nk)/Tb)"
    },
    {
      "page_no": 7,
      "bbox": [
        380.5460510253906,
        415.0283203125,
        504.0003967285156,
        432.10504150390625
      ],
      "text": "\u0013\n.\n(1)"
    },
    {
      "page_no": 7,
      "bbox": [
        108.00003051757812,
        446.6768798828125,
        470.4179382324219,
        458.364013671875
      ],
      "text": "Then we sample Wj children for nj for all the nodes in depth i, and start the next iteration."
    },
    {
      "page_no": 7,
      "bbox": [
        108.29902648925781,
        468.4942626953125,
        200.08346557617188,
        480.449462890625
      ],
      "text": "4\nEXPERIMENTS"
    },
    {
      "page_no": 7,
      "bbox": [
        108.0000228881836,
        487.7994079589844,
        338.2257080078125,
        497.76202392578125
      ],
      "text": "Our experiments are centered around two main questions:"
    },
    {
      "page_no": 7,
      "bbox": [
        135.3970184326172,
        504.8084716796875,
        504.00213623046875,
        525.8209838867188
      ],
      "text": "• Compute-optimal model size: How does performance scale as inference-time compute is\nincreased with a fixed inference strategy, but with varying model size?"
    },
    {
      "page_no": 7,
      "bbox": [
        135.39703369140625,
        532.867431640625,
        503.9975891113281,
        553.8800048828125
      ],
      "text": "• Compute-optimal inference strategy: How does performance scale as inference-time\ncompute is increased with various inference strategies (and various model sizes)?"
    },
    {
      "page_no": 7,
      "bbox": [
        108.0,
        561.0173950195312,
        267.7403564453125,
        570.97998046875
      ],
      "text": "We detail our experimental setup below."
    },
    {
      "page_no": 7,
      "bbox": [
        108.0,
        580.2304077148438,
        504.0033264160156,
        659.6060180664062
      ],
      "text": "4.1\nSETUP\nDatasets.\nWe conduct experiments on two mathematical problem-solving datasets to investigate\nthe effects of scaling inference compute for both challenging and simpler problems. Specifically,\nMATH (Hendrycks et al., 2021a) and GSM8K (Cobbe et al., 2021) are datasets containing high\nschool mathematics competition-level problems and grade-school level mathematical reasoning\nproblems, respectively. Following Lightman et al. (2024); Wang et al. (2024); Sun et al. (2024),\nwe use the MATH500 subset as our test set."
    },
    {
      "page_no": 7,
      "bbox": [
        108.0,
        667.4204711914062,
        504.00341796875,
        732.2689819335938
      ],
      "text": "Policy model (solution generator).\nTo study the how performance scales as inference compute is\nincreased using a fixed strategy, the primary axis of variation is model size. Therefore, we choose\nPythia (Biderman et al., 2023) as our base models, since various model sizes are available in the\nPythia family. To study inference scaling under different inference strategies (e.g., tree search,\nweighted majority voting), we use math-specialized Llemma models (Azerbayev et al., 2024). We\nfinetune these models on the MetaMath dataset (Yu et al., 2024) using full parameter supervised"
    },
    {
      "page_no": 7,
      "bbox": [
        303.5090026855469,
        752.1943969726562,
        308.49029541015625,
        762.156982421875
      ],
      "text": "7"
    },
    {
      "page_no": 8,
      "bbox": [
        108.0,
        27.81348991394043,
        293.0951843261719,
        37.77608871459961
      ],
      "text": "Published as a conference paper at ICLR 2025"
    },
    {
      "page_no": 8,
      "bbox": [
        137.23187255859375,
        194.88107299804688,
        290.8404846191406,
        216.9232177734375
      ],
      "text": "2\n4\n8\n16\n32\n64\n128\n256\nInference FLOPs per question (×1012)"
    },
    {
      "page_no": 8,
      "bbox": [
        124.14595794677734,
        179.70408630371094,
        133.4508819580078,
        192.1106414794922
      ],
      "text": "12"
    },
    {
      "page_no": 8,
      "bbox": [
        124.14595794677734,
        155.81227111816406,
        133.4508819580078,
        168.2188262939453
      ],
      "text": "16"
    },
    {
      "page_no": 8,
      "bbox": [
        124.14595794677734,
        137.28033447265625,
        133.4508819580078,
        149.6868896484375
      ],
      "text": "20"
    },
    {
      "page_no": 8,
      "bbox": [
        124.14595794677734,
        122.13863372802734,
        133.4508819580078,
        134.54519653320312
      ],
      "text": "24"
    },
    {
      "page_no": 8,
      "bbox": [
        124.14595794677734,
        109.33651733398438,
        133.4508819580078,
        121.74308013916016
      ],
      "text": "28"
    },
    {
      "page_no": 8,
      "bbox": [
        124.14595794677734,
        98.246826171875,
        133.4508819580078,
        110.65338897705078
      ],
      "text": "32"
    },
    {
      "page_no": 8,
      "bbox": [
        111.5113754272461,
        105.96910095214844,
        124.57091522216797,
        184.16775512695312
      ],
      "text": "Test error on GSM8K"
    },
    {
      "page_no": 8,
      "bbox": [
        139.12429809570312,
        81.9515151977539,
        297.6507263183594,
        96.31700897216797
      ],
      "text": "Inference scaling (Weighted Majority)"
    },
    {
      "page_no": 8,
      "bbox": [
        244.05538940429688,
        97.50086975097656,
        294.701904296875,
        137.42308044433594
      ],
      "text": "Sampling (7B)\nSampling (34B)\nREBASE (7B)\nREBASE (34B)"
    },
    {
      "page_no": 8,
      "bbox": [
        333.7648620605469,
        194.88107299804688,
        487.3735046386719,
        216.9232177734375
      ],
      "text": "2\n4\n8\n16\n32\n64\n128\n256\nInference FLOPs per question (×1012)"
    },
    {
      "page_no": 8,
      "bbox": [
        320.678955078125,
        179.70408630371094,
        329.98388671875,
        192.1106414794922
      ],
      "text": "12"
    },
    {
      "page_no": 8,
      "bbox": [
        320.678955078125,
        155.81227111816406,
        329.98388671875,
        168.2188262939453
      ],
      "text": "16"
    },
    {
      "page_no": 8,
      "bbox": [
        320.678955078125,
        137.28033447265625,
        329.98388671875,
        149.6868896484375
      ],
      "text": "20"
    },
    {
      "page_no": 8,
      "bbox": [
        320.678955078125,
        122.13863372802734,
        329.98388671875,
        134.54519653320312
      ],
      "text": "24"
    },
    {
      "page_no": 8,
      "bbox": [
        320.678955078125,
        109.33651733398438,
        329.98388671875,
        121.74308013916016
      ],
      "text": "28"
    },
    {
      "page_no": 8,
      "bbox": [
        320.678955078125,
        98.246826171875,
        329.98388671875,
        110.65338897705078
      ],
      "text": "32"
    },
    {
      "page_no": 8,
      "bbox": [
        308.04437255859375,
        105.96910095214844,
        321.1039123535156,
        184.16775512695312
      ],
      "text": "Test error on GSM8K"
    },
    {
      "page_no": 8,
      "bbox": [
        354.6430969238281,
        81.9515151977539,
        475.22308349609375,
        96.31700897216797
      ],
      "text": "Inference scaling (Best-of-N)"
    },
    {
      "page_no": 8,
      "bbox": [
        440.58837890625,
        97.50086975097656,
        491.2348937988281,
        137.42308044433594
      ],
      "text": "Sampling (7B)\nSampling (34B)\nREBASE (7B)\nREBASE (34B)"
    },
    {
      "page_no": 8,
      "bbox": [
        107.99998474121094,
        230.4525146484375,
        504.00323486328125,
        273.3830261230469
      ],
      "text": "Figure 5: GSM8k inference scaling across inference strategies and model sizes (lower is bet-\nter).\nThe left/right panel shows the problem-solving error rate on GSM8K based on weighted\nmajority/best-of-n. MCTS is not included in the comparison because of its poor compute-accuracy\ntrade-off. REBASE is the compute-optimal inference strategy, and the optimal model size varies."
    },
    {
      "page_no": 8,
      "bbox": [
        107.99998474121094,
        296.930419921875,
        504.00311279296875,
        317.8520202636719
      ],
      "text": "fine-tuning (Full-SFT), The finetuning configuration is given in the Appendix. Additionally, we test\nthe Mistral-7B (Jiang et al., 2023) to expand our findings across different models and architectures."
    },
    {
      "page_no": 8,
      "bbox": [
        107.99998474121094,
        325.85845947265625,
        504.0033264160156,
        357.8299865722656
      ],
      "text": "Reward model.\nAll of the experiments use the same Llemma-34B reward model, which we fine-\ntuned on the synthetic process reward modeling dataset, Math-Shepherd (Wang et al., 2024). We\nadded a reward head to the model, enabling it to output a scalar reward at the end of each step."
    },
    {
      "page_no": 8,
      "bbox": [
        107.99993896484375,
        365.83642578125,
        504.0033264160156,
        430.6849060058594
      ],
      "text": "Inference configuration.\nWe use sampling and tree search methods to generate multiple candi-\ndates, and select the answer through best-of-n, majority voting, or weighted voting. Each con-\nfiguration is run multiple times to calculate the mean and variance, which mitigates effects from\nrandomness and thereby improves the reliability of our conclusions. Unless explicitly stated other-\nwise, each point in the figures in this section corresponds to 2i samples, where i is an integer starting\nfrom 0."
    },
    {
      "page_no": 8,
      "bbox": [
        107.99993896484375,
        440.1272888183594,
        504.00323486328125,
        486.7038879394531
      ],
      "text": "4.2\nCOMPUTE-OPTIMAL MODEL SIZE\nTo compare the inference compute budgets of different models, we plot the figures with the num-\nber of FLOPs used per question during inference. We compute the inference FLOPs based on the\ncommonly-used formula proposed by Kaplan et al. (2020)."
    },
    {
      "page_no": 8,
      "bbox": [
        107.99993896484375,
        494.7103271484375,
        504.0032958984375,
        592.435791015625
      ],
      "text": "Scaling law of compute-optimal inference for model size.\nFig. 1 shows the relationship between\ninference compute and error rate for different model sizes. The error rate first decreases steadily and\nthen starts to saturate. Initially, sampling many times from smaller models is compute-optimal. At\nlarger compute budgets the larger models are preferable, since the performance of small models has\nsaturated. As highlighted in the right panel of Fig. 1, the optimal model size varies based on the\ninference budget. We performed a regression analysis on inference FLOPs C and model sizes N\nto establish a relationship between a given computational budget and its optimal model size. The\nresulting equation, log10 (C) = 1.19 log10 (N) + 2.03, lets us estimate the optimal inference model\nsize for a specific compute budget."
    },
    {
      "page_no": 8,
      "bbox": [
        107.99995422363281,
        600.4422607421875,
        504.0037841796875,
        676.248779296875
      ],
      "text": "Llemma-7B achieves competitive accuracy to Llemma-34B with less compute.\nFig. 4 and\nFig. 5 shows the relationship between error rate and inference FLOPs for Llemma 7B and Llemma\n34B using different inference strategies. Llemma-7B requires around 2× less total FLOPs than\nLlemma-34B to achieve comparable accuracy. This held across inference strategies (sampling strate-\ngies, MCTS, REBASE) and tasks (MATH, GSM8K). This result suggests that, with the same training\ndataset and model family, generating more tokens with a suitable inference strategy using a smaller\nmodel can have more favorable cost-performance tradeoffs than using a larger model."
    },
    {
      "page_no": 8,
      "bbox": [
        107.99996948242188,
        685.6921997070312,
        504.00360107421875,
        732.268798828125
      ],
      "text": "4.3\nCOMPUTE-OPTIMAL INFERENCE STRATEGY\nREBASE is Pareto-optimal.\nREBASE consistently achieves the best cost-performance tradeoffs,\noutperforming the sampling-based methods in all settings when fixing the model and the evaluation\ntask (Fig. 4, 5, 6, and 7). For example, in Fig. 4, REBASE is the compute-optimal strategy at all"
    },
    {
      "page_no": 8,
      "bbox": [
        303.5090026855469,
        752.1942138671875,
        308.49029541015625,
        762.1567993164062
      ],
      "text": "8"
    },
    {
      "page_no": 9,
      "bbox": [
        108.0,
        27.81348991394043,
        293.0951843261719,
        37.77608871459961
      ],
      "text": "Published as a conference paper at ICLR 2025"
    },
    {
      "page_no": 9,
      "bbox": [
        114.87318420410156,
        187.12698364257812,
        234.928955078125,
        207.65713500976562
      ],
      "text": "4\n16\n64\n256\n1024\nInfer. FLOPs per question (×1012)"
    },
    {
      "page_no": 9,
      "bbox": [
        122.41534423828125,
        182.1654052734375,
        130.6258544921875,
        193.1127471923828
      ],
      "text": "45"
    },
    {
      "page_no": 9,
      "bbox": [
        122.41534423828125,
        164.97964477539062,
        130.6258544921875,
        175.92698669433594
      ],
      "text": "50"
    },
    {
      "page_no": 9,
      "bbox": [
        122.41534423828125,
        149.4332275390625,
        130.6258544921875,
        160.3805694580078
      ],
      "text": "55"
    },
    {
      "page_no": 9,
      "bbox": [
        122.41534423828125,
        135.24044799804688,
        130.6258544921875,
        146.1877899169922
      ],
      "text": "60"
    },
    {
      "page_no": 9,
      "bbox": [
        122.41534423828125,
        122.18435668945312,
        130.6258544921875,
        133.13169860839844
      ],
      "text": "65"
    },
    {
      "page_no": 9,
      "bbox": [
        122.41534423828125,
        110.09632110595703,
        130.6258544921875,
        121.04366302490234
      ],
      "text": "70"
    },
    {
      "page_no": 9,
      "bbox": [
        122.41534423828125,
        98.84262084960938,
        130.6258544921875,
        109.78996276855469
      ],
      "text": "75"
    },
    {
      "page_no": 9,
      "bbox": [
        122.41534423828125,
        88.31548309326172,
        130.6258544921875,
        99.26282501220703
      ],
      "text": "80"
    },
    {
      "page_no": 9,
      "bbox": [
        110.64743041992188,
        106.95249938964844,
        122.81114196777344,
        174.53469848632812
      ],
      "text": "Test error on MATH"
    },
    {
      "page_no": 9,
      "bbox": [
        161.60623168945312,
        81.94390106201172,
        206.52734375,
        95.32398986816406
      ],
      "text": "Llemma-7B"
    },
    {
      "page_no": 9,
      "bbox": [
        184.58615112304688,
        96.42664337158203,
        229.5397186279297,
        133.61036682128906
      ],
      "text": "Sampling W.M.\nSampling BoN\nREBASE W.M.\nREBASE BoN"
    },
    {
      "page_no": 9,
      "bbox": [
        246.54310607910156,
        187.12698364257812,
        366.5989074707031,
        207.65713500976562
      ],
      "text": "16\n32\n64 128 256 5121024\nInfer. FLOPs per question (×1012)"
    },
    {
      "page_no": 9,
      "bbox": [
        254.00332641601562,
        182.1654052734375,
        262.2138366699219,
        193.1127471923828
      ],
      "text": "45"
    },
    {
      "page_no": 9,
      "bbox": [
        254.00332641601562,
        162.80836486816406,
        262.2138366699219,
        173.75570678710938
      ],
      "text": "50"
    },
    {
      "page_no": 9,
      "bbox": [
        254.00332641601562,
        145.2977752685547,
        262.2138366699219,
        156.2451171875
      ],
      "text": "55"
    },
    {
      "page_no": 9,
      "bbox": [
        254.00332641601562,
        129.31187438964844,
        262.2138366699219,
        140.25921630859375
      ],
      "text": "60"
    },
    {
      "page_no": 9,
      "bbox": [
        254.00332641601562,
        114.60626220703125,
        262.2138366699219,
        125.55360412597656
      ],
      "text": "65"
    },
    {
      "page_no": 9,
      "bbox": [
        254.00332641601562,
        100.99099731445312,
        262.2138366699219,
        111.93833923339844
      ],
      "text": "70"
    },
    {
      "page_no": 9,
      "bbox": [
        254.00332641601562,
        88.31548309326172,
        262.2138366699219,
        99.26282501220703
      ],
      "text": "75"
    },
    {
      "page_no": 9,
      "bbox": [
        242.2354278564453,
        106.95249938964844,
        254.39913940429688,
        174.53469848632812
      ],
      "text": "Test error on MATH"
    },
    {
      "page_no": 9,
      "bbox": [
        290.7249755859375,
        81.94390106201172,
        340.6636047363281,
        95.32398986816406
      ],
      "text": "Llemma-34B"
    },
    {
      "page_no": 9,
      "bbox": [
        316.2560729980469,
        96.42664337158203,
        361.2096252441406,
        133.61036682128906
      ],
      "text": "Sampling W.M.\nSampling BoN\nREBASE W.M.\nREBASE BoN"
    },
    {
      "page_no": 9,
      "bbox": [
        377.5703430175781,
        187.12698364257812,
        498.1944274902344,
        207.65713500976562
      ],
      "text": "4\n8\n16 32 64 128256512\nInfer. FLOPs per question (×1012)"
    },
    {
      "page_no": 9,
      "bbox": [
        385.5913391113281,
        182.1654052734375,
        393.8018493652344,
        193.1127471923828
      ],
      "text": "50"
    },
    {
      "page_no": 9,
      "bbox": [
        385.5913391113281,
        163.1339569091797,
        393.8018493652344,
        174.081298828125
      ],
      "text": "55"
    },
    {
      "page_no": 9,
      "bbox": [
        385.5913391113281,
        145.7595977783203,
        393.8018493652344,
        156.70693969726562
      ],
      "text": "60"
    },
    {
      "page_no": 9,
      "bbox": [
        385.5913391113281,
        129.7767333984375,
        393.8018493652344,
        140.7240753173828
      ],
      "text": "65"
    },
    {
      "page_no": 9,
      "bbox": [
        385.5913391113281,
        114.97891998291016,
        393.8018493652344,
        125.92626190185547
      ],
      "text": "70"
    },
    {
      "page_no": 9,
      "bbox": [
        385.5913391113281,
        101.20248413085938,
        393.8018493652344,
        112.14982604980469
      ],
      "text": "75"
    },
    {
      "page_no": 9,
      "bbox": [
        385.5913391113281,
        88.31548309326172,
        393.8018493652344,
        99.26282501220703
      ],
      "text": "80"
    },
    {
      "page_no": 9,
      "bbox": [
        373.82342529296875,
        106.95249938964844,
        385.9871520996094,
        174.53469848632812
      ],
      "text": "Test error on MATH"
    },
    {
      "page_no": 9,
      "bbox": [
        427.1314392089844,
        81.94390106201172,
        466.8851318359375,
        95.32398986816406
      ],
      "text": "Mistral-7B"
    },
    {
      "page_no": 9,
      "bbox": [
        447.2832946777344,
        96.42664337158203,
        492.2368469238281,
        133.61036682128906
      ],
      "text": "Sampling W.M.\nSampling BoN\nREBASE W.M.\nREBASE BoN"
    },
    {
      "page_no": 9,
      "bbox": [
        108.0,
        220.94354248046875,
        504.0032958984375,
        252.91506958007812
      ],
      "text": "Figure 6: MATH inference scaling across inference strategies and models (lower is better). The\ntested models are Llemma-7B (left), Llemma-34B (middle), & Mistral-7B (right). In the legend,\nW.M. and BoN refer to weighted majority and best-of-n, respectively."
    },
    {
      "page_no": 9,
      "bbox": [
        114.95511627197266,
        370.9539794921875,
        235.01087951660156,
        391.484130859375
      ],
      "text": "2\n4\n8\n16\n32\n64\nInfer. FLOPs per question (×1012)"
    },
    {
      "page_no": 9,
      "bbox": [
        122.41534423828125,
        365.9924011230469,
        130.6258544921875,
        376.93975830078125
      ],
      "text": "10"
    },
    {
      "page_no": 9,
      "bbox": [
        122.41534423828125,
        338.5430603027344,
        130.6258544921875,
        349.49041748046875
      ],
      "text": "15"
    },
    {
      "page_no": 9,
      "bbox": [
        122.41534423828125,
        319.06744384765625,
        130.6258544921875,
        330.0148010253906
      ],
      "text": "20"
    },
    {
      "page_no": 9,
      "bbox": [
        122.41534423828125,
        303.9609680175781,
        130.6258544921875,
        314.9083251953125
      ],
      "text": "25"
    },
    {
      "page_no": 9,
      "bbox": [
        122.41534423828125,
        291.61810302734375,
        130.6258544921875,
        302.5654602050781
      ],
      "text": "30"
    },
    {
      "page_no": 9,
      "bbox": [
        122.41534423828125,
        272.1424865722656,
        130.6258544921875,
        292.12969970703125
      ],
      "text": "35\n40"
    },
    {
      "page_no": 9,
      "bbox": [
        110.64743041992188,
        288.1409912109375,
        122.81114196777344,
        360.9755554199219
      ],
      "text": "Test error on GSM8K"
    },
    {
      "page_no": 9,
      "bbox": [
        161.64718627929688,
        265.7709045410156,
        206.56829833984375,
        279.1510009765625
      ],
      "text": "Llemma-7B"
    },
    {
      "page_no": 9,
      "bbox": [
        184.66807556152344,
        280.253662109375,
        229.62164306640625,
        317.4373474121094
      ],
      "text": "Sampling W.M.\nSampling BoN\nREBASE W.M.\nREBASE BoN"
    },
    {
      "page_no": 9,
      "bbox": [
        246.54310607910156,
        370.9539794921875,
        366.5989074707031,
        391.484130859375
      ],
      "text": "16\n32\n64\n128\n256\nInfer. FLOPs per question (×1012)"
    },
    {
      "page_no": 9,
      "bbox": [
        254.03561401367188,
        365.9924011230469,
        262.2461242675781,
        376.93975830078125
      ],
      "text": "10"
    },
    {
      "page_no": 9,
      "bbox": [
        254.03561401367188,
        348.0848693847656,
        262.2461242675781,
        359.0322265625
      ],
      "text": "12"
    },
    {
      "page_no": 9,
      "bbox": [
        254.03561401367188,
        332.9442443847656,
        262.2461242675781,
        343.8916015625
      ],
      "text": "14"
    },
    {
      "page_no": 9,
      "bbox": [
        254.03561401367188,
        319.828857421875,
        262.2461242675781,
        330.7762145996094
      ],
      "text": "16"
    },
    {
      "page_no": 9,
      "bbox": [
        254.03561401367188,
        308.26025390625,
        262.2461242675781,
        319.2076110839844
      ],
      "text": "18"
    },
    {
      "page_no": 9,
      "bbox": [
        254.03561401367188,
        272.1424865722656,
        262.2461242675781,
        308.859130859375
      ],
      "text": "20\n22\n24\n26"
    },
    {
      "page_no": 9,
      "bbox": [
        242.2677001953125,
        288.1409912109375,
        254.43141174316406,
        360.9755554199219
      ],
      "text": "Test error on GSM8K"
    },
    {
      "page_no": 9,
      "bbox": [
        290.7411193847656,
        265.7709045410156,
        340.67974853515625,
        279.1510009765625
      ],
      "text": "Llemma-34B"
    },
    {
      "page_no": 9,
      "bbox": [
        316.2560729980469,
        280.253662109375,
        361.2096252441406,
        317.4373474121094
      ],
      "text": "Sampling W.M.\nSampling BoN\nREBASE W.M.\nREBASE BoN"
    },
    {
      "page_no": 9,
      "bbox": [
        378.1311340332031,
        370.9539794921875,
        498.1869201660156,
        391.484130859375
      ],
      "text": "2\n4\n8\n16\n32\n64\nInfer. FLOPs per question (×1012)"
    },
    {
      "page_no": 9,
      "bbox": [
        389.730712890625,
        365.9924011230469,
        393.8359680175781,
        376.93975830078125
      ],
      "text": "8"
    },
    {
      "page_no": 9,
      "bbox": [
        385.6236267089844,
        348.2247009277344,
        393.8341369628906,
        359.17205810546875
      ],
      "text": "10"
    },
    {
      "page_no": 9,
      "bbox": [
        385.6236267089844,
        333.7073974609375,
        393.8341369628906,
        344.6547546386719
      ],
      "text": "12"
    },
    {
      "page_no": 9,
      "bbox": [
        385.6236267089844,
        321.4332275390625,
        393.8341369628906,
        332.3805847167969
      ],
      "text": "14"
    },
    {
      "page_no": 9,
      "bbox": [
        385.6236267089844,
        272.1424865722656,
        393.8341369628906,
        321.7481994628906
      ],
      "text": "16\n18\n20\n22\n24\n26"
    },
    {
      "page_no": 9,
      "bbox": [
        373.855712890625,
        288.1409912109375,
        386.0194396972656,
        360.9755554199219
      ],
      "text": "Test error on GSM8K"
    },
    {
      "page_no": 9,
      "bbox": [
        427.427978515625,
        265.7709045410156,
        467.181640625,
        279.1510009765625
      ],
      "text": "Mistral-7B"
    },
    {
      "page_no": 9,
      "bbox": [
        447.8440856933594,
        280.253662109375,
        492.7976379394531,
        317.4373474121094
      ],
      "text": "Sampling W.M.\nSampling BoN\nREBASE W.M.\nREBASE BoN"
    },
    {
      "page_no": 9,
      "bbox": [
        108.0,
        404.7705078125,
        504.0032958984375,
        436.7420349121094
      ],
      "text": "Figure 7: GSM8K inference scaling across inference strategies and models (lower is better). The\ntested models are Llemma-7B (left), Llemma-34B (middle), & Mistral-7B (right). In the legend,\nW.M. and BoN refer to weighted majority and best-of-n, respectively."
    },
    {
      "page_no": 9,
      "bbox": [
        133.16148376464844,
        527.7188720703125,
        205.19906616210938,
        545.9398803710938
      ],
      "text": "2\n4\n8\n16 32 64\nNumber of Samples"
    },
    {
      "page_no": 9,
      "bbox": [
        117.04829406738281,
        515.706787109375,
        125.16000366210938,
        526.5223999023438
      ],
      "text": "27"
    },
    {
      "page_no": 9,
      "bbox": [
        117.04829406738281,
        503.8027648925781,
        125.16000366210938,
        514.618408203125
      ],
      "text": "30"
    },
    {
      "page_no": 9,
      "bbox": [
        117.04829406738281,
        491.8987731933594,
        125.16000366210938,
        502.7143859863281
      ],
      "text": "33"
    },
    {
      "page_no": 9,
      "bbox": [
        117.04829406738281,
        479.99481201171875,
        125.16000366210938,
        490.8104248046875
      ],
      "text": "36"
    },
    {
      "page_no": 9,
      "bbox": [
        117.04829406738281,
        468.0908203125,
        125.16000366210938,
        478.90643310546875
      ],
      "text": "39"
    },
    {
      "page_no": 9,
      "bbox": [
        117.04829406738281,
        456.1868591308594,
        125.16000366210938,
        467.0024719238281
      ],
      "text": "42"
    },
    {
      "page_no": 9,
      "bbox": [
        106.57276916503906,
        470.9763488769531,
        117.78895568847656,
        515.7703247070312
      ],
      "text": "Test Error (%)"
    },
    {
      "page_no": 9,
      "bbox": [
        122.79698181152344,
        448.08770751953125,
        209.50047302246094,
        459.3039245605469
      ],
      "text": "Llemma-7B on MATH-easy"
    },
    {
      "page_no": 9,
      "bbox": [
        176.55604553222656,
        460.180419921875,
        204.20208740234375,
        478.86376953125
      ],
      "text": "Sampling\nREBASE"
    },
    {
      "page_no": 9,
      "bbox": [
        230.75462341308594,
        527.7188720703125,
        302.79217529296875,
        545.9398803710938
      ],
      "text": "2\n4\n8\n16 32 64\nNumber of Samples"
    },
    {
      "page_no": 9,
      "bbox": [
        214.64141845703125,
        518.0040283203125,
        222.75311279296875,
        528.8196411132812
      ],
      "text": "60"
    },
    {
      "page_no": 9,
      "bbox": [
        214.64141845703125,
        506.7265319824219,
        222.75311279296875,
        517.5421752929688
      ],
      "text": "63"
    },
    {
      "page_no": 9,
      "bbox": [
        214.64141845703125,
        495.4490966796875,
        222.75311279296875,
        506.26470947265625
      ],
      "text": "66"
    },
    {
      "page_no": 9,
      "bbox": [
        214.64141845703125,
        484.171630859375,
        222.75311279296875,
        494.98724365234375
      ],
      "text": "69"
    },
    {
      "page_no": 9,
      "bbox": [
        214.64141845703125,
        472.8941955566406,
        222.75311279296875,
        483.7098083496094
      ],
      "text": "72"
    },
    {
      "page_no": 9,
      "bbox": [
        214.64141845703125,
        461.6167297363281,
        222.75311279296875,
        472.4323425292969
      ],
      "text": "75"
    },
    {
      "page_no": 9,
      "bbox": [
        220.82928466796875,
        448.08770751953125,
        307.1009521484375,
        459.3039245605469
      ],
      "text": "Llemma-7B on MATH-hard"
    },
    {
      "page_no": 9,
      "bbox": [
        274.149169921875,
        460.180419921875,
        301.7951965332031,
        478.86376953125
      ],
      "text": "Sampling\nREBASE"
    },
    {
      "page_no": 9,
      "bbox": [
        328.3477478027344,
        527.7188720703125,
        400.38531494140625,
        545.9398803710938
      ],
      "text": "2\n4\n8\n16 32 64\nNumber of Samples"
    },
    {
      "page_no": 9,
      "bbox": [
        312.23455810546875,
        514.1195678710938,
        320.34625244140625,
        524.9351806640625
      ],
      "text": "27"
    },
    {
      "page_no": 9,
      "bbox": [
        312.23455810546875,
        499.83477783203125,
        320.34625244140625,
        510.650390625
      ],
      "text": "30"
    },
    {
      "page_no": 9,
      "bbox": [
        312.23455810546875,
        485.54998779296875,
        320.34625244140625,
        496.3656005859375
      ],
      "text": "33"
    },
    {
      "page_no": 9,
      "bbox": [
        312.23455810546875,
        471.2652282714844,
        320.34625244140625,
        482.0808410644531
      ],
      "text": "36"
    },
    {
      "page_no": 9,
      "bbox": [
        312.23455810546875,
        456.9804382324219,
        320.34625244140625,
        467.7960510253906
      ],
      "text": "39"
    },
    {
      "page_no": 9,
      "bbox": [
        313.776123046875,
        448.08770751953125,
        404.68572998046875,
        459.3039245605469
      ],
      "text": "Llemma-34B on MATH-easy"
    },
    {
      "page_no": 9,
      "bbox": [
        371.7423095703125,
        460.180419921875,
        399.3883361816406,
        478.86376953125
      ],
      "text": "Sampling\nREBASE"
    },
    {
      "page_no": 9,
      "bbox": [
        425.94085693359375,
        527.7188720703125,
        497.9784240722656,
        545.9398803710938
      ],
      "text": "2\n4\n8\n16 32 64\nNumber of Samples"
    },
    {
      "page_no": 9,
      "bbox": [
        409.8276672363281,
        516.3546142578125,
        417.9393615722656,
        527.1702270507812
      ],
      "text": "57"
    },
    {
      "page_no": 9,
      "bbox": [
        409.8276672363281,
        505.4223327636719,
        417.9393615722656,
        516.2379760742188
      ],
      "text": "60"
    },
    {
      "page_no": 9,
      "bbox": [
        409.8276672363281,
        494.4901123046875,
        417.9393615722656,
        505.30572509765625
      ],
      "text": "63"
    },
    {
      "page_no": 9,
      "bbox": [
        409.8276672363281,
        483.5578918457031,
        417.9393615722656,
        494.3735046386719
      ],
      "text": "66"
    },
    {
      "page_no": 9,
      "bbox": [
        409.8276672363281,
        472.62567138671875,
        417.9393615722656,
        483.4412841796875
      ],
      "text": "69"
    },
    {
      "page_no": 9,
      "bbox": [
        409.8276672363281,
        461.6934509277344,
        417.9393615722656,
        472.5090637207031
      ],
      "text": "72"
    },
    {
      "page_no": 9,
      "bbox": [
        411.8083801269531,
        448.08770751953125,
        502.2861328125,
        459.3039245605469
      ],
      "text": "Llemma-34B on MATH-hard"
    },
    {
      "page_no": 9,
      "bbox": [
        469.3354187011719,
        460.180419921875,
        496.9814453125,
        478.86376953125
      ],
      "text": "Sampling\nREBASE"
    },
    {
      "page_no": 9,
      "bbox": [
        107.99998474121094,
        555.9425048828125,
        504.0032653808594,
        587.9140625
      ],
      "text": "Figure 8: Comparisons of sampling and REBASE using weighted majority voting on MATH-easy\nproblems (levels 1-2) and MATH-hard problems (levels 3-5). The tested models are Llemma-7B\nand Llemma-34B."
    },
    {
      "page_no": 9,
      "bbox": [
        107.99998474121094,
        611.00146484375,
        504.00323486328125,
        642.8820190429688
      ],
      "text": "inference compute budgets, with 7B typically the optimal model size. On the other hand, MCTS\nunderperforms the sampling-based methods at each compute budget, likely due to its costly rollouts\n(Fig. 4) compared to the efficient use of the reward model in REBASE."
    },
    {
      "page_no": 9,
      "bbox": [
        108.0,
        649.8564453125,
        504.00323486328125,
        703.654052734375
      ],
      "text": "Tab. 1 shows that REBASE achieves better accuracy with a lower compute budget compared to\nsampling-based weighted voting. With the 7B model, REBASE achieves higher accuracy with 7\ntimes less compute. This finding is novel, and differs from previous tree search methods that typi-\ncally improve the performance at the cost of higher computational expense compared to sampling-\nbased voting (Chen et al., 2024a; Xie et al., 2023)."
    },
    {
      "page_no": 9,
      "bbox": [
        108.00001525878906,
        711.2565307617188,
        504.0033264160156,
        732.26904296875
      ],
      "text": "REBASE yields greater gains on hard problems.\nThe MATH dataset assigns each problem a dif-\nficulty level from 1 to 5. This enables a finer-grained analysis of the relationship between problem"
    },
    {
      "page_no": 9,
      "bbox": [
        303.509033203125,
        752.1944580078125,
        308.4903259277344,
        762.1570434570312
      ],
      "text": "9"
    },
    {
      "page_no": 10,
      "bbox": [
        108.0,
        27.81348991394043,
        293.0951843261719,
        37.77608871459961
      ],
      "text": "Published as a conference paper at ICLR 2025"
    },
    {
      "page_no": 10,
      "bbox": [
        107.99996948242188,
        81.88652801513672,
        504.0031433105469,
        113.85806274414062
      ],
      "text": "Table 1: REBASE with a lower compute budget achieves better accuracy compared to sampling\nwith a higher compute budget. We use weighted voting to aggregate candidates for both sampling\nand REBASE."
    },
    {
      "page_no": 10,
      "bbox": [
        221.39700317382812,
        128.4014434814453,
        440.7535705566406,
        138.36404418945312
      ],
      "text": "# Samples\nFLOPs\nMATH500 Accuracy (%)"
    },
    {
      "page_no": 10,
      "bbox": [
        284.1369934082031,
        144.3625030517578,
        327.86279296875,
        154.32510375976562
      ],
      "text": "Mistral-7B"
    },
    {
      "page_no": 10,
      "bbox": [
        171.24600219726562,
        159.25172424316406,
        398.92156982421875,
        182.12203979492188
      ],
      "text": "Sampling\n256\n8.70 × 1014\n42.8\nREBASE\n32\n1.36 × 1014\n45.0"
    },
    {
      "page_no": 10,
      "bbox": [
        281.9259948730469,
        188.12049865722656,
        330.07525634765625,
        198.08309936523438
      ],
      "text": "Llemma-7B"
    },
    {
      "page_no": 10,
      "bbox": [
        171.24600219726562,
        203.00978088378906,
        398.9216003417969,
        225.88009643554688
      ],
      "text": "Sampling\n256\n10.0 × 1014\n45.5\nREBASE\n32\n1.48 × 1014\n46.8"
    },
    {
      "page_no": 10,
      "bbox": [
        279.43499755859375,
        231.8784942626953,
        332.5655517578125,
        241.84109497070312
      ],
      "text": "Llemma-34B"
    },
    {
      "page_no": 10,
      "bbox": [
        171.24600219726562,
        246.7677764892578,
        398.9216003417969,
        269.6370544433594
      ],
      "text": "Sampling\n64\n12.1 × 1014\n46.7\nREBASE\n32\n7.08 × 1014\n49.2"
    },
    {
      "page_no": 10,
      "bbox": [
        107.99996948242188,
        297.7994689941406,
        504.0032653808594,
        362.5570373535156
      ],
      "text": "difficulty and inference strategy. We divide the MATH test set into MATH-easy (levels 1-2) and\nMATH-hard (levels 3-5) and compare REBASE to sampling on these two subsets. The results are\nshown in Fig. 8. The performance of sampling and REBASE on easy problems (levels 1-2) is com-\nparable. However, REBASE demonstrates a significant advantage on harder problems (levels 3-5).\nThis suggests that advanced inference strategies like tree search are especially effective for solving\ndifficult problems."
    },
    {
      "page_no": 10,
      "bbox": [
        107.99993896484375,
        372.927490234375,
        504.0033264160156,
        492.5699157714844
      ],
      "text": "REBASE saturates later than sampling with higher accuracy.\nFrom Fig. 6 and Fig. 7, we ob-\nserve that both sampling and REBASE saturate early in GSM8K and relatively late in MATH. We\nattribute this to the difference of in difficulty levels between GSM8K and MATH. Specifically, the\nLLM may assign high probability only to correct solutions in easy problems, but spread probability\nmass across solutions in harder problems. Thus, harder problems may require aggregating over more\nsolution paths to converge to the distribution over answers shown in Theorems 1 & 2. On MATH\n(Fig. 6), we see that REBASE finally saturates with a higher accuracy than sampling. We hypoth-\nesize the reason is that drawing samples from REBASE corresponds to sampling from a policy that\nassigns high probability to true answers compared to sampling from the underlying language model.\nIf this was indeed the case, Theorems 1 & 2 indicate that the upper bound would become higher. We\nleave formally analyzing the behavior of tree search algorithms as interesting future work."
    },
    {
      "page_no": 10,
      "bbox": [
        108.29894256591797,
        506.7511901855469,
        201.27845764160156,
        518.7063598632812
      ],
      "text": "5\nCONCLUSIONS"
    },
    {
      "page_no": 10,
      "bbox": [
        107.99993896484375,
        527.59033203125,
        504.00323486328125,
        570.4298706054688
      ],
      "text": "We study the relationship between task performance and the amount of compute expended during\ninference for various model sizes, model families, and inference strategies, to form empirical in-\nference scaling laws. These relationships let us reason about compute-optimal inference: inference\nconfigurations that give the best performance at a given compute budget."
    },
    {
      "page_no": 10,
      "bbox": [
        107.99993896484375,
        579.84033203125,
        504.0033264160156,
        732.2688598632812
      ],
      "text": "Our results lead to three main takeaways. First, we find that using a smaller model and generat-\ning more tokens in an inference strategy often outperforms using a larger model at a fixed compute\nbudget. This has implications for models deployed in the real world, where inference compute\nis constrained in various ways. Specifically, it is potentially beneficial to deploy smaller models\nwith more sophisticated inference strategies for better cost-performance trade-off. Second, we show\nthat in the limit of infinite compute (allocated by drawing more samples), sampling-based majority\nvoting strategies inevitably saturate to a distribution that depends on the underlying generation pol-\nicy. Hence, it is of interest to alter the sampling distribution by designing an alternative inference\nstrategy. Third, we design such an inference strategy–the novel REBASE tree search–and find it is\nPareto optimal, in that it achieves the best performance across all tested compute budgets. Notably,\nit outperforms commonly used weighted majority voting and MCTS methods that have attracted\nmuch interest and widespread use. This finding not only shows the strength of REBASE, but also\nindicates that there is large headroom to improve language model performances via inference-time\nalgorithms."
    },
    {
      "page_no": 10,
      "bbox": [
        301.0189208984375,
        752.1943359375,
        310.98150634765625,
        762.1569213867188
      ],
      "text": "10"
    },
    {
      "page_no": 11,
      "bbox": [
        108.0,
        27.81348991394043,
        293.0951843261719,
        37.77608871459961
      ],
      "text": "Published as a conference paper at ICLR 2025"
    },
    {
      "page_no": 11,
      "bbox": [
        108.29900360107422,
        82.75727844238281,
        212.57635498046875,
        94.71247863769531
      ],
      "text": "ACKNOWLEDGMENT"
    },
    {
      "page_no": 11,
      "bbox": [
        108.00000762939453,
        101.66346740722656,
        504.00323486328125,
        122.58505249023438
      ],
      "text": "Zhiqing Sun acknowledges the support of the Google Fellowship. Sean Welleck thanks NSF SCALE\n(NSF DMS 2134012) and Convergent Research."
    },
    {
      "page_no": 11,
      "bbox": [
        108.29901123046875,
        133.7362823486328,
        175.25979614257812,
        145.6914825439453
      ],
      "text": "REFERENCES"
    },
    {
      "page_no": 11,
      "bbox": [
        108.00000762939453,
        152.1834259033203,
        504.0032043457031,
        173.10501098632812
      ],
      "text": "David H Ackley, Geoffrey E Hinton, and Terrence J Sejnowski. A learning algorithm for boltzmann\nmachines. Cognitive science, 9(1):147–169, 1985."
    },
    {
      "page_no": 11,
      "bbox": [
        108.0,
        181.4293975830078,
        504.0032653808594,
        213.30899047851562
      ],
      "text": "Ibrahim M Alabdulmohsin, Behnam Neyshabur, and Xiaohua Zhai. Revisiting neural scaling laws\nin language and vision. Advances in Neural Information Processing Systems, 35:22300–22312,\n2022."
    },
    {
      "page_no": 11,
      "bbox": [
        107.99998474121094,
        221.6333770751953,
        504.00372314453125,
        253.51394653320312
      ],
      "text": "Jacob Austin, Augustus Odena, Maxwell Nye, Maarten Bosma, Henryk Michalewski, David Dohan,\nEllen Jiang, Carrie Cai, Michael Terry, Quoc Le, and Charles Sutton. Program synthesis with large\nlanguage models, 2021. URL https://arxiv.org/abs/2108.07732."
    },
    {
      "page_no": 11,
      "bbox": [
        108.0,
        261.83734130859375,
        504.00384521484375,
        304.6769104003906
      ],
      "text": "Zhangir Azerbayev, Hailey Schoelkopf, Keiran Paster, Marco Dos Santos, Stephen Marcus McAleer,\nAlbert Q. Jiang, Jia Deng, Stella Biderman, and Sean Welleck. Llemma: An open language model\nfor mathematics. In The Twelfth International Conference on Learning Representations, 2024.\nURL https://openreview.net/forum?id=4WnqRR915j."
    },
    {
      "page_no": 11,
      "bbox": [
        108.0,
        313.00030517578125,
        504.0036315917969,
        355.8398742675781
      ],
      "text": "Stella Biderman, Hailey Schoelkopf, Quentin Gregory Anthony, Herbie Bradley, Kyle O’Brien, Eric\nHallahan, Mohammad Aflah Khan, Shivanshu Purohit, USVSN Sai Prashanth, Edward Raff, et al.\nPythia: A suite for analyzing large language models across training and scaling. In International\nConference on Machine Learning, pp. 2397–2430. PMLR, 2023."
    },
    {
      "page_no": 11,
      "bbox": [
        107.99998474121094,
        364.16326904296875,
        504.0036926269531,
        407.0028381347656
      ],
      "text": "Tim Brooks, Bill Peebles, Connor Holmes, Will DePue, Yufei Guo, Li Jing, David Schnurr, Joe\nTaylor, Troy Luhman, Eric Luhman, Clarence Ng, Ricky Wang, and Aditya Ramesh.\nVideo\ngeneration models as world simulators, 2024. URL https://openai.com/research/\nvideo-generation-models-as-world-simulators."
    },
    {
      "page_no": 11,
      "bbox": [
        108.0,
        415.32720947265625,
        504.00372314453125,
        447.2068176269531
      ],
      "text": "Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D. Kaplan, Prafulla Dhariwal,\nArvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al. Language models are\nfew-shot learners. Advances in Neural Information Processing Systems, 33:1877–1901, 2020."
    },
    {
      "page_no": 11,
      "bbox": [
        108.0,
        455.53118896484375,
        504.0037536621094,
        487.4117736816406
      ],
      "text": "Guoxin Chen, Minpeng Liao, Chengxi Li, and Kai Fan. Alphamath almost zero: Process supervision\nwithout process.\nIn The Thirty-eighth Annual Conference on Neural Information Processing\nSystems, 2024a. URL https://openreview.net/forum?id=VaXnxQ3UKo."
    },
    {
      "page_no": 11,
      "bbox": [
        108.0,
        495.73516845703125,
        504.00469970703125,
        538.57470703125
      ],
      "text": "Ziru Chen, Michael White, Ray Mooney, Ali Payani, Yu Su, and Huan Sun. When is tree search\nuseful for llm planning? it depends on the discriminator. In Proceedings of the 62nd Annual\nMeeting of the Association for Computational Linguistics (Volume 1: Long Papers), pp. 13659–\n13678, 2024b."
    },
    {
      "page_no": 11,
      "bbox": [
        107.99998474121094,
        546.8981323242188,
        504.0031433105469,
        589.7377319335938
      ],
      "text": "Sehyun Choi, Tianqing Fang, Zhaowei Wang, and Yangqiu Song. KCTS: Knowledge-constrained\ntree search decoding with token-level hallucination detection. In The 2023 Conference on Em-\npirical Methods in Natural Language Processing, 2023. URL https://openreview.net/\nforum?id=7H45HfXsJb."
    },
    {
      "page_no": 11,
      "bbox": [
        107.99998474121094,
        598.0611572265625,
        504.0037536621094,
        640.9006958007812
      ],
      "text": "Aakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav Mishra, Adam\nRoberts, Paul Barham, Hyung Won Chung, Charles Sutton, Sebastian Gehrmann, et al. Palm:\nScaling language modeling with pathways. Journal of Machine Learning Research, 24(240):\n1–113, 2023."
    },
    {
      "page_no": 11,
      "bbox": [
        107.99998474121094,
        649.22509765625,
        504.0036315917969,
        692.063720703125
      ],
      "text": "Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Mark Chen, Heewoo Jun, Lukasz Kaiser,\nMatthias Plappert, Jerry Tworek, Jacob Hilton, Reiichiro Nakano, Christopher Hesse, and John\nSchulman. Training verifiers to solve math word problems. arXiv preprint arXiv:2110.14168,\n2021."
    },
    {
      "page_no": 11,
      "bbox": [
        107.99998474121094,
        700.3881225585938,
        504.00384521484375,
        732.2687377929688
      ],
      "text": "Abhimanyu Dubey, Abhinav Jauhri, Abhinav Pandey, Abhishek Kadian, Ahmad Al-Dahle, Aiesha\nLetman, Akhil Mathur, Alan Schelten, Amy Yang, Angela Fan, et al. The llama 3 herd of models.\narXiv preprint arXiv:2407.21783, 2024."
    },
    {
      "page_no": 11,
      "bbox": [
        301.01898193359375,
        752.193115234375,
        310.9815673828125,
        762.1557006835938
      ],
      "text": "11"
    },
    {
      "page_no": 12,
      "bbox": [
        108.0,
        27.81348991394043,
        293.0951843261719,
        37.77608871459961
      ],
      "text": "Published as a conference paper at ICLR 2025"
    },
    {
      "page_no": 12,
      "bbox": [
        108.0,
        84.26844787597656,
        504.00323486328125,
        105.19003295898438
      ],
      "text": "Leo Gao, John Schulman, and Jacob Hilton. Scaling laws for reward model overoptimization. In\nInternational Conference on Machine Learning, pp. 10835–10866. PMLR, 2023."
    },
    {
      "page_no": 12,
      "bbox": [
        108.0,
        115.64540100097656,
        504.0032653808594,
        158.48495483398438
      ],
      "text": "Sachin Goyal, Ziwei Ji, Ankit Singh Rawat, Aditya Krishna Menon, Sanjiv Kumar, and Vaishnavh\nNagarajan. Think before you speak: Training language models with pause tokens. In The Twelfth\nInternational Conference on Learning Representations, 2024a. URL https://openreview.\nnet/forum?id=ph04CRkPdC."
    },
    {
      "page_no": 12,
      "bbox": [
        107.99996948242188,
        168.94032287597656,
        504.0031433105469,
        200.82089233398438
      ],
      "text": "Sachin Goyal, Pratyush Maini, Zachary C Lipton, Aditi Raghunathan, and J Zico Kolter. Scaling\nlaws for data filtering–data curation cannot be compute agnostic. In Proceedings of the IEEE/CVF\nConference on Computer Vision and Pattern Recognition, pp. 22702–22711, 2024b."
    },
    {
      "page_no": 12,
      "bbox": [
        107.99995422363281,
        211.09979248046875,
        503.999755859375,
        232.19784545898438
      ],
      "text": "Alex Graves.\nSequence transduction with recurrent neural networks.\narXiv preprint\narXiv:1211.3711, 2012."
    },
    {
      "page_no": 12,
      "bbox": [
        107.99994659423828,
        242.65321350097656,
        504.00360107421875,
        296.4517517089844
      ],
      "text": "Dan Hendrycks, Steven Basart, Saurav Kadavath, Mantas Mazeika, Akul Arora, Ethan Guo, Collin\nBurns, Samir Puranik, Horace He, Dawn Song, and Jacob Steinhardt. Measuring coding chal-\nlenge competence with APPS. In Thirty-fifth Conference on Neural Information Processing Sys-\ntems Datasets and Benchmarks Track (Round 2), 2021a. URL https://openreview.net/\nforum?id=sD93GOzH3i5."
    },
    {
      "page_no": 12,
      "bbox": [
        107.99993896484375,
        306.9071350097656,
        504.0035400390625,
        349.7457580566406
      ],
      "text": "Dan Hendrycks, Collin Burns, Saurav Kadavath, Akul Arora, Steven Basart, Eric Tang, Dawn\nSong, and Jacob Steinhardt. Measuring mathematical problem solving with the MATH dataset.\nIn Thirty-fifth Conference on Neural Information Processing Systems Datasets and Benchmarks\nTrack (Round 2), 2021b. URL https://openreview.net/forum?id=7Bywt2mQsCe."
    },
    {
      "page_no": 12,
      "bbox": [
        107.99993896484375,
        360.2011413574219,
        504.0035095214844,
        392.0817565917969
      ],
      "text": "Tom Henighan, Jared Kaplan, Mor Katz, Mark Chen, Christopher Hesse, Jacob Jackson, Heewoo\nJun, Tom B. Brown, Prafulla Dhariwal, Scott Gray, et al. Scaling laws for autoregressive genera-\ntive modeling. arXiv preprint arXiv:2010.14701, 2020."
    },
    {
      "page_no": 12,
      "bbox": [
        107.99995422363281,
        402.5371398925781,
        504.0036926269531,
        434.4177551269531
      ],
      "text": "Joel Hestness, Sharan Narang, Newsha Ardalani, Gregory Diamos, Heewoo Jun, Hassan Kianinejad,\nMd Patwary, Mostofa Ali, Yang Yang, and Yanqi Zhou. Deep learning scaling is predictable,\nempirically. arXiv preprint arXiv:1712.00409, 2017."
    },
    {
      "page_no": 12,
      "bbox": [
        107.99995422363281,
        444.8731384277344,
        504.003662109375,
        476.7537536621094
      ],
      "text": "Jordan Hoffmann, Sebastian Borgeaud, Arthur Mensch, Elena Buchatskaya, Trevor Cai, Eliza\nRutherford, Diego de Las Casas, Lisa Anne Hendricks, Johannes Welbl, Aidan Clark, et al. Train-\ning compute-optimal large language models. arXiv preprint arXiv:2203.15556, 2022."
    },
    {
      "page_no": 12,
      "bbox": [
        107.99993896484375,
        487.2091369628906,
        504.0037536621094,
        519.0897216796875
      ],
      "text": "Albert Q Jiang, Alexandre Sablayrolles, Arthur Mensch, Chris Bamford, Devendra Singh Chaplot,\nDiego de las Casas, Florian Bressand, Gianna Lengyel, Guillaume Lample, Lucile Saulnier, et al.\nMistral 7b. arXiv preprint arXiv:2310.06825, 2023."
    },
    {
      "page_no": 12,
      "bbox": [
        107.99992370605469,
        529.3687133789062,
        489.55609130859375,
        539.5077514648438
      ],
      "text": "Andy L Jones. Scaling scaling laws with board games. arXiv preprint arXiv:2104.03113, 2021."
    },
    {
      "page_no": 12,
      "bbox": [
        107.99993896484375,
        549.963134765625,
        504.00360107421875,
        581.8436889648438
      ],
      "text": "Jared Kaplan, Sam McCandlish, Tom Henighan, Tom B. Brown, Benjamin Chess, Rewon Child,\nScott Gray, Alec Radford, Jeffrey Wu, and Dario Amodei. Scaling laws for neural language\nmodels. arXiv preprint arXiv:2001.08361, 2020."
    },
    {
      "page_no": 12,
      "bbox": [
        107.99993896484375,
        592.2991333007812,
        504.0037536621094,
        657.0557250976562
      ],
      "text": "Aitor Lewkowycz, Anders Johan Andreassen, David Dohan, Ethan Dyer, Henryk Michalewski,\nVinay Venkatesh Ramasesh, Ambrose Slone, Cem Anil, Imanol Schlag, Theo Gutman-Solo,\nYuhuai Wu, Behnam Neyshabur, Guy Gur-Ari, and Vedant Misra.\nSolving quantitative rea-\nsoning problems with language models. In Alice H. Oh, Alekh Agarwal, Danielle Belgrave,\nand Kyunghyun Cho (eds.), Advances in Neural Information Processing Systems, 2022. URL\nhttps://openreview.net/forum?id=IFXTZERXdM7."
    },
    {
      "page_no": 12,
      "bbox": [
        107.99996948242188,
        667.5111083984375,
        504.00360107421875,
        732.2687377929688
      ],
      "text": "Yifei Li, Zeqi Lin, Shizhuo Zhang, Qiang Fu, Bei Chen, Jian-Guang Lou, and Weizhu Chen. Mak-\ning language models better reasoners with step-aware verifier. In Anna Rogers, Jordan Boyd-\nGraber, and Naoaki Okazaki (eds.), Proceedings of the 61st Annual Meeting of the Association\nfor Computational Linguistics (Volume 1: Long Papers), pp. 5315–5333, Toronto, Canada, July\n2023. Association for Computational Linguistics. doi: 10.18653/v1/2023.acl-long.291. URL\nhttps://aclanthology.org/2023.acl-long.291."
    },
    {
      "page_no": 12,
      "bbox": [
        301.01898193359375,
        752.1941528320312,
        310.9815673828125,
        762.15673828125
      ],
      "text": "12"
    },
    {
      "page_no": 13,
      "bbox": [
        108.0,
        27.81348991394043,
        293.0951843261719,
        37.77608871459961
      ],
      "text": "Published as a conference paper at ICLR 2025"
    },
    {
      "page_no": 13,
      "bbox": [
        108.0,
        84.26844787597656,
        504.0035095214844,
        127.10800170898438
      ],
      "text": "Hunter Lightman, Vineet Kosaraju, Yuri Burda, Harrison Edwards, Bowen Baker, Teddy Lee, Jan\nLeike, John Schulman, Ilya Sutskever, and Karl Cobbe. Let’s verify step by step. In The Twelfth\nInternational Conference on Learning Representations, 2024. URL https://openreview.\nnet/forum?id=v8L0pN6EOi."
    },
    {
      "page_no": 13,
      "bbox": [
        107.99993896484375,
        136.8874053955078,
        504.00360107421875,
        168.76797485351562
      ],
      "text": "Haowei Lin, Baizhou Huang, Haotian Ye, Qinyu Chen, Zihao Wang, Sujian Li, Jianzhu Ma, Xiaojun\nWan, James Zou, and Yitao Liang.\nSelecting large language model to fine-tune via rectified\nscaling law. In International Conference on Machine Learning, pp. 30080–30107. PMLR, 2024."
    },
    {
      "page_no": 13,
      "bbox": [
        107.99990844726562,
        178.54835510253906,
        504.0047912597656,
        221.38693237304688
      ],
      "text": "Wang Ling, Dani Yogatama, Chris Dyer, and Phil Blunsom. Program induction by rationale gener-\nation: Learning to solve and explain algebraic word problems. In Proceedings of the 55th Annual\nMeeting of the Association for Computational Linguistics (Volume 1: Long Papers), pp. 158–167,\n2017."
    },
    {
      "page_no": 13,
      "bbox": [
        107.99992370605469,
        231.1673126220703,
        504.00347900390625,
        274.0058898925781
      ],
      "text": "Jiacheng Liu, Andrew Cohen, Ramakanth Pasunuru, Yejin Choi, Hannaneh Hajishirzi, and Asli\nCelikyilmaz. Don’t throw away your value model! generating more preferable text with value-\nguided monte-carlo tree search decoding. In First Conference on Language Modeling, 2024. URL\nhttps://openreview.net/forum?id=kh9Zt2Ldmn."
    },
    {
      "page_no": 13,
      "bbox": [
        107.99993896484375,
        283.7862854003906,
        504.0035400390625,
        315.6669006347656
      ],
      "text": "Niklas Muennighoff, Alexander Rush, Boaz Barak, Teven Le Scao, Nouamane Tazi, Aleksandra\nPiktus, Sampo Pyysalo, Thomas Wolf, and Colin A Raffel. Scaling data-constrained language\nmodels. Advances in Neural Information Processing Systems, 36:50358–50376, 2023."
    },
    {
      "page_no": 13,
      "bbox": [
        107.99992370605469,
        325.4462890625,
        504.00372314453125,
        368.2858581542969
      ],
      "text": "Maxwell Nye, Anders Johan Andreassen, Guy Gur-Ari, Henryk Michalewski, Jacob Austin,\nDavid Bieber, David Dohan, Aitor Lewkowycz, Maarten Bosma, David Luan, et al.\nShow\nyour work: Scratchpads for intermediate computation with language models.\narXiv preprint\narXiv:2112.00114, 2021."
    },
    {
      "page_no": 13,
      "bbox": [
        107.99992370605469,
        378.06524658203125,
        261.54351806640625,
        388.0278625488281
      ],
      "text": "OpenAI. Gpt-4 technical report, 2023."
    },
    {
      "page_no": 13,
      "bbox": [
        107.99992370605469,
        397.6318054199219,
        503.9960021972656,
        418.7288818359375
      ],
      "text": "William Peebles and Saining Xie. Scalable diffusion models with transformers. In Proceedings of\nthe IEEE/CVF International Conference on Computer Vision, pp. 4195–4205, 2023."
    },
    {
      "page_no": 13,
      "bbox": [
        107.99992370605469,
        428.50927734375,
        504.0032043457031,
        460.3898620605469
      ],
      "text": "Jacob Pfau, William Merrill, and Samuel R. Bowman. Let’s think dot by dot: Hidden computation in\ntransformer language models. In First Conference on Language Modeling, 2024. URL https:\n//openreview.net/forum?id=NikbrdtYvG."
    },
    {
      "page_no": 13,
      "bbox": [
        107.99990844726562,
        470.16925048828125,
        504.00335693359375,
        502.0498352050781
      ],
      "text": "Jonathan S. Rosenfeld, Amir Rosenfeld, Yonatan Belinkov, and Nir Shavit. A constructive prediction\nof the generalization error across scales. In International Conference on Learning Representa-\ntions, 2020. URL https://openreview.net/forum?id=ryenvpEKDr."
    },
    {
      "page_no": 13,
      "bbox": [
        107.99990844726562,
        511.8292236328125,
        504.0031433105469,
        543.7097778320312
      ],
      "text": "Nikhil Sardana, Jacob Portes, Sasha Doubov, and Jonathan Frankle. Beyond chinchilla-optimal: Ac-\ncounting for inference in language model scaling laws. In International Conference on Machine\nLearning, pp. 43445–43460. PMLR, 2024."
    },
    {
      "page_no": 13,
      "bbox": [
        107.99992370605469,
        553.4891967773438,
        504.0037841796875,
        585.3698120117188
      ],
      "text": "David Silver, Aja Huang, Chris J Maddison, Arthur Guez, Laurent Sifre, George Van Den Driessche,\nJulian Schrittwieser, Ioannis Antonoglou, Veda Panneershelvam, Marc Lanctot, et al. Mastering\nthe game of Go with deep neural networks and tree search. Nature, 529(7587):484–489, 2016."
    },
    {
      "page_no": 13,
      "bbox": [
        107.99993896484375,
        595.1502075195312,
        504.0036315917969,
        627.02978515625
      ],
      "text": "David Silver, Julian Schrittwieser, Karen Simonyan, Ioannis Antonoglou, Aja Huang, Arthur Guez,\nThomas Hubert, Lucas Baker, Matthew Lai, Adrian Bolton, et al. Mastering the game of go\nwithout human knowledge. nature, 550(7676):354–359, 2017."
    },
    {
      "page_no": 13,
      "bbox": [
        107.99993896484375,
        636.8101806640625,
        504.0032653808594,
        679.6497802734375
      ],
      "text": "Charlie Victor Snell, Jaehoon Lee, Kelvin Xu, and Aviral Kumar. Scaling test-time compute opti-\nmally can be more effective than scaling LLM parameters. In The Thirteenth International Con-\nference on Learning Representations, 2025.\nURL https://openreview.net/forum?\nid=4FWAwZtd2n."
    },
    {
      "page_no": 13,
      "bbox": [
        107.99993133544922,
        689.42919921875,
        504.0032653808594,
        732.268798828125
      ],
      "text": "Zhiqing Sun, Longhui Yu, Yikang Shen, Weiyang Liu, Yiming Yang, Sean Welleck, and Chuang\nGan. Easy-to-hard generalization: Scalable alignment beyond human supervision. In The Thirty-\neighth Annual Conference on Neural Information Processing Systems, 2024. URL https://\nopenreview.net/forum?id=qwgfh2fTtN."
    },
    {
      "page_no": 13,
      "bbox": [
        301.0189208984375,
        752.1942138671875,
        310.98150634765625,
        762.1567993164062
      ],
      "text": "13"
    },
    {
      "page_no": 14,
      "bbox": [
        108.0,
        27.81348991394043,
        293.0951843261719,
        37.77608871459961
      ],
      "text": "Published as a conference paper at ICLR 2025"
    },
    {
      "page_no": 14,
      "bbox": [
        108.0,
        84.26844787597656,
        504.0032043457031,
        105.19003295898438
      ],
      "text": "Virginia Teller. Speech and language processing: an introduction to natural language processing,\ncomputational linguistics, and speech recognition, 2000."
    },
    {
      "page_no": 14,
      "bbox": [
        108.0,
        112.78144836425781,
        504.0033874511719,
        155.62002563476562
      ],
      "text": "Ye Tian, Baolin Peng, Linfeng Song, Lifeng Jin, Dian Yu, Lei Han, Haitao Mi, and Dong Yu.\nToward self-improvement of LLMs via imagination, searching, and criticizing. In The Thirty-\neighth Annual Conference on Neural Information Processing Systems, 2024. URL https://\nopenreview.net/forum?id=tPdJ2qHkOB."
    },
    {
      "page_no": 14,
      "bbox": [
        108.00001525878906,
        163.21144104003906,
        504.0036315917969,
        195.09103393554688
      ],
      "text": "Jonathan Uesato, Nate Kushman, Ramana Kumar, Francis Song, Noah Siegel, Lisa Wang, Antonia\nCreswell, Geoffrey Irving, and Irina Higgins. Solving math word problems with process- and\noutcome-based feedback. arXiv preprint arXiv:2211.14275, 2022."
    },
    {
      "page_no": 14,
      "bbox": [
        108.0,
        202.6824493408203,
        504.0035400390625,
        267.4389953613281
      ],
      "text": "Peiyi Wang, Lei Li, Zhihong Shao, Runxin Xu, Damai Dai, Yifei Li, Deli Chen, Yu Wu, and Zhi-\nfang Sui. Math-shepherd: Verify and reinforce LLMs step-by-step without human annotations. In\nLun-Wei Ku, Andre Martins, and Vivek Srikumar (eds.), Proceedings of the 62nd Annual Meet-\ning of the Association for Computational Linguistics (Volume 1: Long Papers), pp. 9426–9439,\nBangkok, Thailand, August 2024. Association for Computational Linguistics. doi: 10.18653/v1/\n2024.acl-long.510. URL https://aclanthology.org/2024.acl-long.510/."
    },
    {
      "page_no": 14,
      "bbox": [
        108.00003051757812,
        275.0303955078125,
        504.00360107421875,
        317.8689880371094
      ],
      "text": "Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc V Le, Ed H. Chi, Sharan Narang, Aakanksha\nChowdhery, and Denny Zhou. Self-consistency improves chain of thought reasoning in language\nmodels. In The Eleventh International Conference on Learning Representations, 2023a. URL\nhttps://openreview.net/forum?id=1PL1NIMMrw."
    },
    {
      "page_no": 14,
      "bbox": [
        108.0,
        325.46038818359375,
        504.0036315917969,
        368.2989807128906
      ],
      "text": "Yizhong Wang, Yeganeh Kordi, Swaroop Mishra, Alisa Liu, Noah A Smith, Daniel Khashabi, and\nHannaneh Hajishirzi. Self-instruct: Aligning language models with self-generated instructions. In\nProceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume\n1: Long Papers), pp. 13484–13508, 2023b."
    },
    {
      "page_no": 14,
      "bbox": [
        107.99999237060547,
        375.890380859375,
        504.0033874511719,
        429.6879577636719
      ],
      "text": "Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, brian ichter, Fei Xia, Ed H. Chi,\nQuoc V Le, and Denny Zhou. Chain of thought prompting elicits reasoning in large language\nmodels. In Alice H. Oh, Alekh Agarwal, Danielle Belgrave, and Kyunghyun Cho (eds.), Ad-\nvances in Neural Information Processing Systems, 2022. URL https://openreview.net/\nforum?id=_VjQlMeSB_J."
    },
    {
      "page_no": 14,
      "bbox": [
        108.0,
        437.27935791015625,
        504.0035095214844,
        480.1179504394531
      ],
      "text": "Sean Welleck, Amanda Bertsch, Matthew Finlayson, Hailey Schoelkopf, Alex Xie, Graham Neubig,\nIlia Kulikov, and Zaid Harchaoui. From decoding to meta-generation: Inference-time algorithms\nfor large language models. Transactions on Machine Learning Research, 2024. ISSN 2835-8856.\nURL https://openreview.net/forum?id=eskQMcIbMS. Survey Certification."
    },
    {
      "page_no": 14,
      "bbox": [
        108.0,
        487.7093505859375,
        504.00384521484375,
        519.5899047851562
      ],
      "text": "Yuxi Xie, Kenji Kawaguchi, Yiran Zhao, Xu Zhao, Min-Yen Kan, Junxian He, and Qizhe Xie. Self-\nevaluation guided beam search for reasoning. In Thirty-seventh Conference on Neural Information\nProcessing Systems, 2023. URL https://openreview.net/forum?id=Bw82hwg5Q3."
    },
    {
      "page_no": 14,
      "bbox": [
        108.0,
        527.1802978515625,
        504.0036315917969,
        570.0198974609375
      ],
      "text": "Shunyu Yao, Dian Yu, Jeffrey Zhao, Izhak Shafran, Thomas L. Griffiths, Yuan Cao, and Karthik R\nNarasimhan.\nTree of thoughts: Deliberate problem solving with large language models.\nIn\nThirty-seventh Conference on Neural Information Processing Systems, 2023.\nURL https:\n//openreview.net/forum?id=5Xc1ecxO1h."
    },
    {
      "page_no": 14,
      "bbox": [
        108.0,
        577.6103515625,
        504.0046081542969,
        631.4088745117188
      ],
      "text": "Jiahui Yu, Yuanzhong Xu, Jing Yu Koh, Thang Luong, Gunjan Baid, Zirui Wang, Vijay Vasudevan,\nAlexander Ku, Yinfei Yang, Burcu Karagol Ayan, Ben Hutchinson, Wei Han, Zarana Parekh, Xin\nLi, Han Zhang, Jason Baldridge, and Yonghui Wu. Scaling autoregressive models for content-rich\ntext-to-image generation. Transactions on Machine Learning Research, 2022. ISSN 2835-8856.\nURL https://openreview.net/forum?id=AFDcYJKhND. Featured Certification."
    },
    {
      "page_no": 14,
      "bbox": [
        107.99996948242188,
        638.9993286132812,
        504.0036315917969,
        681.8389282226562
      ],
      "text": "Longhui Yu, Weisen Jiang, Han Shi, Jincheng YU, Zhengying Liu, Yu Zhang, James Kwok, Zhen-\nguo Li, Adrian Weller, and Weiyang Liu. Metamath: Bootstrap your own mathematical questions\nfor large language models. In The Twelfth International Conference on Learning Representations,\n2024. URL https://openreview.net/forum?id=N8N0hgNDRt."
    },
    {
      "page_no": 14,
      "bbox": [
        108.0,
        689.4293212890625,
        504.0033264160156,
        732.2689208984375
      ],
      "text": "Shun Zhang, Zhenfang Chen, Yikang Shen, Mingyu Ding, Joshua B. Tenenbaum, and Chuang Gan.\nPlanning with large language models for code generation. In The Eleventh International Confer-\nence on Learning Representations, 2023. URL https://openreview.net/forum?id=\nLr8cOOtYbfL."
    },
    {
      "page_no": 14,
      "bbox": [
        301.0190124511719,
        752.1943359375,
        310.9815979003906,
        762.1569213867188
      ],
      "text": "14"
    },
    {
      "page_no": 15,
      "bbox": [
        108.0,
        27.81348991394043,
        293.0951843261719,
        37.77608871459961
      ],
      "text": "Published as a conference paper at ICLR 2025"
    },
    {
      "page_no": 15,
      "bbox": [
        108.0,
        84.26844787597656,
        504.0032958984375,
        116.14901733398438
      ],
      "text": "Andy Zhou, Kai Yan, Michal Shlapentokh-Rothman, Haohan Wang, and Yu-Xiong Wang. Language\nagent tree search unifies reasoning, acting, and planning in language models. In Proceedings of\nthe 41st International Conference on Machine Learning, pp. 62138–62160, 2024."
    },
    {
      "page_no": 15,
      "bbox": [
        301.01898193359375,
        752.1943969726562,
        310.9815673828125,
        762.156982421875
      ],
      "text": "15"
    },
    {
      "page_no": 16,
      "bbox": [
        108.0,
        27.81348991394043,
        293.0951843261719,
        37.77608871459961
      ],
      "text": "Published as a conference paper at ICLR 2025"
    },
    {
      "page_no": 16,
      "bbox": [
        108.29900360107422,
        82.75727844238281,
        221.4178466796875,
        94.71247863769531
      ],
      "text": "A\nOMITTED PROOFS"
    },
    {
      "page_no": 16,
      "bbox": [
        108.24899291992188,
        102.42543029785156,
        230.1212921142578,
        112.38803100585938
      ],
      "text": "A.1\nPROOF OF THEOREM 1"
    },
    {
      "page_no": 16,
      "bbox": [
        107.99990844726562,
        119.7037582397461,
        504.0000305175781,
        151.94400024414062
      ],
      "text": "Proof. Recall that we assume the answer must be shorter than L tokens. Let A = {v | |v| ≤L} be\nthe set of all possible answers. Let ˜π(y | x) be the probability of the language model π outputting\nthe answer y to the question x after marginalizing over the “reasoning paths”, i.e.,"
    },
    {
      "page_no": 16,
      "bbox": [
        252.76290893554688,
        160.7382354736328,
        315.7958679199219,
        173.00244140625
      ],
      "text": "˜π(y | x) =\nX"
    },
    {
      "page_no": 16,
      "bbox": [
        299.0699157714844,
        162.91065979003906,
        359.2384948730469,
        184.25445556640625
      ],
      "text": "r∈V∗\nπ(rey|x)."
    },
    {
      "page_no": 16,
      "bbox": [
        107.99990844726562,
        195.6937713623047,
        459.0971374511719,
        217.4464111328125
      ],
      "text": "Given an input x, Assume that y∗= arg max\ny∈A\n˜π(y|x), y′ = arg max\ny∈A\\{y∗}\n˜π(y|x), and denote"
    },
    {
      "page_no": 16,
      "bbox": [
        258.3078918457031,
        225.66720581054688,
        353.69439697265625,
        237.49835205078125
      ],
      "text": "δ = ˜π(y∗|x) −˜π(y′|x)."
    },
    {
      "page_no": 16,
      "bbox": [
        107.99978637695312,
        252.84873962402344,
        504.0002136230469,
        285.57037353515625
      ],
      "text": "For any y, denote by fn(y) the number of times that the model answers y in the first n samples. Let\nEn be the event that majority voting with n samples does not output y∗. We note that En happens\nonly if there exists y′′ such that fn(y′′) ≥fn(y∗). Therefore, by union bound,"
    },
    {
      "page_no": 16,
      "bbox": [
        211.90478515625,
        289.1576232910156,
        400.0966796875,
        304.2043762207031
      ],
      "text": "P(En) ≤P(∃y′′ ∈A\\{y∗}, fn(y′′) ≥fn(y∗))"
    },
    {
      "page_no": 16,
      "bbox": [
        241.28675842285156,
        308.8321838378906,
        278.7217102050781,
        320.96722412109375
      ],
      "text": "≤\nX"
    },
    {
      "page_no": 16,
      "bbox": [
        250.69573974609375,
        308.9572448730469,
        377.3846740722656,
        332.8133850097656
      ],
      "text": "y′′∈A\\{y∗}\nP(fn(y′′) ≥fn(y∗))"
    },
    {
      "page_no": 16,
      "bbox": [
        241.28675842285156,
        336.0402526855469,
        343.605712890625,
        349.0203857421875
      ],
      "text": "≤|A|P(fn(y′) ≥fn(y∗))"
    },
    {
      "page_no": 16,
      "bbox": [
        107.99978637695312,
        362.1592102050781,
        504.0023193359375,
        395.6399230957031
      ],
      "text": "Note that fn(y∗) −fn(y′) can be viewed as a sum of n i.i.d. random variables, which take value\n1 with probability ˜π(y∗|x), −1 with probability ˜π(y′|x), and 0 otherwise. Thus, their expectations\nare all δ = ˜π(y∗|x) −˜π(y′|x). By Hoeffding’s inequality, we have"
    },
    {
      "page_no": 16,
      "bbox": [
        228.13380432128906,
        403.4396057128906,
        370.4148864746094,
        422.26239013671875
      ],
      "text": "P(fn(y′) ≥fn(y∗)) ≤exp\n\u0012\n−nδ2"
    },
    {
      "page_no": 16,
      "bbox": [
        360.7909851074219,
        418.2929382324219,
        365.77227783203125,
        428.2555236816406
      ],
      "text": "2"
    },
    {
      "page_no": 16,
      "bbox": [
        372.1039733886719,
        404.5743713378906,
        383.8675537109375,
        421.4215393066406
      ],
      "text": "\u0013\n."
    },
    {
      "page_no": 16,
      "bbox": [
        107.99996948242188,
        443.2984924316406,
        130.4158172607422,
        453.2611083984375
      ],
      "text": "Thus,"
    },
    {
      "page_no": 16,
      "bbox": [
        193.7689666748047,
        456.26776123046875,
        296.7360534667969,
        475.0915832519531
      ],
      "text": "P(En) ≤|A| exp\n\u0012\n−nδ2"
    },
    {
      "page_no": 16,
      "bbox": [
        287.11199951171875,
        471.1209411621094,
        292.0932922363281,
        481.0835266113281
      ],
      "text": "2"
    },
    {
      "page_no": 16,
      "bbox": [
        298.4259948730469,
        457.4033508300781,
        328.4515686035156,
        474.1203918457031
      ],
      "text": "\u0013\n⇒"
    },
    {
      "page_no": 16,
      "bbox": [
        341.49298095703125,
        454.0793762207031,
        355.8889465332031,
        471.9489440917969
      ],
      "text": "+∞\nX"
    },
    {
      "page_no": 16,
      "bbox": [
        341.1819763183594,
        462.11041259765625,
        418.2335510253906,
        485.2315673828125
      ],
      "text": "n=1\nP(En) < +∞."
    },
    {
      "page_no": 16,
      "bbox": [
        107.99996948242188,
        496.6544494628906,
        247.9446258544922,
        506.6170654296875
      ],
      "text": "By Borel–Cantelli lemma, we have"
    },
    {
      "page_no": 16,
      "bbox": [
        261.8089599609375,
        514.8143310546875,
        321.32647705078125,
        538.9225463867188
      ],
      "text": "P\n\u0012\nlim sup\nn→+∞En"
    },
    {
      "page_no": 16,
      "bbox": [
        321.82598876953125,
        514.8143310546875,
        350.193603515625,
        531.6605224609375
      ],
      "text": "\u0013\n= 0,"
    },
    {
      "page_no": 16,
      "bbox": [
        108.00001525878906,
        546.9839477539062,
        305.24761962890625,
        557.1229858398438
      ],
      "text": "which implies the following is true almost surely:"
    },
    {
      "page_no": 16,
      "bbox": [
        189.0060272216797,
        563.3873901367188,
        422.9954833984375,
        583.236572265625
      ],
      "text": "∃N ∈N∗, such that for any n ≥N, y∗= arg max\ny∈A\nfn(y)"
    },
    {
      "page_no": 16,
      "bbox": [
        108.00003051757812,
        598.514404296875,
        428.79058837890625,
        625.58251953125
      ],
      "text": "Hence\nlim\nn→+∞accMV\nn\n({(x, y)}; π) = I [y = y∗]\n(almost surely)."
    },
    {
      "page_no": 16,
      "bbox": [
        108.0,
        636.3013305664062,
        503.99774169921875,
        669.7820434570312
      ],
      "text": "Recall the definition of y∗, the above shows the theorem is true for a dataset with a single example\n{(x, y)}. For general datasets D with m examples, one can apply the above argument to each\nexamples and combine the results to conclude the proof of the almost-sure convergence."
    },
    {
      "page_no": 16,
      "bbox": [
        108.00001525878906,
        675.0503540039062,
        504.0018310546875,
        707.8982543945312
      ],
      "text": "Next, we prove the asymptotic result on E\n\u0002\naccMV\nn\n({D}; π)\n\u0003\n. We slightly abuse notation for sim-\nplicity as follows: We let y∗(xi) = arg max\ny∈A\n˜π(y|xi), y′ =\narg max\ny∈A\\{y∗(xi)}\n˜π(y|xi), and let"
    },
    {
      "page_no": 16,
      "bbox": [
        213.1160125732422,
        715.558349609375,
        398.8865966796875,
        734.2794799804688
      ],
      "text": "δmin =\nmin\n(xi,yi)∈D ˜π(y∗(xi)|xi) −˜π(y′(xi)|xi)."
    },
    {
      "page_no": 16,
      "bbox": [
        301.0190124511719,
        752.1944580078125,
        310.9815979003906,
        762.1570434570312
      ],
      "text": "16"
    },
    {
      "page_no": 17,
      "bbox": [
        108.0,
        27.81348991394043,
        293.0951843261719,
        37.77608871459961
      ],
      "text": "Published as a conference paper at ICLR 2025"
    },
    {
      "page_no": 17,
      "bbox": [
        107.99996948242188,
        82.6683578491211,
        504.0003356933594,
        105.80150604248047
      ],
      "text": "We denote by En(xi) the event that majority voting with n samples does not output y∗(xi) given\ninput xi. Then it’s easy to see that"
    },
    {
      "page_no": 17,
      "bbox": [
        175.19996643066406,
        111.95368957519531,
        303.775390625,
        136.7705078125
      ],
      "text": "P(En(xi)) ≤|A| exp\n\u0012\n−nδ2\nmin\n2"
    },
    {
      "page_no": 17,
      "bbox": [
        305.468017578125,
        113.08930969238281,
        436.8014831542969,
        130.77752685546875
      ],
      "text": "\u0013\n⇒\nP(En(xi)) = O(c−n)"
    },
    {
      "page_no": 17,
      "bbox": [
        108.00003051757812,
        144.20286560058594,
        330.7292175292969,
        154.39602661132812
      ],
      "text": "where c > 1 is a constant (which does not depend on i)."
    },
    {
      "page_no": 17,
      "bbox": [
        108.00001525878906,
        159.76931762695312,
        500.18133544921875,
        172.9114990234375
      ],
      "text": "Note that if accMV\nn\n({xi, yi}; π) = 1, we have yi = y∗(xi) unless En(xi) happens. In other words,"
    },
    {
      "page_no": 17,
      "bbox": [
        176.88697814941406,
        178.30235290527344,
        377.73797607421875,
        192.25152587890625
      ],
      "text": "accMV\nn\n({xi, yi}; π) ≤I [yi = y∗(xi)] + I[En(xi)]"
    },
    {
      "page_no": 17,
      "bbox": [
        156.96192932128906,
        194.0108184814453,
        455.0406188964844,
        211.26596069335938
      ],
      "text": "⇒\n\f\fE\n\u0002\naccMV\nn\n({xi, yi}; π)\n\u0003\n−I [yi = y∗(xi)]\n\f\f ≤P(En(xi)) = O(c−n)."
    },
    {
      "page_no": 17,
      "bbox": [
        108.00003051757812,
        220.4118194580078,
        315.75067138671875,
        271.7050476074219
      ],
      "text": "Taking a summation over the entire dataset D yields\n\f\f\f\f\faccMV\nn\n(D; π) −1"
    },
    {
      "page_no": 17,
      "bbox": [
        229.38600158691406,
        254.9369354248047,
        238.13316345214844,
        264.8995361328125
      ],
      "text": "m"
    },
    {
      "page_no": 17,
      "bbox": [
        240.98899841308594,
        237.98475646972656,
        255.38494873046875,
        255.76394653320312
      ],
      "text": "m\nX"
    },
    {
      "page_no": 17,
      "bbox": [
        241.7310028076172,
        245.92637634277344,
        316.1790466308594,
        269.16656494140625
      ],
      "text": "i=1\nI [yi = y∗(xi)]"
    },
    {
      "page_no": 17,
      "bbox": [
        316.1759948730469,
        237.83131408691406,
        340.8403015136719,
        271.7049865722656
      ],
      "text": "≤1"
    },
    {
      "page_no": 17,
      "bbox": [
        333.97601318359375,
        254.9369354248047,
        342.7231750488281,
        264.8995361328125
      ],
      "text": "m"
    },
    {
      "page_no": 17,
      "bbox": [
        345.5790100097656,
        237.98475646972656,
        359.9749755859375,
        255.76394653320312
      ],
      "text": "m\nX"
    },
    {
      "page_no": 17,
      "bbox": [
        346.3210144042969,
        245.92637634277344,
        452.974609375,
        269.16656494140625
      ],
      "text": "i=1\nP(En(xi)) = O(c−n),"
    },
    {
      "page_no": 17,
      "bbox": [
        108.00003051757812,
        275.84844970703125,
        215.90492248535156,
        285.8110656738281
      ],
      "text": "which concludes the proof."
    },
    {
      "page_no": 17,
      "bbox": [
        108.2490005493164,
        298.762451171875,
        230.1212921142578,
        308.7250671386719
      ],
      "text": "A.2\nPROOF OF THEOREM 2"
    },
    {
      "page_no": 17,
      "bbox": [
        108.0,
        315.52301025390625,
        406.190185546875,
        325.6620788574219
      ],
      "text": "Proof. The proof is similar to the proof of Theorem 1. We only need to set"
    },
    {
      "page_no": 17,
      "bbox": [
        232.9290008544922,
        333.75537109375,
        295.96197509765625,
        346.01953125
      ],
      "text": "˜π(y | x) =\nX"
    },
    {
      "page_no": 17,
      "bbox": [
        279.2350158691406,
        335.9278259277344,
        379.0735778808594,
        357.2715759277344
      ],
      "text": "r∈V∗\nπ(rey|xi)ρ(xirey)."
    },
    {
      "page_no": 17,
      "bbox": [
        108.0,
        364.48046875,
        375.5655212402344,
        374.4430847167969
      ],
      "text": "Then the technique in the proof of Theorem 1 immediately applies."
    },
    {
      "page_no": 17,
      "bbox": [
        301.0190124511719,
        752.1944580078125,
        310.9815979003906,
        762.1570434570312
      ],
      "text": "17"
    },
    {
      "page_no": 18,
      "bbox": [
        108.0,
        27.81348991394043,
        293.0951843261719,
        37.77608871459961
      ],
      "text": "Published as a conference paper at ICLR 2025"
    },
    {
      "page_no": 18,
      "bbox": [
        108.29900360107422,
        82.75727844238281,
        210.99359130859375,
        94.71247863769531
      ],
      "text": "B\nMCTS DETAILS"
    },
    {
      "page_no": 18,
      "bbox": [
        108.00001525878906,
        101.95246887207031,
        504.0033874511719,
        122.87405395507812
      ],
      "text": "In this section, we present additional background on the Monte Carlo Tree Search (MCTS) algo-\nrithm. The MCTS process can be formulated as the following steps:"
    },
    {
      "page_no": 18,
      "bbox": [
        108.00001525878906,
        130.5045166015625,
        504.00341796875,
        162.47506713867188
      ],
      "text": "Selection.\nThe process begins at the root node. Here, the algorithm recursively selects the child\nnode that offers the highest Upper Confidence Bound applied to Trees (UCT) value, continuing until\na node is reached that has not been expanded. The UCT is calculated using the formula"
    },
    {
      "page_no": 18,
      "bbox": [
        216.01400756835938,
        181.1299285888672,
        304.23828125,
        191.092529296875
      ],
      "text": "UCT(s) = Q(s) + C"
    },
    {
      "page_no": 18,
      "bbox": [
        304.9480285644531,
        170.3693389892578,
        314.9106140136719,
        180.33193969726562
      ],
      "text": "s"
    },
    {
      "page_no": 18,
      "bbox": [
        316.1059875488281,
        174.3899383544922,
        392.0263671875,
        184.3525390625
      ],
      "text": "ln (N(Parent(s)))"
    },
    {
      "page_no": 18,
      "bbox": [
        343.30999755859375,
        181.1299285888672,
        395.98760986328125,
        197.926513671875
      ],
      "text": "N(s)\n,"
    },
    {
      "page_no": 18,
      "bbox": [
        108.00003051757812,
        208.13792419433594,
        504.00152587890625,
        229.29006958007812
      ],
      "text": "where Q(s) denotes the quality score of node s, N(s) is the number of visits to node s, Parent(s)\ndenotes the parent node of s, and C is a constant determining the level of exploration."
    },
    {
      "page_no": 18,
      "bbox": [
        108.00006103515625,
        236.7809295654297,
        504.0036315917969,
        268.8920593261719
      ],
      "text": "Expansion and evaluation.\nUpon reaching a non-terminal node s, the node is expanded by gen-\nerating multiple child nodes. Each child node c is then evaluated using a value function V (c), which\npredicts the potential quality of continuing the sequence from node c."
    },
    {
      "page_no": 18,
      "bbox": [
        108.00009155273438,
        276.5215148925781,
        504.0028381347656,
        308.4930725097656
      ],
      "text": "Backpropagation.\nAfter evaluation, the algorithm updates the UCT values and the visit counts\nfor all nodes along the path from the selected node back to the root. For any node n in this path, the\nupdates are made as follows:"
    },
    {
      "page_no": 18,
      "bbox": [
        232.45608520507812,
        316.10382080078125,
        313.5207214355469,
        326.1955261230469
      ],
      "text": "N(n) ←N(n) + 1,"
    },
    {
      "page_no": 18,
      "bbox": [
        233.67112731933594,
        330.84783935546875,
        375.5815734863281,
        347.6795349121094
      ],
      "text": "Q(n) ←(N(n) −1) Q(n) + V (s)"
    },
    {
      "page_no": 18,
      "bbox": [
        312.364990234375,
        337.7169189453125,
        379.54559326171875,
        354.5135192871094
      ],
      "text": "N(n)\n."
    },
    {
      "page_no": 18,
      "bbox": [
        301.01898193359375,
        752.1944580078125,
        310.9815673828125,
        762.1570434570312
      ],
      "text": "18"
    },
    {
      "page_no": 19,
      "bbox": [
        108.0,
        27.81348991394043,
        293.0951843261719,
        37.77608871459961
      ],
      "text": "Published as a conference paper at ICLR 2025"
    },
    {
      "page_no": 19,
      "bbox": [
        108.29900360107422,
        82.75727844238281,
        237.11253356933594,
        94.71247863769531
      ],
      "text": "C\nHYPER-PARAMETERS"
    },
    {
      "page_no": 19,
      "bbox": [
        107.99999237060547,
        101.86150360107422,
        504.0030822753906,
        122.87405395507812
      ],
      "text": "Finetuning.\nAll the hyperparameters for model fine-tuning can be found in Tab. 2. We preprocess\nthe MetaMath Dataset to make the solutions in a stepwise format."
    },
    {
      "page_no": 19,
      "bbox": [
        107.99999237060547,
        134.69447326660156,
        504.00323486328125,
        166.57504272460938
      ],
      "text": "Table 2: Fine-tuning Hyper-parameters: LR refers to the learning rate, BS refers to the batch size.\nPythia, Llemma-7B and LLemma-34B are the generators we use in our experiments, RM is short\nfor Reward Model. We only use problems from GSM8K to train the Pythia models."
    },
    {
      "page_no": 19,
      "bbox": [
        110.38999938964844,
        181.1194610595703,
        495.6337890625,
        191.08206176757812
      ],
      "text": "Model\n# Epoch\nDataset\nBS\nLR\nMax Seq Length\nDtype"
    },
    {
      "page_no": 19,
      "bbox": [
        110.38999938964844,
        197.08045959472656,
        494.52777099609375,
        283.7549743652344
      ],
      "text": "Pythia-410M\n1\nMetaMath (GSM8K)\n128\n8E-5\n768\nFP32\nPythia-1.4B\n1\nMetaMath (GSM8K)\n128\n4E-5\n768\nFP32\nPythia-2.8B\n1\nMetaMath (GSM8K)\n128\n3E-5\n768\nFP32\nPythia-6.9B\n1\nMetaMath (GSM8K)\n128\n2E-5\n768\nFP32\nPythia-12B\n1\nMetaMath (GSM8K)\n128\n1E-5\n768\nFP32\nLlemma-7B\n1\nMetaMath\n128\n8E-6\n1024\nFP32\nLlemma-34B\n1\nMetaMath\n128\n8E-6\n768\nFP32\nLlemma-34B RM\n2\nMath-Shepherd\n128\n1E-5\n768\nBF16"
    },
    {
      "page_no": 19,
      "bbox": [
        107.99993896484375,
        300.866943359375,
        504.0032043457031,
        365.8540344238281
      ],
      "text": "Inference.\nFor all the inference strategies, the temperature for LLM token generation is set to 1.0.\nMax tokens for the output is 1024 and max tokens for one step is 256. For REBASE, we set the\nbalance temperature (i.e., the parameter Tb in Eq. (1)) to 0.1. For MCTS, we set C in the UCT\nvalue to 1 and we expand 4, 8, 16 children for the root, 2 children for other selected nodes with total\n32, 64, 128 expansions respectively. New expanded nodes will be assigned values by the PRM, and\nthen backpropagate the Q values through the process described in the last section."
    },
    {
      "page_no": 19,
      "bbox": [
        301.0189208984375,
        752.1944580078125,
        310.98150634765625,
        762.1570434570312
      ],
      "text": "19"
    },
    {
      "page_no": 20,
      "bbox": [
        108.0,
        27.81348991394043,
        293.0951843261719,
        37.77608871459961
      ],
      "text": "Published as a conference paper at ICLR 2025"
    },
    {
      "page_no": 20,
      "bbox": [
        108.29900360107422,
        82.75727844238281,
        325.89190673828125,
        94.71247863769531
      ],
      "text": "D\nADDITIONAL EXPERIMENTAL RESULTS"
    },
    {
      "page_no": 20,
      "bbox": [
        108.0,
        102.19544982910156,
        504.0033874511719,
        192.61892700195312
      ],
      "text": "D.1\nMAJORITY VOTING EXPERIMENT RESULTS\nIn this section, we additionally include experimental results on the majority voting method, along\nwith its comparison with weighted majority voting (Fig. 9, 10 ,11, 12). The experiments show that\nalthough the gap between majority voting and weighted majority voting on sampling is huge. This\ngap becomes much smaller if we apply REBASE. This phenomenon can be caused by the selection\nability of tree search like REBASE. Once REBASE already samples solutions with high rewards,\nconducing weighted majority voting gains less since the sampled solutions may all have relatively\nhigh and stable rewards compared with those of sampling."
    },
    {
      "page_no": 20,
      "bbox": [
        108.00001525878906,
        202.0893096923828,
        504.0032958984375,
        281.5538024902344
      ],
      "text": "D.2\nADDITIONAL EXPERIMENTS ON LLAMA3 MODELS\nWe conduct additional experiments with Llama3-8B-Instruct (Dubey et al., 2024) model on MATH\nand GSM8K datasets, as shown in Fig. 13. Results for code generation task MBPP are presented\n(Austin et al., 2021) in Tab. 3. These experiments demonstrate that our conclusions generalize to\nthe Llama3 architecture and coding tasks, confirming that increased computational effort improves\nperformance until saturation is reached, and REBASE reaches the optimal performance-compute\ntrade-off."
    },
    {
      "page_no": 20,
      "bbox": [
        108.00004577636719,
        288.8871765136719,
        504.0047912597656,
        353.6437683105469
      ],
      "text": "In mathematical reasoning tasks, REBASE consistently outperforms the sampling approach across\ndifferent answer selection strategies, including best-of-n, majority voting, and weighted voting. The\nhighest performance on each dataset is achieved using REBASE. Specifically, on GSM8K, REBASE\ncombined with weighted majority voting using 128 samples achieves an accuracy of 90.2%, sur-\npassing the best accuracy of 89.7% obtained by the sampling method with 256 samples using the\nbest-of-n strategy. Similarly, on MATH, REBASE with weighted majority voting using 128 samples"
    },
    {
      "page_no": 20,
      "bbox": [
        114.87318420410156,
        478.9449768066406,
        234.928955078125,
        499.4751281738281
      ],
      "text": "4\n16\n64\n256\n1024\nInfer. FLOPs per question (×1012)"
    },
    {
      "page_no": 20,
      "bbox": [
        122.41534423828125,
        473.9833984375,
        130.6258544921875,
        484.9307556152344
      ],
      "text": "45"
    },
    {
      "page_no": 20,
      "bbox": [
        122.41534423828125,
        456.7976379394531,
        130.6258544921875,
        467.7449951171875
      ],
      "text": "50"
    },
    {
      "page_no": 20,
      "bbox": [
        122.41534423828125,
        441.251220703125,
        130.6258544921875,
        452.1985778808594
      ],
      "text": "55"
    },
    {
      "page_no": 20,
      "bbox": [
        122.41534423828125,
        427.0584411621094,
        130.6258544921875,
        438.00579833984375
      ],
      "text": "60"
    },
    {
      "page_no": 20,
      "bbox": [
        122.41534423828125,
        414.0023498535156,
        130.6258544921875,
        424.94970703125
      ],
      "text": "65"
    },
    {
      "page_no": 20,
      "bbox": [
        122.41534423828125,
        401.914306640625,
        130.6258544921875,
        412.8616638183594
      ],
      "text": "70"
    },
    {
      "page_no": 20,
      "bbox": [
        122.41534423828125,
        390.6606140136719,
        130.6258544921875,
        401.60797119140625
      ],
      "text": "75"
    },
    {
      "page_no": 20,
      "bbox": [
        122.41534423828125,
        380.13348388671875,
        130.6258544921875,
        391.0808410644531
      ],
      "text": "80"
    },
    {
      "page_no": 20,
      "bbox": [
        110.64743041992188,
        398.7705078125,
        122.81114196777344,
        466.3526916503906
      ],
      "text": "Test error on MATH"
    },
    {
      "page_no": 20,
      "bbox": [
        161.60623168945312,
        373.76190185546875,
        206.52734375,
        387.1419982910156
      ],
      "text": "Llemma-7B"
    },
    {
      "page_no": 20,
      "bbox": [
        186.53604125976562,
        388.2446594238281,
        229.54061889648438,
        407.531982421875
      ],
      "text": "Sampling M.V.\nREBASE M.V."
    },
    {
      "page_no": 20,
      "bbox": [
        246.54310607910156,
        478.9449768066406,
        366.5989074707031,
        499.4751281738281
      ],
      "text": "16\n32\n64 128 256 5121024\nInfer. FLOPs per question (×1012)"
    },
    {
      "page_no": 20,
      "bbox": [
        254.00332641601562,
        473.9833984375,
        262.2138366699219,
        484.9307556152344
      ],
      "text": "45"
    },
    {
      "page_no": 20,
      "bbox": [
        254.00332641601562,
        454.6263427734375,
        262.2138366699219,
        465.5736999511719
      ],
      "text": "50"
    },
    {
      "page_no": 20,
      "bbox": [
        254.00332641601562,
        437.11578369140625,
        262.2138366699219,
        448.0631408691406
      ],
      "text": "55"
    },
    {
      "page_no": 20,
      "bbox": [
        254.00332641601562,
        421.1298522949219,
        262.2138366699219,
        432.07720947265625
      ],
      "text": "60"
    },
    {
      "page_no": 20,
      "bbox": [
        254.00332641601562,
        406.42425537109375,
        262.2138366699219,
        417.3716125488281
      ],
      "text": "65"
    },
    {
      "page_no": 20,
      "bbox": [
        254.00332641601562,
        392.8089904785156,
        262.2138366699219,
        403.75634765625
      ],
      "text": "70"
    },
    {
      "page_no": 20,
      "bbox": [
        254.00332641601562,
        380.13348388671875,
        262.2138366699219,
        391.0808410644531
      ],
      "text": "75"
    },
    {
      "page_no": 20,
      "bbox": [
        242.2354278564453,
        398.7705078125,
        254.39913940429688,
        466.3526916503906
      ],
      "text": "Test error on MATH"
    },
    {
      "page_no": 20,
      "bbox": [
        290.7249755859375,
        373.76190185546875,
        340.6636047363281,
        387.1419982910156
      ],
      "text": "Llemma-34B"
    },
    {
      "page_no": 20,
      "bbox": [
        318.2059631347656,
        388.2446594238281,
        361.2105407714844,
        407.531982421875
      ],
      "text": "Sampling M.V.\nREBASE M.V."
    },
    {
      "page_no": 20,
      "bbox": [
        377.5703430175781,
        478.9449768066406,
        498.1944274902344,
        499.4751281738281
      ],
      "text": "4\n8\n16 32 64 128256512\nInfer. FLOPs per question (×1012)"
    },
    {
      "page_no": 20,
      "bbox": [
        385.5913391113281,
        473.9833984375,
        393.8018493652344,
        484.9307556152344
      ],
      "text": "50"
    },
    {
      "page_no": 20,
      "bbox": [
        385.5913391113281,
        454.9519348144531,
        393.8018493652344,
        465.8992919921875
      ],
      "text": "55"
    },
    {
      "page_no": 20,
      "bbox": [
        385.5913391113281,
        437.5776062011719,
        393.8018493652344,
        448.52496337890625
      ],
      "text": "60"
    },
    {
      "page_no": 20,
      "bbox": [
        385.5913391113281,
        421.5947265625,
        393.8018493652344,
        432.5420837402344
      ],
      "text": "65"
    },
    {
      "page_no": 20,
      "bbox": [
        385.5913391113281,
        406.7969055175781,
        393.8018493652344,
        417.7442626953125
      ],
      "text": "70"
    },
    {
      "page_no": 20,
      "bbox": [
        385.5913391113281,
        393.0204772949219,
        393.8018493652344,
        403.96783447265625
      ],
      "text": "75"
    },
    {
      "page_no": 20,
      "bbox": [
        385.5913391113281,
        380.13348388671875,
        393.8018493652344,
        391.0808410644531
      ],
      "text": "80"
    },
    {
      "page_no": 20,
      "bbox": [
        373.82342529296875,
        398.7705078125,
        385.9871520996094,
        466.3526916503906
      ],
      "text": "Test error on MATH"
    },
    {
      "page_no": 20,
      "bbox": [
        427.1314392089844,
        373.76190185546875,
        466.8851318359375,
        387.1419982910156
      ],
      "text": "Mistral-7B"
    },
    {
      "page_no": 20,
      "bbox": [
        449.2331848144531,
        388.2446594238281,
        492.2377624511719,
        407.531982421875
      ],
      "text": "Sampling M.V.\nREBASE M.V."
    },
    {
      "page_no": 20,
      "bbox": [
        108.0,
        512.761474609375,
        503.999755859375,
        544.7320556640625
      ],
      "text": "Figure 9: The inference scaling laws of different models for the problem-solving error rate on\nMATH test set. The tested models are Llemma-7B (left), Llemma-34B (middle), & Mistral-7B\n(right). In the legend, M.V. refer to majority voting."
    },
    {
      "page_no": 20,
      "bbox": [
        114.95511627197266,
        663.1929931640625,
        235.01087951660156,
        683.7230834960938
      ],
      "text": "2\n4\n8\n16\n32\n64\nInfer. FLOPs per question (×1012)"
    },
    {
      "page_no": 20,
      "bbox": [
        122.41534423828125,
        658.2314453125,
        130.6258544921875,
        669.1787719726562
      ],
      "text": "10"
    },
    {
      "page_no": 20,
      "bbox": [
        122.41534423828125,
        630.7821044921875,
        130.6258544921875,
        641.7294311523438
      ],
      "text": "15"
    },
    {
      "page_no": 20,
      "bbox": [
        122.41534423828125,
        611.3064575195312,
        130.6258544921875,
        622.2537841796875
      ],
      "text": "20"
    },
    {
      "page_no": 20,
      "bbox": [
        122.41534423828125,
        596.2000122070312,
        130.6258544921875,
        607.1473388671875
      ],
      "text": "25"
    },
    {
      "page_no": 20,
      "bbox": [
        122.41534423828125,
        583.8571166992188,
        130.6258544921875,
        594.804443359375
      ],
      "text": "30"
    },
    {
      "page_no": 20,
      "bbox": [
        122.41534423828125,
        564.3814697265625,
        130.6258544921875,
        584.3687133789062
      ],
      "text": "35\n40"
    },
    {
      "page_no": 20,
      "bbox": [
        110.64743041992188,
        580.3799438476562,
        122.81114196777344,
        653.2145385742188
      ],
      "text": "Test error on GSM8K"
    },
    {
      "page_no": 20,
      "bbox": [
        161.64718627929688,
        558.0098876953125,
        206.56829833984375,
        571.3899536132812
      ],
      "text": "Llemma-7B"
    },
    {
      "page_no": 20,
      "bbox": [
        186.6179656982422,
        572.4926147460938,
        229.62254333496094,
        591.7799682617188
      ],
      "text": "Sampling M.V.\nREBASE M.V."
    },
    {
      "page_no": 20,
      "bbox": [
        246.54310607910156,
        663.1929931640625,
        366.5989074707031,
        683.7230834960938
      ],
      "text": "16\n32\n64\n128\n256\nInfer. FLOPs per question (×1012)"
    },
    {
      "page_no": 20,
      "bbox": [
        254.03561401367188,
        658.2314453125,
        262.2461242675781,
        669.1787719726562
      ],
      "text": "10"
    },
    {
      "page_no": 20,
      "bbox": [
        254.03561401367188,
        640.48388671875,
        262.2461242675781,
        651.4312133789062
      ],
      "text": "12"
    },
    {
      "page_no": 20,
      "bbox": [
        254.03561401367188,
        625.4785766601562,
        262.2461242675781,
        636.4259033203125
      ],
      "text": "14"
    },
    {
      "page_no": 20,
      "bbox": [
        254.03561401367188,
        612.4804077148438,
        262.2461242675781,
        623.427734375
      ],
      "text": "16"
    },
    {
      "page_no": 20,
      "bbox": [
        254.03561401367188,
        601.0151977539062,
        262.2461242675781,
        611.9625244140625
      ],
      "text": "18"
    },
    {
      "page_no": 20,
      "bbox": [
        254.03561401367188,
        565.2201538085938,
        262.2461242675781,
        601.7064819335938
      ],
      "text": "20\n22\n24\n26"
    },
    {
      "page_no": 20,
      "bbox": [
        242.2677001953125,
        580.3799438476562,
        254.43141174316406,
        653.2145385742188
      ],
      "text": "Test error on GSM8K"
    },
    {
      "page_no": 20,
      "bbox": [
        290.7411193847656,
        558.0098876953125,
        340.67974853515625,
        571.3899536132812
      ],
      "text": "Llemma-34B"
    },
    {
      "page_no": 20,
      "bbox": [
        318.2059631347656,
        572.4926147460938,
        361.2105407714844,
        591.7799682617188
      ],
      "text": "Sampling M.V.\nREBASE M.V."
    },
    {
      "page_no": 20,
      "bbox": [
        378.1311340332031,
        663.1929931640625,
        498.1869201660156,
        683.7230834960938
      ],
      "text": "2\n4\n8\n16\n32\n64\nInfer. FLOPs per question (×1012)"
    },
    {
      "page_no": 20,
      "bbox": [
        385.6236267089844,
        658.2314453125,
        393.8341369628906,
        669.1787719726562
      ],
      "text": "10"
    },
    {
      "page_no": 20,
      "bbox": [
        385.6236267089844,
        640.3238525390625,
        393.8341369628906,
        651.2711791992188
      ],
      "text": "12"
    },
    {
      "page_no": 20,
      "bbox": [
        385.6236267089844,
        625.1832885742188,
        393.8341369628906,
        636.130615234375
      ],
      "text": "14"
    },
    {
      "page_no": 20,
      "bbox": [
        385.6236267089844,
        612.06787109375,
        393.8341369628906,
        623.0151977539062
      ],
      "text": "16"
    },
    {
      "page_no": 20,
      "bbox": [
        385.6236267089844,
        600.499267578125,
        393.8341369628906,
        611.4465942382812
      ],
      "text": "18"
    },
    {
      "page_no": 20,
      "bbox": [
        385.6236267089844,
        564.3814697265625,
        393.8341369628906,
        601.09814453125
      ],
      "text": "20\n22\n24\n26"
    },
    {
      "page_no": 20,
      "bbox": [
        373.855712890625,
        580.3799438476562,
        386.0194396972656,
        653.2145385742188
      ],
      "text": "Test error on GSM8K"
    },
    {
      "page_no": 20,
      "bbox": [
        427.427978515625,
        558.0098876953125,
        467.181640625,
        571.3899536132812
      ],
      "text": "Mistral-7B"
    },
    {
      "page_no": 20,
      "bbox": [
        449.7939758300781,
        572.4926147460938,
        492.7985534667969,
        591.7799682617188
      ],
      "text": "Sampling M.V.\nREBASE M.V."
    },
    {
      "page_no": 20,
      "bbox": [
        108.0,
        697.009521484375,
        503.99755859375,
        728.9810180664062
      ],
      "text": "Figure 10: The inference scaling laws of different models for the problem-solving error rate on\nGSM8K test set. The tested models are Llemma-7B (left), Llemma-34B (middle), & Mistral-7B\n(right). In the legend, M.V. refer to majority voting."
    },
    {
      "page_no": 20,
      "bbox": [
        301.0190124511719,
        752.1944580078125,
        310.9815979003906,
        762.1570434570312
      ],
      "text": "20"
    },
    {
      "page_no": 21,
      "bbox": [
        108.0,
        27.81348991394043,
        293.0951843261719,
        37.77608871459961
      ],
      "text": "Published as a conference paper at ICLR 2025"
    },
    {
      "page_no": 21,
      "bbox": [
        114.87318420410156,
        187.12698364257812,
        234.928955078125,
        207.65713500976562
      ],
      "text": "4\n16\n64\n256\n1024\nInfer. FLOPs per question (×1012)"
    },
    {
      "page_no": 21,
      "bbox": [
        122.41534423828125,
        182.1654052734375,
        130.6258544921875,
        193.1127471923828
      ],
      "text": "45"
    },
    {
      "page_no": 21,
      "bbox": [
        122.41534423828125,
        164.97964477539062,
        130.6258544921875,
        175.92698669433594
      ],
      "text": "50"
    },
    {
      "page_no": 21,
      "bbox": [
        122.41534423828125,
        149.4332275390625,
        130.6258544921875,
        160.3805694580078
      ],
      "text": "55"
    },
    {
      "page_no": 21,
      "bbox": [
        122.41534423828125,
        135.24044799804688,
        130.6258544921875,
        146.1877899169922
      ],
      "text": "60"
    },
    {
      "page_no": 21,
      "bbox": [
        122.41534423828125,
        122.18435668945312,
        130.6258544921875,
        133.13169860839844
      ],
      "text": "65"
    },
    {
      "page_no": 21,
      "bbox": [
        122.41534423828125,
        110.09632110595703,
        130.6258544921875,
        121.04366302490234
      ],
      "text": "70"
    },
    {
      "page_no": 21,
      "bbox": [
        122.41534423828125,
        98.84262084960938,
        130.6258544921875,
        109.78996276855469
      ],
      "text": "75"
    },
    {
      "page_no": 21,
      "bbox": [
        122.41534423828125,
        88.31548309326172,
        130.6258544921875,
        99.26282501220703
      ],
      "text": "80"
    },
    {
      "page_no": 21,
      "bbox": [
        110.64743041992188,
        106.95249938964844,
        122.81114196777344,
        174.53469848632812
      ],
      "text": "Test error on MATH"
    },
    {
      "page_no": 21,
      "bbox": [
        161.60623168945312,
        81.94390106201172,
        206.52734375,
        95.32398986816406
      ],
      "text": "Llemma-7B"
    },
    {
      "page_no": 21,
      "bbox": [
        184.58615112304688,
        96.42664337158203,
        229.5397186279297,
        133.61036682128906
      ],
      "text": "Sampling M.V.\nSampling W.M.\nREBASE M.V.\nREBASE W.M."
    },
    {
      "page_no": 21,
      "bbox": [
        246.54310607910156,
        187.12698364257812,
        366.5989074707031,
        207.65713500976562
      ],
      "text": "16\n32\n64 128 256 5121024\nInfer. FLOPs per question (×1012)"
    },
    {
      "page_no": 21,
      "bbox": [
        254.00332641601562,
        182.1654052734375,
        262.2138366699219,
        193.1127471923828
      ],
      "text": "45"
    },
    {
      "page_no": 21,
      "bbox": [
        254.00332641601562,
        162.80836486816406,
        262.2138366699219,
        173.75570678710938
      ],
      "text": "50"
    },
    {
      "page_no": 21,
      "bbox": [
        254.00332641601562,
        145.2977752685547,
        262.2138366699219,
        156.2451171875
      ],
      "text": "55"
    },
    {
      "page_no": 21,
      "bbox": [
        254.00332641601562,
        129.31187438964844,
        262.2138366699219,
        140.25921630859375
      ],
      "text": "60"
    },
    {
      "page_no": 21,
      "bbox": [
        254.00332641601562,
        114.60626220703125,
        262.2138366699219,
        125.55360412597656
      ],
      "text": "65"
    },
    {
      "page_no": 21,
      "bbox": [
        254.00332641601562,
        100.99099731445312,
        262.2138366699219,
        111.93833923339844
      ],
      "text": "70"
    },
    {
      "page_no": 21,
      "bbox": [
        254.00332641601562,
        88.31548309326172,
        262.2138366699219,
        99.26282501220703
      ],
      "text": "75"
    },
    {
      "page_no": 21,
      "bbox": [
        242.2354278564453,
        106.95249938964844,
        254.39913940429688,
        174.53469848632812
      ],
      "text": "Test error on MATH"
    },
    {
      "page_no": 21,
      "bbox": [
        290.7249755859375,
        81.94390106201172,
        340.6636047363281,
        95.32398986816406
      ],
      "text": "Llemma-34B"
    },
    {
      "page_no": 21,
      "bbox": [
        316.2560729980469,
        96.42664337158203,
        361.2096252441406,
        133.61036682128906
      ],
      "text": "Sampling M.V.\nSampling W.M.\nREBASE M.V.\nREBASE W.M."
    },
    {
      "page_no": 21,
      "bbox": [
        377.5703430175781,
        187.12698364257812,
        498.1944274902344,
        207.65713500976562
      ],
      "text": "4\n8\n16 32 64 128256512\nInfer. FLOPs per question (×1012)"
    },
    {
      "page_no": 21,
      "bbox": [
        385.5913391113281,
        182.1654052734375,
        393.8018493652344,
        193.1127471923828
      ],
      "text": "50"
    },
    {
      "page_no": 21,
      "bbox": [
        385.5913391113281,
        163.1339569091797,
        393.8018493652344,
        174.081298828125
      ],
      "text": "55"
    },
    {
      "page_no": 21,
      "bbox": [
        385.5913391113281,
        145.7595977783203,
        393.8018493652344,
        156.70693969726562
      ],
      "text": "60"
    },
    {
      "page_no": 21,
      "bbox": [
        385.5913391113281,
        129.7767333984375,
        393.8018493652344,
        140.7240753173828
      ],
      "text": "65"
    },
    {
      "page_no": 21,
      "bbox": [
        385.5913391113281,
        114.97891998291016,
        393.8018493652344,
        125.92626190185547
      ],
      "text": "70"
    },
    {
      "page_no": 21,
      "bbox": [
        385.5913391113281,
        101.20248413085938,
        393.8018493652344,
        112.14982604980469
      ],
      "text": "75"
    },
    {
      "page_no": 21,
      "bbox": [
        385.5913391113281,
        88.31548309326172,
        393.8018493652344,
        99.26282501220703
      ],
      "text": "80"
    },
    {
      "page_no": 21,
      "bbox": [
        373.82342529296875,
        106.95249938964844,
        385.9871520996094,
        174.53469848632812
      ],
      "text": "Test error on MATH"
    },
    {
      "page_no": 21,
      "bbox": [
        427.1314392089844,
        81.94390106201172,
        466.8851318359375,
        95.32398986816406
      ],
      "text": "Mistral-7B"
    },
    {
      "page_no": 21,
      "bbox": [
        447.2832946777344,
        96.42664337158203,
        492.2368469238281,
        133.61036682128906
      ],
      "text": "Sampling M.V.\nSampling W.M.\nREBASE M.V.\nREBASE W.M."
    },
    {
      "page_no": 21,
      "bbox": [
        107.99998474121094,
        220.94354248046875,
        503.999755859375,
        252.91506958007812
      ],
      "text": "Figure 11: The inference scaling laws of different models for the problem-solving error rate on\nMATH test set. The tested models are Llemma-7B (left), Llemma-34B (middle), & Mistral-7B\n(right). In the legend, M.V. and W.M. refer to majority voting and weighted majority, respectively."
    },
    {
      "page_no": 21,
      "bbox": [
        114.95511627197266,
        371.0159912109375,
        235.01087951660156,
        391.546142578125
      ],
      "text": "2\n4\n8\n16\n32\n64\nInfer. FLOPs per question (×1012)"
    },
    {
      "page_no": 21,
      "bbox": [
        122.41534423828125,
        366.0544128417969,
        130.6258544921875,
        377.00177001953125
      ],
      "text": "10"
    },
    {
      "page_no": 21,
      "bbox": [
        122.41534423828125,
        338.6050720214844,
        130.6258544921875,
        349.55242919921875
      ],
      "text": "15"
    },
    {
      "page_no": 21,
      "bbox": [
        122.41534423828125,
        319.12945556640625,
        130.6258544921875,
        330.0768127441406
      ],
      "text": "20"
    },
    {
      "page_no": 21,
      "bbox": [
        122.41534423828125,
        304.0229797363281,
        130.6258544921875,
        314.9703369140625
      ],
      "text": "25"
    },
    {
      "page_no": 21,
      "bbox": [
        122.41534423828125,
        291.68011474609375,
        130.6258544921875,
        302.6274719238281
      ],
      "text": "30"
    },
    {
      "page_no": 21,
      "bbox": [
        122.41534423828125,
        272.2044982910156,
        130.6258544921875,
        292.19171142578125
      ],
      "text": "35\n40"
    },
    {
      "page_no": 21,
      "bbox": [
        110.64743041992188,
        288.2030029296875,
        122.81114196777344,
        361.0375671386719
      ],
      "text": "Test error on GSM8K"
    },
    {
      "page_no": 21,
      "bbox": [
        161.64718627929688,
        265.8329162597656,
        206.56829833984375,
        279.2130126953125
      ],
      "text": "Llemma-7B"
    },
    {
      "page_no": 21,
      "bbox": [
        184.66807556152344,
        280.315673828125,
        229.62164306640625,
        317.4993591308594
      ],
      "text": "Sampling M.V.\nSampling W.M.\nREBASE M.V.\nREBASE W.M."
    },
    {
      "page_no": 21,
      "bbox": [
        246.54310607910156,
        371.0159912109375,
        366.5989074707031,
        391.546142578125
      ],
      "text": "16\n32\n64\n128\n256\nInfer. FLOPs per question (×1012)"
    },
    {
      "page_no": 21,
      "bbox": [
        254.03561401367188,
        366.0544128417969,
        262.2461242675781,
        377.00177001953125
      ],
      "text": "10"
    },
    {
      "page_no": 21,
      "bbox": [
        254.03561401367188,
        348.4013671875,
        262.2461242675781,
        359.3487243652344
      ],
      "text": "12"
    },
    {
      "page_no": 21,
      "bbox": [
        254.03561401367188,
        333.47589111328125,
        262.2461242675781,
        344.4232482910156
      ],
      "text": "14"
    },
    {
      "page_no": 21,
      "bbox": [
        254.03561401367188,
        320.5469055175781,
        262.2461242675781,
        331.4942626953125
      ],
      "text": "16"
    },
    {
      "page_no": 21,
      "bbox": [
        254.03561401367188,
        309.1427001953125,
        262.2461242675781,
        320.0900573730469
      ],
      "text": "18"
    },
    {
      "page_no": 21,
      "bbox": [
        254.03561401367188,
        273.5381774902344,
        262.2461242675781,
        309.8886413574219
      ],
      "text": "20\n22\n24\n26"
    },
    {
      "page_no": 21,
      "bbox": [
        242.2677001953125,
        288.2030029296875,
        254.43141174316406,
        361.0375671386719
      ],
      "text": "Test error on GSM8K"
    },
    {
      "page_no": 21,
      "bbox": [
        290.7411193847656,
        265.8329162597656,
        340.67974853515625,
        279.2130126953125
      ],
      "text": "Llemma-34B"
    },
    {
      "page_no": 21,
      "bbox": [
        316.2560729980469,
        280.315673828125,
        361.2096252441406,
        317.4993591308594
      ],
      "text": "Sampling M.V.\nSampling W.M.\nREBASE M.V.\nREBASE W.M."
    },
    {
      "page_no": 21,
      "bbox": [
        378.1311340332031,
        371.0159912109375,
        498.1869201660156,
        391.546142578125
      ],
      "text": "2\n4\n8\n16\n32\n64\nInfer. FLOPs per question (×1012)"
    },
    {
      "page_no": 21,
      "bbox": [
        389.730712890625,
        366.0544128417969,
        393.8359680175781,
        377.00177001953125
      ],
      "text": "8"
    },
    {
      "page_no": 21,
      "bbox": [
        385.6236267089844,
        348.2867126464844,
        393.8341369628906,
        359.23406982421875
      ],
      "text": "10"
    },
    {
      "page_no": 21,
      "bbox": [
        385.6236267089844,
        333.7694091796875,
        393.8341369628906,
        344.7167663574219
      ],
      "text": "12"
    },
    {
      "page_no": 21,
      "bbox": [
        385.6236267089844,
        321.4952392578125,
        393.8341369628906,
        332.4425964355469
      ],
      "text": "14"
    },
    {
      "page_no": 21,
      "bbox": [
        385.6236267089844,
        272.2044982910156,
        393.8341369628906,
        321.8102111816406
      ],
      "text": "16\n18\n20\n22\n24\n26"
    },
    {
      "page_no": 21,
      "bbox": [
        373.855712890625,
        288.2030029296875,
        386.0194396972656,
        361.0375671386719
      ],
      "text": "Test error on GSM8K"
    },
    {
      "page_no": 21,
      "bbox": [
        427.427978515625,
        265.8329162597656,
        467.181640625,
        279.2130126953125
      ],
      "text": "Mistral-7B"
    },
    {
      "page_no": 21,
      "bbox": [
        447.8440856933594,
        280.315673828125,
        492.7976379394531,
        317.4993591308594
      ],
      "text": "Sampling M.V.\nSampling W.M.\nREBASE M.V.\nREBASE W.M."
    },
    {
      "page_no": 21,
      "bbox": [
        108.0,
        404.83251953125,
        503.99755859375,
        436.8040466308594
      ],
      "text": "Figure 12: The inference scaling laws of different models for the problem-solving error rate on\nGSM8K test set. The tested models are Llemma-7B (left), Llemma-34B (middle), & Mistral-7B\n(right). In the legend, M.V. and W.M. refer to majority voting and weighted majority, respectively."
    },
    {
      "page_no": 21,
      "bbox": [
        132.05902099609375,
        449.75543212890625,
        479.9413757324219,
        459.7180480957031
      ],
      "text": "Table 3: Zero shot pass rates of Sampling and REBASE on MBPP code generation task."
    },
    {
      "page_no": 21,
      "bbox": [
        108.0,
        474.41680908203125,
        501.40679931640625,
        484.7950744628906
      ],
      "text": "# Samples\nSampling FLOPs\nSampling Pass Rate\nREBASE FLOPs\nREBASE Pass Rate"
    },
    {
      "page_no": 21,
      "bbox": [
        124.2894058227539,
        489.9272766113281,
        471.22662353515625,
        537.4967651367188
      ],
      "text": "8\n8 × 1012\n63\n8.3 × 1012\n69.6\n16\n16 × 1012\n69.4\n17.5 × 1012\n72.4\n32\n32 × 1012\n72.4\n34.9 × 1012\n75.8\n64\n64 × 1012\n79\n69.2 × 1012\n81.4"
    },
    {
      "page_no": 21,
      "bbox": [
        107.99999237060547,
        563.1339111328125,
        503.9981689453125,
        584.2850341796875
      ],
      "text": "achieves an accuracy of 47.4%, significantly outperforming the sampling method’s best accuracy of\n41.9% with 256 samples using best-of-n."
    },
    {
      "page_no": 21,
      "bbox": [
        107.99998474121094,
        591.2594604492188,
        504.00323486328125,
        656.0160522460938
      ],
      "text": "For the code generation task MBPP, we analyze scaling behavior and compute-optimal inference\nthrough pass rate evaluation. The results confirm that REBASE is more compute-efficient than sam-\npling. This advantage can be attributed to the use of a reward model that evaluates partial code\nsolutions. By conducting one iteration of REBASE, our method prunes suboptimal partial solutions\nwhile encouraging exploration of promising ones, thereby enhancing computational efficiency and\nsolution quality."
    },
    {
      "page_no": 21,
      "bbox": [
        107.9999771118164,
        665.0824584960938,
        455.3161926269531,
        689.5910034179688
      ],
      "text": "D.3\nCOMPARISON OF DIFFERENT STRATEGIES ACROSS DIFFERENT MODELS\nWe show the accuracy of different strategies under a specific compute budget in Tab. 4."
    },
    {
      "page_no": 21,
      "bbox": [
        301.01898193359375,
        752.1944580078125,
        310.9815673828125,
        762.1570434570312
      ],
      "text": "21"
    },
    {
      "page_no": 22,
      "bbox": [
        108.0,
        27.81348991394043,
        293.0951843261719,
        37.77608871459961
      ],
      "text": "Published as a conference paper at ICLR 2025"
    },
    {
      "page_no": 22,
      "bbox": [
        136.19393920898438,
        194.02989196777344,
        300.74798583984375,
        214.8806610107422
      ],
      "text": "2\n8\n32\n128\n512\nInfer. FLOPs per question (×1012)"
    },
    {
      "page_no": 22,
      "bbox": [
        127.66436767578125,
        188.99082946777344,
        131.83372497558594,
        200.109130859375
      ],
      "text": "7"
    },
    {
      "page_no": 22,
      "bbox": [
        123.4931411743164,
        169.2613983154297,
        131.8318634033203,
        180.37969970703125
      ],
      "text": "10"
    },
    {
      "page_no": 22,
      "bbox": [
        123.4931411743164,
        153.9580535888672,
        131.8318634033203,
        165.07635498046875
      ],
      "text": "12"
    },
    {
      "page_no": 22,
      "bbox": [
        123.4931411743164,
        141.45433044433594,
        131.8318634033203,
        152.5726318359375
      ],
      "text": "15"
    },
    {
      "page_no": 22,
      "bbox": [
        123.4931411743164,
        93.91781616210938,
        131.8318634033203,
        142.00086975097656
      ],
      "text": "17\n20\n22\n25\n27\n30"
    },
    {
      "page_no": 22,
      "bbox": [
        111.54146575927734,
        109.92365264892578,
        123.89512634277344,
        183.8956298828125
      ],
      "text": "Test error on GSM8K"
    },
    {
      "page_no": 22,
      "bbox": [
        179.43768310546875,
        87.20423889160156,
        255.7718048095703,
        100.79326629638672
      ],
      "text": "Llama3-instruct-8B"
    },
    {
      "page_no": 22,
      "bbox": [
        255.65789794921875,
        101.59801483154297,
        295.9388732910156,
        150.95372009277344
      ],
      "text": "Sampling M.V.\nSampling W.M.\nSampling BoN\nREBASE M.V.\nREBASE W.M.\nREBASE BoN"
    },
    {
      "page_no": 22,
      "bbox": [
        337.3487548828125,
        194.02989196777344,
        496.8085021972656,
        214.8806610107422
      ],
      "text": "4\n16\n64\n256\n1024\nInfer. FLOPs per question (×1012)"
    },
    {
      "page_no": 22,
      "bbox": [
        319.99334716796875,
        188.99082946777344,
        328.33209228515625,
        200.109130859375
      ],
      "text": "50"
    },
    {
      "page_no": 22,
      "bbox": [
        319.99334716796875,
        169.6621856689453,
        328.33209228515625,
        180.78048706054688
      ],
      "text": "55"
    },
    {
      "page_no": 22,
      "bbox": [
        319.99334716796875,
        152.01649475097656,
        328.33209228515625,
        163.13479614257812
      ],
      "text": "60"
    },
    {
      "page_no": 22,
      "bbox": [
        319.99334716796875,
        135.78404235839844,
        328.33209228515625,
        146.90234375
      ],
      "text": "65"
    },
    {
      "page_no": 22,
      "bbox": [
        319.99334716796875,
        120.75514221191406,
        328.33209228515625,
        131.87344360351562
      ],
      "text": "70"
    },
    {
      "page_no": 22,
      "bbox": [
        319.99334716796875,
        106.7635726928711,
        328.33209228515625,
        117.88186645507812
      ],
      "text": "75"
    },
    {
      "page_no": 22,
      "bbox": [
        319.99334716796875,
        93.67532348632812,
        328.33209228515625,
        104.79361724853516
      ],
      "text": "80"
    },
    {
      "page_no": 22,
      "bbox": [
        308.04168701171875,
        112.6033706665039,
        320.3953552246094,
        181.24095153808594
      ],
      "text": "Test error on MATH"
    },
    {
      "page_no": 22,
      "bbox": [
        374.689697265625,
        87.20423889160156,
        451.0238342285156,
        100.79326629638672
      ],
      "text": "Llama3-instruct-8B"
    },
    {
      "page_no": 22,
      "bbox": [
        449.6617431640625,
        101.59801483154297,
        489.9427185058594,
        150.95372009277344
      ],
      "text": "Sampling M.V.\nSampling W.M.\nSampling BoN\nREBASE M.V.\nREBASE W.M.\nREBASE BoN"
    },
    {
      "page_no": 22,
      "bbox": [
        107.99999237060547,
        228.218505859375,
        504.00360107421875,
        260.1900329589844
      ],
      "text": "Figure 13: GSM8K (left) and MATH (right) inference scaling across inference strategies and\nmodels (lower is better). The tested model is Llama3-instruct-8B. In the legend, M.V., W.M., and\nBoN refer to majority voting, weighted majority, and best-of-n, respectively."
    },
    {
      "page_no": 22,
      "bbox": [
        108.0,
        279.58245849609375,
        503.99615478515625,
        300.5950012207031
      ],
      "text": "Table 4: Accuracy of different inference configurations under a specific compute budget. MV,\nBoN and WV denote Majority Voting, best-of-n and Weighted Voting, respectively."
    },
    {
      "page_no": 22,
      "bbox": [
        196.0546875,
        317.045166015625,
        501.34320068359375,
        326.7739562988281
      ],
      "text": "# SAMPLES\nMATH FLOPS\nGSM8K FLOPS\nMATH500\nGSM8K"
    },
    {
      "page_no": 22,
      "bbox": [
        277.383056640625,
        332.6315612792969,
        332.2036437988281,
        342.3603515625
      ],
      "text": "MISTRAL-7B"
    },
    {
      "page_no": 22,
      "bbox": [
        108.24315643310547,
        347.17138671875,
        493.1283874511719,
        425.15350341796875
      ],
      "text": "GREEDY\n1\n3.4 × 1012\n2.3 × 1012\n28.6\n77.9\nSAMPLING + MV\n32\n109.2 × 1012\n72.6 × 1012\n36.1\n85.7\nSAMPLING + BON\n32\n109.2 × 1012\n72.6 × 1012\n40.3\n89.4\nSAMPLING + WV\n32\n109.2 × 1012\n72.6 × 1012\n39.7\n89.1\nREBASE + MV\n32\n136.2 × 1012\n78.9 × 1012\n44.1\n88.8\nREBASE + BON\n32\n136.2 × 1012\n78.9 × 1012\n45.4\n89.4\nREBASE + WV\n32\n136.2 × 1012\n78.9 × 1012\n45.0\n89.8"
    },
    {
      "page_no": 22,
      "bbox": [
        278.1076354980469,
        431.0110778808594,
        331.47906494140625,
        440.7398681640625
      ],
      "text": "LLEMMA-7B"
    },
    {
      "page_no": 22,
      "bbox": [
        108.24315643310547,
        445.5509338378906,
        493.12786865234375,
        523.5330810546875
      ],
      "text": "GREEDY\n1\n3.92 × 1012\n2.3 × 1012\n30.0\n68.5\nSAMPLING + MV\n32\n125.4 × 1012\n73.9 × 1012\n41.0\n80.0\nSAMPLING + BON\n32\n125.4 × 1012\n73.9 × 1012\n41.7\n85.6\nSAMPLING + WV\n32\n125.4 × 1012\n73.9 × 1012\n43.5\n85.4\nREBASE + MV\n32\n148.0 × 1012\n82.6 × 1012\n46.1\n86.1\nREBASE + BON\n32\n148.0 × 1012\n82.6 × 1012\n44.1\n86.9\nREBASE + WV\n32\n148.0 × 1012\n82.6 × 1012\n46.8\n87.3"
    },
    {
      "page_no": 22,
      "bbox": [
        256.12005615234375,
        529.3906860351562,
        353.46563720703125,
        539.1194458007812
      ],
      "text": "LLAMA3-INSTRUCT-8B"
    },
    {
      "page_no": 22,
      "bbox": [
        108.24315643310547,
        543.9304809570312,
        493.12835693359375,
        621.91259765625
      ],
      "text": "GREEDY\n1\n3.84 × 1012\n2.28 × 1012\n29.6\n79.0\nSAMPLING + MV\n32\n122.9 × 1012\n73.2 × 1012\n35.4\n84.6\nSAMPLING + BON\n32\n122.9 × 1012\n73.2 × 1012\n39.7\n88.5\nSAMPLING + WV\n32\n122.9 × 1012\n73.2 × 1012\n39.5\n88.6\nREBASE + MV\n32\n172.8 × 1012\n79.3 × 1012\n45.2\n88.3\nREBASE + BON\n32\n172.8 × 1012\n79.3 × 1012\n45.5\n88.7\nREBASE + WV\n32\n172.8 × 1012\n79.3 × 1012\n43.7\n89.1"
    },
    {
      "page_no": 22,
      "bbox": [
        275.4319152832031,
        627.7702026367188,
        334.1541748046875,
        637.4989624023438
      ],
      "text": "LLEMMA-34B"
    },
    {
      "page_no": 22,
      "bbox": [
        108.24315643310547,
        642.3099975585938,
        493.12841796875,
        720.2930908203125
      ],
      "text": "GREEDY\n1\n19.0 × 1012\n11.2 × 1012\n33.0\n78.4\nSAMPLING + MV\n8\n152.3 × 1012\n89.7 × 1012\n39.9\n84.3\nSAMPLING + BON\n8\n152.3 × 1012\n89.7 × 1012\n40.4\n86.7\nSAMPLING + WV\n8\n152.3 × 1012\n89.7 × 1012\n41.0\n86.0\nREBASE + MV\n8\n176.8 × 1012\n98.7 × 1012\n43.9\n86.1\nREBASE + BON\n8\n176.8 × 1012\n98.7 × 1012\n43.6\n86.9\nREBASE + WV\n8\n176.8 × 1012\n98.7 × 1012\n42.9\n86.9"
    },
    {
      "page_no": 22,
      "bbox": [
        301.0190124511719,
        752.1944580078125,
        310.9815979003906,
        762.1570434570312
      ],
      "text": "22"
    }
  ],
  "pictures": [
    {
      "page_no": 1,
      "bbox": [
        457.7754821777344,
        484.7279357910156,
        463.09527587890625,
        590.3258056640625
      ],
      "xref": 23,
      "image_path": "../data/parsed_documents/2408.00724/images/2408.00724_p1_blk1_crop.png"
    },
    {
      "page_no": 4,
      "bbox": [
        137.69900512695312,
        81.858154296875,
        474.2673034667969,
        247.73199462890625
      ],
      "xref": 1,
      "image_path": "../data/parsed_documents/2408.00724/images/2408.00724_p4_blk1_crop.png"
    },
    {
      "page_no": 6,
      "bbox": [
        187.19900512695312,
        73.3559341430664,
        424.8052978515625,
        187.63397216796875
      ],
      "xref": 1,
      "image_path": "../data/parsed_documents/2408.00724/images/2408.00724_p6_blk1_crop.png"
    },
    {
      "page_no": 6,
      "bbox": [
        146.35400390625,
        188.62991333007812,
        463.1543273925781,
        248.16598510742188
      ],
      "xref": 2,
      "image_path": "../data/parsed_documents/2408.00724/images/2408.00724_p6_blk2_crop.png"
    }
  ],
  "tables": [
    {
      "page_no": 1,
      "index": 1,
      "flavor": "stream",
      "nrows": 8,
      "ncols": 3,
      "csv_path": "../data/parsed_documents/2408.00724/2408.00724_p1_table1_stream.csv"
    },
    {
      "page_no": 1,
      "index": 2,
      "flavor": "stream",
      "nrows": 18,
      "ncols": 1,
      "csv_path": "../data/parsed_documents/2408.00724/2408.00724_p1_table2_stream.csv"
    },
    {
      "page_no": 1,
      "index": 3,
      "flavor": "stream",
      "nrows": 17,
      "ncols": 4,
      "csv_path": "../data/parsed_documents/2408.00724/2408.00724_p1_table3_stream.csv"
    },
    {
      "page_no": 2,
      "index": 1,
      "flavor": "stream",
      "nrows": 53,
      "ncols": 1,
      "csv_path": "../data/parsed_documents/2408.00724/2408.00724_p2_table1_stream.csv"
    },
    {
      "page_no": 3,
      "index": 1,
      "flavor": "stream",
      "nrows": 21,
      "ncols": 1,
      "csv_path": "../data/parsed_documents/2408.00724/2408.00724_p3_table1_stream.csv"
    },
    {
      "page_no": 4,
      "index": 1,
      "flavor": "stream",
      "nrows": 11,
      "ncols": 2,
      "csv_path": "../data/parsed_documents/2408.00724/2408.00724_p4_table1_stream.csv"
    },
    {
      "page_no": 5,
      "index": 1,
      "flavor": "stream",
      "nrows": 25,
      "ncols": 1,
      "csv_path": "../data/parsed_documents/2408.00724/2408.00724_p5_table1_stream.csv"
    },
    {
      "page_no": 6,
      "index": 1,
      "flavor": "stream",
      "nrows": 37,
      "ncols": 1,
      "csv_path": "../data/parsed_documents/2408.00724/2408.00724_p6_table1_stream.csv"
    },
    {
      "page_no": 7,
      "index": 1,
      "flavor": "stream",
      "nrows": 14,
      "ncols": 4,
      "csv_path": "../data/parsed_documents/2408.00724/2408.00724_p7_table1_stream.csv"
    },
    {
      "page_no": 8,
      "index": 1,
      "flavor": "stream",
      "nrows": 12,
      "ncols": 5,
      "csv_path": "../data/parsed_documents/2408.00724/2408.00724_p8_table1_stream.csv"
    },
    {
      "page_no": 8,
      "index": 2,
      "flavor": "stream",
      "nrows": 42,
      "ncols": 1,
      "csv_path": "../data/parsed_documents/2408.00724/2408.00724_p8_table2_stream.csv"
    },
    {
      "page_no": 9,
      "index": 1,
      "flavor": "lattice",
      "nrows": 1,
      "ncols": 6,
      "csv_path": "../data/parsed_documents/2408.00724/2408.00724_p9_table1_lattice.csv"
    },
    {
      "page_no": 9,
      "index": 2,
      "flavor": "lattice",
      "nrows": 1,
      "ncols": 6,
      "csv_path": "../data/parsed_documents/2408.00724/2408.00724_p9_table2_lattice.csv"
    },
    {
      "page_no": 9,
      "index": 3,
      "flavor": "lattice",
      "nrows": 1,
      "ncols": 4,
      "csv_path": "../data/parsed_documents/2408.00724/2408.00724_p9_table3_lattice.csv"
    },
    {
      "page_no": 10,
      "index": 1,
      "flavor": "stream",
      "nrows": 12,
      "ncols": 4,
      "csv_path": "../data/parsed_documents/2408.00724/2408.00724_p10_table1_stream.csv"
    },
    {
      "page_no": 11,
      "index": 1,
      "flavor": "stream",
      "nrows": 47,
      "ncols": 1,
      "csv_path": "../data/parsed_documents/2408.00724/2408.00724_p11_table1_stream.csv"
    },
    {
      "page_no": 12,
      "index": 1,
      "flavor": "stream",
      "nrows": 32,
      "ncols": 1,
      "csv_path": "../data/parsed_documents/2408.00724/2408.00724_p12_table1_stream.csv"
    },
    {
      "page_no": 13,
      "index": 1,
      "flavor": "stream",
      "nrows": 22,
      "ncols": 1,
      "csv_path": "../data/parsed_documents/2408.00724/2408.00724_p13_table1_stream.csv"
    },
    {
      "page_no": 14,
      "index": 1,
      "flavor": "stream",
      "nrows": 52,
      "ncols": 1,
      "csv_path": "../data/parsed_documents/2408.00724/2408.00724_p14_table1_stream.csv"
    },
    {
      "page_no": 15,
      "index": 1,
      "flavor": "stream",
      "nrows": 5,
      "ncols": 3,
      "csv_path": "../data/parsed_documents/2408.00724/2408.00724_p15_table1_stream.csv"
    },
    {
      "page_no": 16,
      "index": 1,
      "flavor": "stream",
      "nrows": 54,
      "ncols": 1,
      "csv_path": "../data/parsed_documents/2408.00724/2408.00724_p16_table1_stream.csv"
    },
    {
      "page_no": 17,
      "index": 1,
      "flavor": "stream",
      "nrows": 23,
      "ncols": 1,
      "csv_path": "../data/parsed_documents/2408.00724/2408.00724_p17_table1_stream.csv"
    },
    {
      "page_no": 18,
      "index": 1,
      "flavor": "stream",
      "nrows": 24,
      "ncols": 7,
      "csv_path": "../data/parsed_documents/2408.00724/2408.00724_p18_table1_stream.csv"
    },
    {
      "page_no": 19,
      "index": 1,
      "flavor": "stream",
      "nrows": 16,
      "ncols": 7,
      "csv_path": "../data/parsed_documents/2408.00724/2408.00724_p19_table1_stream.csv"
    },
    {
      "page_no": 20,
      "index": 1,
      "flavor": "stream",
      "nrows": 22,
      "ncols": 1,
      "csv_path": "../data/parsed_documents/2408.00724/2408.00724_p20_table1_stream.csv"
    },
    {
      "page_no": 20,
      "index": 2,
      "flavor": "stream",
      "nrows": 19,
      "ncols": 3,
      "csv_path": "../data/parsed_documents/2408.00724/2408.00724_p20_table2_stream.csv"
    },
    {
      "page_no": 21,
      "index": 1,
      "flavor": "stream",
      "nrows": 18,
      "ncols": 3,
      "csv_path": "../data/parsed_documents/2408.00724/2408.00724_p21_table1_stream.csv"
    },
    {
      "page_no": 21,
      "index": 2,
      "flavor": "stream",
      "nrows": 6,
      "ncols": 5,
      "csv_path": "../data/parsed_documents/2408.00724/2408.00724_p21_table2_stream.csv"
    },
    {
      "page_no": 22,
      "index": 1,
      "flavor": "stream",
      "nrows": 16,
      "ncols": 7,
      "csv_path": "../data/parsed_documents/2408.00724/2408.00724_p22_table1_stream.csv"
    },
    {
      "page_no": 22,
      "index": 2,
      "flavor": "stream",
      "nrows": 33,
      "ncols": 6,
      "csv_path": "../data/parsed_documents/2408.00724/2408.00724_p22_table2_stream.csv"
    }
  ]
}