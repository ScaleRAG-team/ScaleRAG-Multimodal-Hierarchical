"Appendices"
"A. Related Work"
"Language model reasoning. Language model performance on challenging mathematical reasoning tasks"
"has rapidly improved in recent years [20, 22, 25, 32, 39]. These improvements can be attributed to four"
"primary factors: 1) running continued pretraining on large corpora of math focused data [20, 22, 32, 39];"
"2) improving the LLM proposal distribution by either applying targeted optimization on specific reasoning"
"tasks by finetuning with RL [32, 35, 49, 50] enabling models to critique and revise their answers"
"iteratively [4, 8, 23, 30]; 3) enabling LLMs to benefit from additional test-time computation by finetuning"
"verifiers [6, 7, 10, 22, 40, 42, 45, 48]. Our work builds on these second and third lines of research by"
"analyzing the extent to which test-time compute scaling can be improved by 1) refining an LLMâ€™s proposal"
"distribution and 2) conducting search against verifiers."
"Analyzing test-time compute scaling. The tradeoff between train-time and test-time compute using"
"Monte-Carlo tree search applied to the board game Hex was previously studied by Jones [16]. We instead"
"focus our analysis on full-scale language model math reasoning problems. A survey work by Villalobos"
"and Atkinson [44] analyzed the tradeoff between training and inference across a number of domains."
"However, much of their language-model analysis focused on test-time compute scaling in settings where"
"the ground-truth answer is known.
In contrast, our analysis focuses on the setting when the ground-truth"
"answer is not known. Additionally, a number of works in the RL literature have proposed methods, such"
"as MCTS [19], which aim to navigate the tradeoff between test-time and training-time compute so as"
"to enable a form of
iterative self-play. The findings in our work can be used to help develop similar"
"algorithms that can operate on open-ended natural language."
"Augmenting LLMs with test-time compute. Beyond verifiers and revisions, a number of additional works"
"have proposed alternative methods for enabling LMs to use test-time compute for reasoning. Namely, Wang"
"et al. [46] conducts a hierarchical hypothesis search to enable inductive reasoning capabilities. A number"
"of related works have proposed augmenting language models with tools at test-time, which can greatly"
"improve their performance on downstream tasks [11, 26, 27]. Finally, several works have proposed"
"methods for learning thought tokens in an unsupervised manner [12, 51], enabling models to more"
"effectively utilize the additional test-time compute that comes with sampling longer sequences. While we"
"focus our analysis on two primary mechanisms by which test-time compute can be scaled in this work (e.g."
"verifiers and revisions), many of the methods by which we conduct our analysis (e.g. compute optimal"
"scaling according to question difficulty) could, in principle, also be applied to any of these other methods"
"of scaling test-time compute, and we believe that this is an interesting direction for future research."
"B. Additional Revision Results"
"We plot additional results for majority selection using out PaLM 2-S* revision model in Figure 10. With"
"majority selection, we see largely similar trends to those found in Figure 7 for verifier selection."
"C. Unsupervised Difficulty Bins"
"We compute difficulty bins without oracle ground-truth correctness information by averaging the PRM"
"final-answer score over 2048 samples on each question, so as to obtain a value estimate corresponding to"
