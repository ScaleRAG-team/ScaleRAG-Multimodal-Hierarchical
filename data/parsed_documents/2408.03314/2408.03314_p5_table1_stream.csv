"","modelâ€™s initial samples are more likely to be on the right track but may just need further refinement."
"On the other hand, challenging problems may require more exploration of different high-level problem",""
"solving strategies, so sampling many times independently in parallel may be preferable in this setting.",""
"","In the case of verifiers, we also have the option to choose between different search algorithms (e.g."
"beam-search,","lookahead-search, best-of-N), each of which may exhibit different properties depending on"
"","the quality of the verifier and proposal distribution at hand. More sophisticated search procedures might"
"be more useful in harder problems compared to a much simpler best-of-N or majority baseline.",""
"3.1. Test-Time Compute-Optimal Scaling Strategy",""
"","In general, we would therefore like to select the optimal allocation of our test-time compute budget"
"","for a given problem. To this end, for any given approach of utilizing test-time compute (e.g., revisions"
"","and search against a verifier in this paper, various other methods elsewhere), we define the â€œtest-time"
"","compute-optimal scaling strategyâ€ as the strategy that chooses hyperparameters corresponding to"
"","a given test-time strategy for maximal performance benefits on a given prompt at test time. Formally,"
"",""
"define Target(ğœƒ, ğ‘, ğ‘) as the distribution over natural",""
"","given prompt ğ‘, using test-time compute hyper-parameters ğœƒ, and a compute budget of ğ‘. We would"
"","like to select the hyper-parameters ğœƒ which maximize the accuracy of the target distribution for a given"
"problem. We express this formally as:",""
