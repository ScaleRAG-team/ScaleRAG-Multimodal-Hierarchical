"for math reasoning. In general, we found that the efficacy of a given approach heavily correlates with"
"the difficulty of the problem from the perspective of the base LLM’s capabilities. This motivated us to"
"introduce the notion of “compute-optimal” scaling of test-time computation, which prescribes a adaptive,"
"prompt-dependent strategy to improve performance under a given test-time compute budget. By applying"
"such a compute-optimal scaling strategy, we find that can improve the efficiency of test-time compute"
"scaling by a factor of 2 − 4×. When comparing benefits obtained from additional test-time compute"
"against benefits from additional pre-training compute in a FLOPs-matched setting, we show for the first"
"time that using test-time computation with seemingly simple methods (i.e., revisions and search) can"
"already scale well on certain types of prompts, providing gains over spending those FLOPs in pretraining."
"That said, there are also limitations associated with our study that future work can aim to address."
"In this work we focused on improving the test-time"
"Further improving test-time compute scaling."
"compute scaling of two primary mechanisms: the verifier and the proposal distribution (via revisions)."
"While we combined verifiers with revisions in Section 6, we did not experiment with PRM tree-search"
"techniques in combination with revisions. Neither did we study other techniques such as critique and"
"revise [23]. Future work should investigate how test-time compute scaling can be further improved by"
"combining a variety of these approaches. Additionally, we found that across the board these schemes"
"provided small gains on hard problems; future work should work to develop new ways of using test-time"
"compute which can circumvent this limitation."
"Assessing question difficulty quickly. We used a notion question difficulty as a simple sufficient statistic"
"for approximating the compute-optimal
test-time scaling strategy. While this scheme was effective,"
"estimating our notion of difficulty requires applying a non-trivial amount of test-time compute itself."
"Future work should consider alternative ways of more efficiently estimating question difficulty (e.g., by"
"pretraining or finetuning models to directly predict difficulty of a question) or dynamically switching"
"between assessing difficulty and attempting to solve a question."
"Interleaving test-time and training-time compute. We focused purely on test-time compute scaling"
"in this work and the degree to which test-time compute can be traded off for additional pretraining."
"However,
in the future, we envision that the outputs of applying additional test-time compute can be"
"distilled back into the base LLM, enabling an iterative self-improvement loop that operates on open-ended"
"natural
language. To this end, future work should extend our findings and study how the outputs of"
"applying test-time compute can be used to improve the base LLM itself."
"Acknowledgements"
"We thank Yi Su, Rishabh Agarwal, Yinlam Chow, Aleksandra Faust, Vincent Zhuang, George Tucker,"
"Hao Liu, Jiayi Pan, Ethan Dyer, Behnam Neyshabur, Xavier Garcia, Yamini Bansal, Lampros Lamprou,"
"Yuxiao Qu, and Amrith Setlur for their feedback on an earlier version of the paper and discussions. We"
"attribute and thank Rishabh Agarwal, Vincent Zhuang, Yi Su, and Avi Singh for ideas and discussions,"
"and experiments that concretely demonstrated the promise of pairwise sample generation for training"
"revision models, and edit distance based sampling in [1]. We thank Slav Petrov for leadership support."
"References"
