"perform best with some ideal ratio of sequential","to parallel compute. Moreover, by optimally"
"selecting the best setting for a given question difficulty and test-time compute budget, we can",""
"outperform the parallel best-of-N baseline using up to 4x less test-time compute.",""
"7. Putting it Together: Exchanging Pretraining and Test-Time Compute",""
"So far, we saw that utilizing additional test-time computation can enable us to represent more complex",""
"distributions than the one predicted by the base LLM itself, thereby improving performance. We now",""
"posit that this increased flexibility of representing distributions means that we can expect additional",""
"test-time compute to make up for the lack of a higher-capacity model or training for more FLOPs during",""
"",""
"","In this section, we study to what extent this is possible. We pose the following question:"
